<!DOCTYPE html>
<html>
  <head>
  <title>Meltdown, Spectre, and the State of Technology – 觀點 – 從草根到大師 git.io/JJCxS</title>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="
  
     Meltdown, Spectre, and the State of Technology 
    
  Posted on             Monday, January 8, 2018 
            Friday, June 15, 2018 
     Author  by  Ben Thompson   
    
    
  
  
  
    You’ve heard the adage “It’s all 1s and 0s”, but that’s not a figure of speech: the transistor, the fundamental building block of computers, is simply a switch that is either on (“1”) or off (“0”). It turns out, though, as Chris Dixon chronicled in a wonderful essay entitled  How Aristotle Created the Computer  , that 1s and 0s, through the combination of mathematical logic and transistors, are all you need:
    
      The history of computers is often told as a history of objects, from the abacus to the Babbage engine up through the code-breaking machines of World War II. In fact, it is better understood as a history of ideas, mainly ideas that emerged from mathematical logic, an obscure and cult-like discipline that first developed in the 19th century.
    
    Dixon’s essay — which  I’ve linked to previously  — is well worth a read, but the relevant point for this article is perhaps a surprising one: computers are really stupid; what makes them useful is that they are stupid really quickly.
     The Problem with Processor Vulnerabilities 
    Last week the technology world was shaken by  the disclosure of two vulnerabilities in modern processors  : Meltdown and Spectre. The announcement was a bit haphazard, thanks to the fact that the disclosure date was moved up by a week due to widespread speculation about the nature of the vulnerability (probably driven by updates to the Linux kernel), but also because Meltdown and Spectre are similar in some respects, but different in others.
    Start with the similarities: the outcome for both vulnerabilities is the same — a non-privileged user can access information on the computer they should not be able to, like secret keys or passwords or any other type of data owned by other users. This is a particularly big problem for cloud services like AWS, where multiple “tenants” use the same physical hardware:
      
    This multi-tenant architecture is achieved through the use of virtual machines: there is specialized software that runs on a single physical computer that allows each individual user to operate as if they have their own computer, when in fact they are sharing. This is a win-win: single-user computers sit idle the vast majority of the time (they are stupid really quickly), but if multiple users can use one computer then the hardware can be utilized far more efficiently. And, in the case of cloud services, that same concept can be scaled up to millions of physical computers sharing even more fundamental infrastructure like cooling, networking, administration, etc.
    The entire edifice, though, is predicated on a fundamental assumption: that users in one virtual machine cannot access data from another. That assumption, by extension, relies on trust in the integrity of the virtual machine software, which relies on trust in the integrity of the underlying operating system, which ultimately relies on trust in the processor at the heart of a server. From the  Meltdown white paper  ( 
    emphasis mine
    ):
    
      To load data from the main memory into a register, the data in the main memory is referenced using a virtual address. In parallel to translating a virtual address into a physical address, the CPU also checks the permission bits of the virtual address, i.e., whether this virtual address is user accessible or only accessible by the kernel. As already discussed in Section 2.2, 
     this hardware-based isolation through a permission bit is considered secure and recommended by the hardware vendors. Hence, modern operating systems always map the entire kernel into the virtual address space of every user process.
     As a consequence, all kernel addresses lead to a valid physical address when translating them, and the CPU can access the content of such addresses. The only difference to accessing a user space address is that the CPU raises an exception as the current permission level does not allow to access such an address. Hence, the user space cannot simply read the contents of such an address.
    
    The kernel is the core part of the operating system that should be inaccessible by normal users; it has its own memory to store not only core system data but also data from all of the users (for example, when it has to be written to or read from permanent storage). Even here, though, the system relies on virtualization — that memory is the same physical memory users utilize for their applications. It is up to the CPU to keep track of what parts of memory belong to whom, and this is where the vulnerabilities come in.
     Speculative Execution 
    I just referenced three critical parts of a computer: the processor, memory, and permanent storage. In fact, the architecture for storing data is even more complex than that:
      
    
      Registers are the fastest form of memory, accessible every single clock cycle (that is, a 2.0 GHz processor can access registers two billion times a second). They are also the smallest, usually only containing the inputs and outputs for the current calculation.
      There are then various levels of cache (L1, L2, etc.) that are increasingly slower and, on the flipside, increasingly larger and less expensive. This cache is located in a hierarchy: data that is needed immediately will be moved from the registers to L1 cache, for example; slightly less necessary data will be in L2, then L3, etc.
      The next major part of the memory hierarchy is main memory, that is system RAM. While the amount of cache is dependent on the processor model, the amount of memory is up to the overall system builder. This memory is massively slower than cache, but it is also massively larger and far less expensive.
      The last part of the memory hierarchy, at least on a single computer, is permanent storage — the hard drive. Solid-state drives (SSDs) have made a huge difference in speed here, but even then permanent memory is massively slower than main memory, with the same tradeoffs: you can have a lot more of it at a much lower price.
      While not part of the traditional memory hierarchy, cloud applications often have permanent memory on a separate physical server on the same network; the usual tradeoffs apply — very slow access in exchange for other benefits, in this case keeping data separate from its application.
    
    To be sure, “very slow” is all relative — we are talking about nanoseconds here.  This post by Jeff Atwood  puts it in human terms:
    
      That infinite space “between” what we humans feel as time is where computers spend all their time. It’s an entirely different timescale. The book  Systems Performance: Enterprise and the Cloud  has a great table that illustrates just how enormous these time differentials are. Just translate computer time into arbitrary seconds:
      
        
          
            1 CPU cycle
            0.3 ns
            1 s
          
          
            Level 1 cache access
            0.9 ns
            3 s
          
          
            Level 2 cache access
            2.8 ns
            9 s
          
          
            Level 3 cache access
            12.9 ns
            43 s
          
          
            Main memory access
            120 ns
            6 min
          
          
            Solid-state disk I/O
            50-150 μs
            2-6 days
          
          
            Rotational disk I/O
            1-10 ms
            1-12 months
          
          
            Internet: SF to NYC
            40 ms
            4 years
          
          
            Internet: SF to UK
            81 ms
            8 years
          
          
            Internet: SF to Australia
            183 ms
            19 years
          
          
            OS virtualization reboot
            4 s
            423 years
          
          
            SCSI command time-out
            30 s
            3000 years
          
          
            Hardware virtualization reboot
            40 s
            4000 years
          
          
            Physical system reboot
            5 m
            32 millenia
          
        
      
      […]
      The late, great  Jim Gray  …also  had an interesting way of explaining this  . If the CPU registers are how long it takes you to fetch data from your brain, then going to disk is the equivalent of fetching data from Pluto.
        
    
    Gray presented this slide while at Microsoft, to give context to that that “Olympia, Washington” reference. Let me extend his analogy:
    
    Suppose you were a college student interning for the summer at Microsoft in Redmond, and you were packing clothes at home in Olympia. Now Seattle summers can be quite finicky — it could be blustery and rainy, or hot and sunny. It’s often hard to know what the weather will be like until the morning of. To that end, the prudent course of action would not be to pack only one set of clothes, but rather to pack clothes for either possibility. After all, it is far faster to change clothes from a suitcase than it is to drive home to Olympia every time the weather changes.
   
    This is where the analogy starts to fall apart: what modern processors do to alleviate the time it takes to fetch data is not only fetch more data than they might need, but actually do calculations on that data ahead-of-time. This is known as speculative execution, and it is the heart of these vulnerabilities. To put this analogy in algorithmic form:
    
      Check the weather (execute multiple sub-processes that trigger sensors, relay data, etc.)         
          If the weather is sunny, wear shorts-and-t-shirt
          Else wear jeans-and-sweatshirt
        
      
    
    Remember, computers are stupid, but they are stupid fast: executing “wear shorts-and-t-shirt” or “wear jeans-and-sweatshirt” takes nanoseconds — what takes time is waiting for the weather observation. So to save time the processor will get you dressed before it knows the weather, usually based on history — what was the weather the last several days? That means you can decide on footwear, accessories, etc., all while waiting for the weather observation. That’s the other thing about processors: they can do a lot of things at the same time. To that end the fastest possible way to get something done is to guess what the final outcome will be and backtrack if necessary.
     Meltdown 
    Now, imagine the algorithm was changed to the following:
    
      Check your manager’s calendar to see if they will be in the office         
          If they will be in the office, wear slacks and collared-shirt
          If they will not be in the office, wear shorts-and-t-shirt
        
      
    
    There’s just one problem: you’re not supposed to have access to your manager’s calendar. Keep in mind that computers are stupid: the processor doesn’t know this implicitly, it has to actually check if you have access. So in practice this algorithm is more like this:
    
      Check your manager’s calendar to see if they will be in the office         
          Check if this intern has access to their manager’s calendar             
              If the intern has access, access the calendar                 
                  If they will be in the office, wear slacks and collared-shirt
                  If they will not be in the office, wear shorts-and-t-shirt
                
              
              If the intern does not have access, stop getting dressed
            
          
        
      
    
    Remember, though, computers are very good at doing lots of things at once, and not very good at looking up data; in this case the processor will, under certain conditions, look at the manager’s calendar and decide what to wear 
    before it knows whether or not it should look at the calendar
    . If it later realizes it shouldn’t have access to the calendar it will undo everything, but the clothes might end up slightly disheveled, which means you might be able to back out the answer you weren’t supposed to know.
    I already said that the analogy was falling apart; it is now in complete tatters but this, in broad-strokes, is Meltdown: the processor will speculatively fetch and execute privileged data before it knows if it should or not; that process, though, leaves traces in cache, and those traces can be captured by a non-privileged user.
     Explaining Spectre 
    Spectre is even more devious, but harder to pull off: remember, multiple users are using the same processor — roommates, if you will. Suppose I pack my suitcase the same as you, and then I “train” the processor to always expect sunny days (perhaps I run a simulation program and make every day sunny). The processor will start choosing shorts-and-t-shirt ahead of time. Then, when you wake up, the processor will have already chosen shorts-and-t-shirt; if it is actually rainy, it will put the shorts-and-t-shirt back, but ever-so-slightly disheveled.
    This analogy has gone from tatters to total disintegration — it really doesn’t work here. Your data isn’t simply retrieved from main memory speculatively, it is momentarily parked in cache while the processor follows the wrong branch; it is quickly removed once the processor fixes it error, but I can still figure out what data was there — which means I’ve now stolen your data.
    Meltdown is easier to explain because — Intel’s protestation to the contrary (Meltdown also affects Apple’s processors) — it is due to a design flaw. The processor is responsible for checking if data can be accessed, and to check too slowly, such that the data can be stolen, is a bug. That is also why Meltdown can be worked around in software (basically, there will be an extra step checking permissions before using the data, which is why the patch causes a performance hit).
    Spectre is something else entirely: this is the processor acting 
    as designed
    . Computers do basic calculations unfathomably quickly, but take forever to get the data to make those calculations: therefore doing calculations without waiting for bottlenecks, based on best guesses, is the best possible way to leverage this fundamental imbalance. Most of the time you will get results far more quickly, and if you guess wrong you are no slower than you would have been had you done everything in order.
    This, too, is why Spectre affects all processors: the speed gains from leveraging modern processors’ parallelism and execution speed are so massive that speculative execution is an obvious choice; that the branch predictor might be trained by another user such that cache changes could be tracked simply didn’t occur to anyone  until the last year  (that we know of).
    And, by extension, Spectre can’t be fixed by software: specific implementations can be blocked, but the vulnerability is built-in. New processors will need to be designed, but the billions of processors in use aren’t going anywhere. We’re going to have to muddle through.
     Spectre and the State of Technology 
    I ended 2017 without my customary “State of Technology” post, and just as well: Spectre is a far better representation than anything I might have written. Faced with a fundamental imbalance (data fetch slowness versus execution speed), processor engineers devised an ingenious system optimized for performance, but having failed to envision the possibility of bad actors abusing the system, everyone was left vulnerable.
    The analogy is obvious: faced with a fundamental imbalance (the difficulty of gaining and retaining users versus the ease of rapid iteration and optimization), Internet companies devised ingenious systems optimized for engagement, but having  failed to envision the possibility of bad actors abusing the system  , everyone was left vulnerable.
    Spectre, though, helps illustrate why these issues are so vexing:
    
      I don’t believe anyone intended to create this vulnerability
      The vulnerability might be worth it — the gains from faster processors have been absolutely massive!
      Regardless, decisions made in the past are in the past: the best we can do is muddle through
    
    So it is with the effects of Facebook, Google/YouTube, etc., and the Internet broadly. Power comes from  giving people what they want  — hardly a bad motivation! — and the benefits still may — probably? — outweigh the downsides. Regardless, our only choice is to move forward.
    
    I wrote a follow-up to this article in
    
     this Daily Update
    
    .
   
    
      
         Share 
        
          
              Facebook  
              Twitter  
              LinkedIn  
              Email  
            
          
        
      
    
    
       
     Related
     
    
  
  

" />
    <meta property="og:description" content="
  
     Meltdown, Spectre, and the State of Technology 
    
  Posted on             Monday, January 8, 2018 
            Friday, June 15, 2018 
     Author  by  Ben Thompson   
    
    
  
  
  
    You’ve heard the adage “It’s all 1s and 0s”, but that’s not a figure of speech: the transistor, the fundamental building block of computers, is simply a switch that is either on (“1”) or off (“0”). It turns out, though, as Chris Dixon chronicled in a wonderful essay entitled  How Aristotle Created the Computer  , that 1s and 0s, through the combination of mathematical logic and transistors, are all you need:
    
      The history of computers is often told as a history of objects, from the abacus to the Babbage engine up through the code-breaking machines of World War II. In fact, it is better understood as a history of ideas, mainly ideas that emerged from mathematical logic, an obscure and cult-like discipline that first developed in the 19th century.
    
    Dixon’s essay — which  I’ve linked to previously  — is well worth a read, but the relevant point for this article is perhaps a surprising one: computers are really stupid; what makes them useful is that they are stupid really quickly.
     The Problem with Processor Vulnerabilities 
    Last week the technology world was shaken by  the disclosure of two vulnerabilities in modern processors  : Meltdown and Spectre. The announcement was a bit haphazard, thanks to the fact that the disclosure date was moved up by a week due to widespread speculation about the nature of the vulnerability (probably driven by updates to the Linux kernel), but also because Meltdown and Spectre are similar in some respects, but different in others.
    Start with the similarities: the outcome for both vulnerabilities is the same — a non-privileged user can access information on the computer they should not be able to, like secret keys or passwords or any other type of data owned by other users. This is a particularly big problem for cloud services like AWS, where multiple “tenants” use the same physical hardware:
      
    This multi-tenant architecture is achieved through the use of virtual machines: there is specialized software that runs on a single physical computer that allows each individual user to operate as if they have their own computer, when in fact they are sharing. This is a win-win: single-user computers sit idle the vast majority of the time (they are stupid really quickly), but if multiple users can use one computer then the hardware can be utilized far more efficiently. And, in the case of cloud services, that same concept can be scaled up to millions of physical computers sharing even more fundamental infrastructure like cooling, networking, administration, etc.
    The entire edifice, though, is predicated on a fundamental assumption: that users in one virtual machine cannot access data from another. That assumption, by extension, relies on trust in the integrity of the virtual machine software, which relies on trust in the integrity of the underlying operating system, which ultimately relies on trust in the processor at the heart of a server. From the  Meltdown white paper  ( 
    emphasis mine
    ):
    
      To load data from the main memory into a register, the data in the main memory is referenced using a virtual address. In parallel to translating a virtual address into a physical address, the CPU also checks the permission bits of the virtual address, i.e., whether this virtual address is user accessible or only accessible by the kernel. As already discussed in Section 2.2, 
     this hardware-based isolation through a permission bit is considered secure and recommended by the hardware vendors. Hence, modern operating systems always map the entire kernel into the virtual address space of every user process.
     As a consequence, all kernel addresses lead to a valid physical address when translating them, and the CPU can access the content of such addresses. The only difference to accessing a user space address is that the CPU raises an exception as the current permission level does not allow to access such an address. Hence, the user space cannot simply read the contents of such an address.
    
    The kernel is the core part of the operating system that should be inaccessible by normal users; it has its own memory to store not only core system data but also data from all of the users (for example, when it has to be written to or read from permanent storage). Even here, though, the system relies on virtualization — that memory is the same physical memory users utilize for their applications. It is up to the CPU to keep track of what parts of memory belong to whom, and this is where the vulnerabilities come in.
     Speculative Execution 
    I just referenced three critical parts of a computer: the processor, memory, and permanent storage. In fact, the architecture for storing data is even more complex than that:
      
    
      Registers are the fastest form of memory, accessible every single clock cycle (that is, a 2.0 GHz processor can access registers two billion times a second). They are also the smallest, usually only containing the inputs and outputs for the current calculation.
      There are then various levels of cache (L1, L2, etc.) that are increasingly slower and, on the flipside, increasingly larger and less expensive. This cache is located in a hierarchy: data that is needed immediately will be moved from the registers to L1 cache, for example; slightly less necessary data will be in L2, then L3, etc.
      The next major part of the memory hierarchy is main memory, that is system RAM. While the amount of cache is dependent on the processor model, the amount of memory is up to the overall system builder. This memory is massively slower than cache, but it is also massively larger and far less expensive.
      The last part of the memory hierarchy, at least on a single computer, is permanent storage — the hard drive. Solid-state drives (SSDs) have made a huge difference in speed here, but even then permanent memory is massively slower than main memory, with the same tradeoffs: you can have a lot more of it at a much lower price.
      While not part of the traditional memory hierarchy, cloud applications often have permanent memory on a separate physical server on the same network; the usual tradeoffs apply — very slow access in exchange for other benefits, in this case keeping data separate from its application.
    
    To be sure, “very slow” is all relative — we are talking about nanoseconds here.  This post by Jeff Atwood  puts it in human terms:
    
      That infinite space “between” what we humans feel as time is where computers spend all their time. It’s an entirely different timescale. The book  Systems Performance: Enterprise and the Cloud  has a great table that illustrates just how enormous these time differentials are. Just translate computer time into arbitrary seconds:
      
        
          
            1 CPU cycle
            0.3 ns
            1 s
          
          
            Level 1 cache access
            0.9 ns
            3 s
          
          
            Level 2 cache access
            2.8 ns
            9 s
          
          
            Level 3 cache access
            12.9 ns
            43 s
          
          
            Main memory access
            120 ns
            6 min
          
          
            Solid-state disk I/O
            50-150 μs
            2-6 days
          
          
            Rotational disk I/O
            1-10 ms
            1-12 months
          
          
            Internet: SF to NYC
            40 ms
            4 years
          
          
            Internet: SF to UK
            81 ms
            8 years
          
          
            Internet: SF to Australia
            183 ms
            19 years
          
          
            OS virtualization reboot
            4 s
            423 years
          
          
            SCSI command time-out
            30 s
            3000 years
          
          
            Hardware virtualization reboot
            40 s
            4000 years
          
          
            Physical system reboot
            5 m
            32 millenia
          
        
      
      […]
      The late, great  Jim Gray  …also  had an interesting way of explaining this  . If the CPU registers are how long it takes you to fetch data from your brain, then going to disk is the equivalent of fetching data from Pluto.
        
    
    Gray presented this slide while at Microsoft, to give context to that that “Olympia, Washington” reference. Let me extend his analogy:
    
    Suppose you were a college student interning for the summer at Microsoft in Redmond, and you were packing clothes at home in Olympia. Now Seattle summers can be quite finicky — it could be blustery and rainy, or hot and sunny. It’s often hard to know what the weather will be like until the morning of. To that end, the prudent course of action would not be to pack only one set of clothes, but rather to pack clothes for either possibility. After all, it is far faster to change clothes from a suitcase than it is to drive home to Olympia every time the weather changes.
   
    This is where the analogy starts to fall apart: what modern processors do to alleviate the time it takes to fetch data is not only fetch more data than they might need, but actually do calculations on that data ahead-of-time. This is known as speculative execution, and it is the heart of these vulnerabilities. To put this analogy in algorithmic form:
    
      Check the weather (execute multiple sub-processes that trigger sensors, relay data, etc.)         
          If the weather is sunny, wear shorts-and-t-shirt
          Else wear jeans-and-sweatshirt
        
      
    
    Remember, computers are stupid, but they are stupid fast: executing “wear shorts-and-t-shirt” or “wear jeans-and-sweatshirt” takes nanoseconds — what takes time is waiting for the weather observation. So to save time the processor will get you dressed before it knows the weather, usually based on history — what was the weather the last several days? That means you can decide on footwear, accessories, etc., all while waiting for the weather observation. That’s the other thing about processors: they can do a lot of things at the same time. To that end the fastest possible way to get something done is to guess what the final outcome will be and backtrack if necessary.
     Meltdown 
    Now, imagine the algorithm was changed to the following:
    
      Check your manager’s calendar to see if they will be in the office         
          If they will be in the office, wear slacks and collared-shirt
          If they will not be in the office, wear shorts-and-t-shirt
        
      
    
    There’s just one problem: you’re not supposed to have access to your manager’s calendar. Keep in mind that computers are stupid: the processor doesn’t know this implicitly, it has to actually check if you have access. So in practice this algorithm is more like this:
    
      Check your manager’s calendar to see if they will be in the office         
          Check if this intern has access to their manager’s calendar             
              If the intern has access, access the calendar                 
                  If they will be in the office, wear slacks and collared-shirt
                  If they will not be in the office, wear shorts-and-t-shirt
                
              
              If the intern does not have access, stop getting dressed
            
          
        
      
    
    Remember, though, computers are very good at doing lots of things at once, and not very good at looking up data; in this case the processor will, under certain conditions, look at the manager’s calendar and decide what to wear 
    before it knows whether or not it should look at the calendar
    . If it later realizes it shouldn’t have access to the calendar it will undo everything, but the clothes might end up slightly disheveled, which means you might be able to back out the answer you weren’t supposed to know.
    I already said that the analogy was falling apart; it is now in complete tatters but this, in broad-strokes, is Meltdown: the processor will speculatively fetch and execute privileged data before it knows if it should or not; that process, though, leaves traces in cache, and those traces can be captured by a non-privileged user.
     Explaining Spectre 
    Spectre is even more devious, but harder to pull off: remember, multiple users are using the same processor — roommates, if you will. Suppose I pack my suitcase the same as you, and then I “train” the processor to always expect sunny days (perhaps I run a simulation program and make every day sunny). The processor will start choosing shorts-and-t-shirt ahead of time. Then, when you wake up, the processor will have already chosen shorts-and-t-shirt; if it is actually rainy, it will put the shorts-and-t-shirt back, but ever-so-slightly disheveled.
    This analogy has gone from tatters to total disintegration — it really doesn’t work here. Your data isn’t simply retrieved from main memory speculatively, it is momentarily parked in cache while the processor follows the wrong branch; it is quickly removed once the processor fixes it error, but I can still figure out what data was there — which means I’ve now stolen your data.
    Meltdown is easier to explain because — Intel’s protestation to the contrary (Meltdown also affects Apple’s processors) — it is due to a design flaw. The processor is responsible for checking if data can be accessed, and to check too slowly, such that the data can be stolen, is a bug. That is also why Meltdown can be worked around in software (basically, there will be an extra step checking permissions before using the data, which is why the patch causes a performance hit).
    Spectre is something else entirely: this is the processor acting 
    as designed
    . Computers do basic calculations unfathomably quickly, but take forever to get the data to make those calculations: therefore doing calculations without waiting for bottlenecks, based on best guesses, is the best possible way to leverage this fundamental imbalance. Most of the time you will get results far more quickly, and if you guess wrong you are no slower than you would have been had you done everything in order.
    This, too, is why Spectre affects all processors: the speed gains from leveraging modern processors’ parallelism and execution speed are so massive that speculative execution is an obvious choice; that the branch predictor might be trained by another user such that cache changes could be tracked simply didn’t occur to anyone  until the last year  (that we know of).
    And, by extension, Spectre can’t be fixed by software: specific implementations can be blocked, but the vulnerability is built-in. New processors will need to be designed, but the billions of processors in use aren’t going anywhere. We’re going to have to muddle through.
     Spectre and the State of Technology 
    I ended 2017 without my customary “State of Technology” post, and just as well: Spectre is a far better representation than anything I might have written. Faced with a fundamental imbalance (data fetch slowness versus execution speed), processor engineers devised an ingenious system optimized for performance, but having failed to envision the possibility of bad actors abusing the system, everyone was left vulnerable.
    The analogy is obvious: faced with a fundamental imbalance (the difficulty of gaining and retaining users versus the ease of rapid iteration and optimization), Internet companies devised ingenious systems optimized for engagement, but having  failed to envision the possibility of bad actors abusing the system  , everyone was left vulnerable.
    Spectre, though, helps illustrate why these issues are so vexing:
    
      I don’t believe anyone intended to create this vulnerability
      The vulnerability might be worth it — the gains from faster processors have been absolutely massive!
      Regardless, decisions made in the past are in the past: the best we can do is muddle through
    
    So it is with the effects of Facebook, Google/YouTube, etc., and the Internet broadly. Power comes from  giving people what they want  — hardly a bad motivation! — and the benefits still may — probably? — outweigh the downsides. Regardless, our only choice is to move forward.
    
    I wrote a follow-up to this article in
    
     this Daily Update
    
    .
   
    
      
         Share 
        
          
              Facebook  
              Twitter  
              LinkedIn  
              Email  
            
          
        
      
    
    
       
     Related
     
    
  
  

" />
    
    <meta name="author" content="觀點" />

    
    <meta property="og:title" content="Meltdown, Spectre, and the State of Technology" />
    <meta property="twitter:title" content="Meltdown, Spectre, and the State of Technology" />
    

  <link rel="stylesheet" type="text/css" href="/opinion/style.css" />
  <link rel="alternate" type="application/rss+xml" title="觀點 - 從草根到大師 git.io/JJCxS" href="/opinion/feed.xml" />

  <!-- Social Share Kit CSS -->
  <link rel="stylesheet" href="/opinion/assets/css/social-share-kit.css" type="text/css">
  <link rel="stylesheet" href="/opinion/assets/css/font-awesome.min.css" type="text/css">
  <link rel="stylesheet" href="/opinion/assets/css/bootstrap.min.css" type="text/css">
  <script type="text/javascript" src="/opinion/assets/js/jquery-3.5.1.js"></script>
  <script type="text/javascript" src="/opinion/assets/js/page.js"></script>

</head>

  <body>
    <div class="wrapper-masthead">
  <div class="container">
    <header class="masthead clearfix">
      

      <div class="site-info">
        <h1 class="site-name" style="display: inline-block;"><a href="/opinion/">觀點</a></h1>
        <i class="site-description" style="font-size: 12px;">從草根到大師 git.io/JJCxS</i>
      </div>

      <nav>
        <span id="search-container" >
          <a href="/opinion/tools"><i class="fa fa-bookmark twitter" title="百宝箱"></i></a>
        <a><i class="fa fa-search" title="限前100結果"></i></a><input type="text" id="search-input" placeholder="標題 作者 來源 日期 (17489)"
          style="margin: 10px 0px 0px 0px; height: 30px;width: auto" title="本站最正確的打開方式">
        </span>
        
        
        <a href="/opinion/categories" style="color: Tomato;"><i class="fa fa-tags" title="分类"></i></a>
        
        
        
        <a href="https://be4.herokuapp.com/" style="color: #003366;"><i class="fa fa-comments" title="论坛"></i></a>
        
        
        
        <a href="/opinion/about"><i class="fa fa-info-circle" title="关于"></i></a>
        
        
        <a title="电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇，del同来源旧一篇" onclick="toggle_visibility('help')"><i class="fa fa-question-circle"></i></a>
        <a id="fa-home" href="https://nodebe4.github.io" title="BE4服务列表" onclick="//toggle_visibility('site-list')"><i class="fa fa-home" aria-hidden="true"></i></a>
      </nav>

    </header>
    <div id="site-list" class="tags" style="display: block;text-align: right;border-bottom: 1px solid lightGray;"><noscript><span style="background-color: #e8e8e8;color: #d10000;font-size: 14px;">开启浏览器JavaScript以获取搜索功能和更好的浏览体验</span></noscript></div>
    <p id="help" style="font-size: 14px;display: none;text-align: right;"><span style="color:green;">电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇, del同来源旧一篇</span>; <span style="color:orange">对应触屏FAB：上下右左</span>; 轉Markdown<a href="https://euangoddard.github.io/clipboard2markdown/"><i class="fa fa-file-text-o"></i></a></p>
  </div>
</div>

<script type="text/javascript" >
  function toggle_visibility(id){
    var help = document.getElementById(id)
    if (help.style.display=='none'){
      help.style.display='block';
    }else{
      help.style.display='none';
    }
  }

  const url = "https://nodebe4.github.io/sitelist.json"

  document.addEventListener("DOMContentLoaded", function(event){
    // var homebtn = document.getElementById("fa-home")
    // homebtn.removeAttribute("href")
    var content = document.getElementById("site-list");
    content.innerHTML = ''
    var ul = document.createElement("ul")
    ul.classList.add("label")
    content.appendChild(ul)
    var cnt = 0

    $.getJSON(url, function(allsites) {

      allsites.map(item =>{
        var li = document.createElement('li')
        li.classList.add("tag")
        li.id = 'site-' + cnt
        ul.appendChild(li)
        var a0 = document.createElement('a')
        li.appendChild(a0)
        a0.href = item.url[0]
        var span = document.createElement('span')
        a0.appendChild(span)
        span.innerText = item['name']
        // span.style.backgroundColor = item['background-color']
        // span.style.color='#E4CBC3'
        span.style.color = item['background-color']
        span.style['font-size'] = '14px'
        cnt += 1
        // test_alive(li.id, a0.href)
      })
    })
  })

function test_alive(id, url){
  var divstatus = document.getElementById(id)
  const base = 'https://textance.herokuapp.com/title/'
  var fullurl = base + url
  $.ajax({
      url: fullurl,
      complete: function(data) {
        if (data.responseText.includes('502')){
          // divstatus.style.color='#FBB7B7'
          // divstatus.style.color='gray'
          // divstatus.title = "服务器无响应"
          divstatus.parentNode.removeChild(divstatus)
        }else{
          // divstatus.style.color='#B6FAC8'
          divstatus.title = data.responseText
        }
      }
  });
  return divstatus
}
</script>



    <!-- Left & centered positioning -->

<div class="ssk-sticky ssk-right ssk-center ssk-sticky-hide-xs ssk-group ssk-round">
  
    <a href="https://be4news.pythonanywhere.com/archivenow/ia/https%3A%2F%2Fstratechery.com%2F2018%2Fmeltdown-spectre-and-the-state-of-technology%2F" class="ssk ssk-link" title="存到互联网档案馆" target="_blank"></a>
    <a href="https://www.facebook.com/sharer.php?u=https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/" class="ssk ssk-facebook"></a>
    <a href="https://twitter.com/intent/tweet?url=https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/&text=Meltdown, Spectre, and the State of Technology&hashtags=觀點" class="ssk ssk-twitter"></a>
    <a href="https://reddit.com/submit?url=https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/&title=Meltdown, Spectre, and the State of Technology" class="ssk ssk-reddit"></a>
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/&title=Meltdown, Spectre, and the State of Technology" class="ssk ssk-linkedin"></a>
    <a href="mailto:{email_address}?subject=Meltdown, Spectre, and the State of Technology&body=
  
     Meltdown, Spectre, and the State of Technology 
    
  Posted on             Monday, January 8, 2018 
            Friday, June 15, 2018 
     Author  by  Ben Thompson   
    
    
  
  
  
    You’ve heard the adage “It’s all 1s and 0s”, but that’s not a figure of speech: the transistor, the fundamental building block of computers, is simply a switch that is either on (“1”) or off (“0”). It turns out, though, as Chris Dixon chronicled in a wonderful essay entitled  How Aristotle Created the Computer  , that 1s and 0s, through the combination of mathematical logic and transistors, are all you need:
    
      The history of computers is often told as a history of objects, from the abacus to the Babbage engine up through the code-breaking machines of World War II. In fact, it is better understood as a history of ideas, mainly ideas that emerged from mathematical logic, an obscure and cult-like discipline that first developed in the 19th century.
    
    Dixon’s essay — which  I’ve linked to previously  — is well worth a read, but the relevant point for this article is perhaps a surprising one: computers are really stupid; what makes them useful is that they are stupid really quickly.
     The Problem with Processor Vulnerabilities 
    Last week the technology world was shaken by  the disclosure of two vulnerabilities in modern processors  : Meltdown and Spectre. The announcement was a bit haphazard, thanks to the fact that the disclosure date was moved up by a week due to widespread speculation about the nature of the vulnerability (probably driven by updates to the Linux kernel), but also because Meltdown and Spectre are similar in some respects, but different in others.
    Start with the similarities: the outcome for both vulnerabilities is the same — a non-privileged user can access information on the computer they should not be able to, like secret keys or passwords or any other type of data owned by other users. This is a particularly big problem for cloud services like AWS, where multiple “tenants” use the same physical hardware:
      
    This multi-tenant architecture is achieved through the use of virtual machines: there is specialized software that runs on a single physical computer that allows each individual user to operate as if they have their own computer, when in fact they are sharing. This is a win-win: single-user computers sit idle the vast majority of the time (they are stupid really quickly), but if multiple users can use one computer then the hardware can be utilized far more efficiently. And, in the case of cloud services, that same concept can be scaled up to millions of physical computers sharing even more fundamental infrastructure like cooling, networking, administration, etc.
    The entire edifice, though, is predicated on a fundamental assumption: that users in one virtual machine cannot access data from another. That assumption, by extension, relies on trust in the integrity of the virtual machine software, which relies on trust in the integrity of the underlying operating system, which ultimately relies on trust in the processor at the heart of a server. From the  Meltdown white paper  ( 
    emphasis mine
    ):
    
      To load data from the main memory into a register, the data in the main memory is referenced using a virtual address. In parallel to translating a virtual address into a physical address, the CPU also checks the permission bits of the virtual address, i.e., whether this virtual address is user accessible or only accessible by the kernel. As already discussed in Section 2.2, 
     this hardware-based isolation through a permission bit is considered secure and recommended by the hardware vendors. Hence, modern operating systems always map the entire kernel into the virtual address space of every user process.
     As a consequence, all kernel addresses lead to a valid physical address when translating them, and the CPU can access the content of such addresses. The only difference to accessing a user space address is that the CPU raises an exception as the current permission level does not allow to access such an address. Hence, the user space cannot simply read the contents of such an address.
    
    The kernel is the core part of the operating system that should be inaccessible by normal users; it has its own memory to store not only core system data but also data from all of the users (for example, when it has to be written to or read from permanent storage). Even here, though, the system relies on virtualization — that memory is the same physical memory users utilize for their applications. It is up to the CPU to keep track of what parts of memory belong to whom, and this is where the vulnerabilities come in.
     Speculative Execution 
    I just referenced three critical parts of a computer: the processor, memory, and permanent storage. In fact, the architecture for storing data is even more complex than that:
      
    
      Registers are the fastest form of memory, accessible every single clock cycle (that is, a 2.0 GHz processor can access registers two billion times a second). They are also the smallest, usually only containing the inputs and outputs for the current calculation.
      There are then various levels of cache (L1, L2, etc.) that are increasingly slower and, on the flipside, increasingly larger and less expensive. This cache is located in a hierarchy: data that is needed immediately will be moved from the registers to L1 cache, for example; slightly less necessary data will be in L2, then L3, etc.
      The next major part of the memory hierarchy is main memory, that is system RAM. While the amount of cache is dependent on the processor model, the amount of memory is up to the overall system builder. This memory is massively slower than cache, but it is also massively larger and far less expensive.
      The last part of the memory hierarchy, at least on a single computer, is permanent storage — the hard drive. Solid-state drives (SSDs) have made a huge difference in speed here, but even then permanent memory is massively slower than main memory, with the same tradeoffs: you can have a lot more of it at a much lower price.
      While not part of the traditional memory hierarchy, cloud applications often have permanent memory on a separate physical server on the same network; the usual tradeoffs apply — very slow access in exchange for other benefits, in this case keeping data separate from its application.
    
    To be sure, “very slow” is all relative — we are talking about nanoseconds here.  This post by Jeff Atwood  puts it in human terms:
    
      That infinite space “between” what we humans feel as time is where computers spend all their time. It’s an entirely different timescale. The book  Systems Performance: Enterprise and the Cloud  has a great table that illustrates just how enormous these time differentials are. Just translate computer time into arbitrary seconds:
      
        
          
            1 CPU cycle
            0.3 ns
            1 s
          
          
            Level 1 cache access
            0.9 ns
            3 s
          
          
            Level 2 cache access
            2.8 ns
            9 s
          
          
            Level 3 cache access
            12.9 ns
            43 s
          
          
            Main memory access
            120 ns
            6 min
          
          
            Solid-state disk I/O
            50-150 μs
            2-6 days
          
          
            Rotational disk I/O
            1-10 ms
            1-12 months
          
          
            Internet: SF to NYC
            40 ms
            4 years
          
          
            Internet: SF to UK
            81 ms
            8 years
          
          
            Internet: SF to Australia
            183 ms
            19 years
          
          
            OS virtualization reboot
            4 s
            423 years
          
          
            SCSI command time-out
            30 s
            3000 years
          
          
            Hardware virtualization reboot
            40 s
            4000 years
          
          
            Physical system reboot
            5 m
            32 millenia
          
        
      
      […]
      The late, great  Jim Gray  …also  had an interesting way of explaining this  . If the CPU registers are how long it takes you to fetch data from your brain, then going to disk is the equivalent of fetching data from Pluto.
        
    
    Gray presented this slide while at Microsoft, to give context to that that “Olympia, Washington” reference. Let me extend his analogy:
    
    Suppose you were a college student interning for the summer at Microsoft in Redmond, and you were packing clothes at home in Olympia. Now Seattle summers can be quite finicky — it could be blustery and rainy, or hot and sunny. It’s often hard to know what the weather will be like until the morning of. To that end, the prudent course of action would not be to pack only one set of clothes, but rather to pack clothes for either possibility. After all, it is far faster to change clothes from a suitcase than it is to drive home to Olympia every time the weather changes.
   
    This is where the analogy starts to fall apart: what modern processors do to alleviate the time it takes to fetch data is not only fetch more data than they might need, but actually do calculations on that data ahead-of-time. This is known as speculative execution, and it is the heart of these vulnerabilities. To put this analogy in algorithmic form:
    
      Check the weather (execute multiple sub-processes that trigger sensors, relay data, etc.)         
          If the weather is sunny, wear shorts-and-t-shirt
          Else wear jeans-and-sweatshirt
        
      
    
    Remember, computers are stupid, but they are stupid fast: executing “wear shorts-and-t-shirt” or “wear jeans-and-sweatshirt” takes nanoseconds — what takes time is waiting for the weather observation. So to save time the processor will get you dressed before it knows the weather, usually based on history — what was the weather the last several days? That means you can decide on footwear, accessories, etc., all while waiting for the weather observation. That’s the other thing about processors: they can do a lot of things at the same time. To that end the fastest possible way to get something done is to guess what the final outcome will be and backtrack if necessary.
     Meltdown 
    Now, imagine the algorithm was changed to the following:
    
      Check your manager’s calendar to see if they will be in the office         
          If they will be in the office, wear slacks and collared-shirt
          If they will not be in the office, wear shorts-and-t-shirt
        
      
    
    There’s just one problem: you’re not supposed to have access to your manager’s calendar. Keep in mind that computers are stupid: the processor doesn’t know this implicitly, it has to actually check if you have access. So in practice this algorithm is more like this:
    
      Check your manager’s calendar to see if they will be in the office         
          Check if this intern has access to their manager’s calendar             
              If the intern has access, access the calendar                 
                  If they will be in the office, wear slacks and collared-shirt
                  If they will not be in the office, wear shorts-and-t-shirt
                
              
              If the intern does not have access, stop getting dressed
            
          
        
      
    
    Remember, though, computers are very good at doing lots of things at once, and not very good at looking up data; in this case the processor will, under certain conditions, look at the manager’s calendar and decide what to wear 
    before it knows whether or not it should look at the calendar
    . If it later realizes it shouldn’t have access to the calendar it will undo everything, but the clothes might end up slightly disheveled, which means you might be able to back out the answer you weren’t supposed to know.
    I already said that the analogy was falling apart; it is now in complete tatters but this, in broad-strokes, is Meltdown: the processor will speculatively fetch and execute privileged data before it knows if it should or not; that process, though, leaves traces in cache, and those traces can be captured by a non-privileged user.
     Explaining Spectre 
    Spectre is even more devious, but harder to pull off: remember, multiple users are using the same processor — roommates, if you will. Suppose I pack my suitcase the same as you, and then I “train” the processor to always expect sunny days (perhaps I run a simulation program and make every day sunny). The processor will start choosing shorts-and-t-shirt ahead of time. Then, when you wake up, the processor will have already chosen shorts-and-t-shirt; if it is actually rainy, it will put the shorts-and-t-shirt back, but ever-so-slightly disheveled.
    This analogy has gone from tatters to total disintegration — it really doesn’t work here. Your data isn’t simply retrieved from main memory speculatively, it is momentarily parked in cache while the processor follows the wrong branch; it is quickly removed once the processor fixes it error, but I can still figure out what data was there — which means I’ve now stolen your data.
    Meltdown is easier to explain because — Intel’s protestation to the contrary (Meltdown also affects Apple’s processors) — it is due to a design flaw. The processor is responsible for checking if data can be accessed, and to check too slowly, such that the data can be stolen, is a bug. That is also why Meltdown can be worked around in software (basically, there will be an extra step checking permissions before using the data, which is why the patch causes a performance hit).
    Spectre is something else entirely: this is the processor acting 
    as designed
    . Computers do basic calculations unfathomably quickly, but take forever to get the data to make those calculations: therefore doing calculations without waiting for bottlenecks, based on best guesses, is the best possible way to leverage this fundamental imbalance. Most of the time you will get results far more quickly, and if you guess wrong you are no slower than you would have been had you done everything in order.
    This, too, is why Spectre affects all processors: the speed gains from leveraging modern processors’ parallelism and execution speed are so massive that speculative execution is an obvious choice; that the branch predictor might be trained by another user such that cache changes could be tracked simply didn’t occur to anyone  until the last year  (that we know of).
    And, by extension, Spectre can’t be fixed by software: specific implementations can be blocked, but the vulnerability is built-in. New processors will need to be designed, but the billions of processors in use aren’t going anywhere. We’re going to have to muddle through.
     Spectre and the State of Technology 
    I ended 2017 without my customary “State of Technology” post, and just as well: Spectre is a far better representation than anything I might have written. Faced with a fundamental imbalance (data fetch slowness versus execution speed), processor engineers devised an ingenious system optimized for performance, but having failed to envision the possibility of bad actors abusing the system, everyone was left vulnerable.
    The analogy is obvious: faced with a fundamental imbalance (the difficulty of gaining and retaining users versus the ease of rapid iteration and optimization), Internet companies devised ingenious systems optimized for engagement, but having  failed to envision the possibility of bad actors abusing the system  , everyone was left vulnerable.
    Spectre, though, helps illustrate why these issues are so vexing:
    
      I don’t believe anyone intended to create this vulnerability
      The vulnerability might be worth it — the gains from faster processors have been absolutely massive!
      Regardless, decisions made in the past are in the past: the best we can do is muddle through
    
    So it is with the effects of Facebook, Google/YouTube, etc., and the Internet broadly. Power comes from  giving people what they want  — hardly a bad motivation! — and the benefits still may — probably? — outweigh the downsides. Regardless, our only choice is to move forward.
    
    I wrote a follow-up to this article in
    
     this Daily Update
    
    .
   
    
      
         Share 
        
          
              Facebook  
              Twitter  
              LinkedIn  
              Email  
            
          
        
      
    
    
       
     Related
     
    
  
  

" class="ssk ssk-email"></a>
    <a href="http://pinterest.com/pin/create/link/?url=https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/" class="ssk ssk-pinterest"></a>
    <a href="https://www.tumblr.com/widgets/share/tool?canonicalUrl=https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/&title=Meltdown, Spectre, and the State of Technology&caption=
  
     Meltdown, Spectre, and the State of Technology 
    
  Posted on             Monday, January 8, 2018 
            Friday, June 15, 2018 
     Author  by  Ben Thompson   
    
    
  
  
  
    You’ve heard the adage “It’s all 1s and 0s”, but that’s not a figure of speech: the transistor, the fundamental building block of computers, is simply a switch that is either on (“1”) or off (“0”). It turns out, though, as Chris Dixon chronicled in a wonderful essay entitled  How Aristotle Created the Computer  , that 1s and 0s, through the combination of mathematical logic and transistors, are all you need:
    
      The history of computers is often told as a history of objects, from the abacus to the Babbage engine up through the code-breaking machines of World War II. In fact, it is better understood as a history of ideas, mainly ideas that emerged from mathematical logic, an obscure and cult-like discipline that first developed in the 19th century.
    
    Dixon’s essay — which  I’ve linked to previously  — is well worth a read, but the relevant point for this article is perhaps a surprising one: computers are really stupid; what makes them useful is that they are stupid really quickly.
     The Problem with Processor Vulnerabilities 
    Last week the technology world was shaken by  the disclosure of two vulnerabilities in modern processors  : Meltdown and Spectre. The announcement was a bit haphazard, thanks to the fact that the disclosure date was moved up by a week due to widespread speculation about the nature of the vulnerability (probably driven by updates to the Linux kernel), but also because Meltdown and Spectre are similar in some respects, but different in others.
    Start with the similarities: the outcome for both vulnerabilities is the same — a non-privileged user can access information on the computer they should not be able to, like secret keys or passwords or any other type of data owned by other users. This is a particularly big problem for cloud services like AWS, where multiple “tenants” use the same physical hardware:
      
    This multi-tenant architecture is achieved through the use of virtual machines: there is specialized software that runs on a single physical computer that allows each individual user to operate as if they have their own computer, when in fact they are sharing. This is a win-win: single-user computers sit idle the vast majority of the time (they are stupid really quickly), but if multiple users can use one computer then the hardware can be utilized far more efficiently. And, in the case of cloud services, that same concept can be scaled up to millions of physical computers sharing even more fundamental infrastructure like cooling, networking, administration, etc.
    The entire edifice, though, is predicated on a fundamental assumption: that users in one virtual machine cannot access data from another. That assumption, by extension, relies on trust in the integrity of the virtual machine software, which relies on trust in the integrity of the underlying operating system, which ultimately relies on trust in the processor at the heart of a server. From the  Meltdown white paper  ( 
    emphasis mine
    ):
    
      To load data from the main memory into a register, the data in the main memory is referenced using a virtual address. In parallel to translating a virtual address into a physical address, the CPU also checks the permission bits of the virtual address, i.e., whether this virtual address is user accessible or only accessible by the kernel. As already discussed in Section 2.2, 
     this hardware-based isolation through a permission bit is considered secure and recommended by the hardware vendors. Hence, modern operating systems always map the entire kernel into the virtual address space of every user process.
     As a consequence, all kernel addresses lead to a valid physical address when translating them, and the CPU can access the content of such addresses. The only difference to accessing a user space address is that the CPU raises an exception as the current permission level does not allow to access such an address. Hence, the user space cannot simply read the contents of such an address.
    
    The kernel is the core part of the operating system that should be inaccessible by normal users; it has its own memory to store not only core system data but also data from all of the users (for example, when it has to be written to or read from permanent storage). Even here, though, the system relies on virtualization — that memory is the same physical memory users utilize for their applications. It is up to the CPU to keep track of what parts of memory belong to whom, and this is where the vulnerabilities come in.
     Speculative Execution 
    I just referenced three critical parts of a computer: the processor, memory, and permanent storage. In fact, the architecture for storing data is even more complex than that:
      
    
      Registers are the fastest form of memory, accessible every single clock cycle (that is, a 2.0 GHz processor can access registers two billion times a second). They are also the smallest, usually only containing the inputs and outputs for the current calculation.
      There are then various levels of cache (L1, L2, etc.) that are increasingly slower and, on the flipside, increasingly larger and less expensive. This cache is located in a hierarchy: data that is needed immediately will be moved from the registers to L1 cache, for example; slightly less necessary data will be in L2, then L3, etc.
      The next major part of the memory hierarchy is main memory, that is system RAM. While the amount of cache is dependent on the processor model, the amount of memory is up to the overall system builder. This memory is massively slower than cache, but it is also massively larger and far less expensive.
      The last part of the memory hierarchy, at least on a single computer, is permanent storage — the hard drive. Solid-state drives (SSDs) have made a huge difference in speed here, but even then permanent memory is massively slower than main memory, with the same tradeoffs: you can have a lot more of it at a much lower price.
      While not part of the traditional memory hierarchy, cloud applications often have permanent memory on a separate physical server on the same network; the usual tradeoffs apply — very slow access in exchange for other benefits, in this case keeping data separate from its application.
    
    To be sure, “very slow” is all relative — we are talking about nanoseconds here.  This post by Jeff Atwood  puts it in human terms:
    
      That infinite space “between” what we humans feel as time is where computers spend all their time. It’s an entirely different timescale. The book  Systems Performance: Enterprise and the Cloud  has a great table that illustrates just how enormous these time differentials are. Just translate computer time into arbitrary seconds:
      
        
          
            1 CPU cycle
            0.3 ns
            1 s
          
          
            Level 1 cache access
            0.9 ns
            3 s
          
          
            Level 2 cache access
            2.8 ns
            9 s
          
          
            Level 3 cache access
            12.9 ns
            43 s
          
          
            Main memory access
            120 ns
            6 min
          
          
            Solid-state disk I/O
            50-150 μs
            2-6 days
          
          
            Rotational disk I/O
            1-10 ms
            1-12 months
          
          
            Internet: SF to NYC
            40 ms
            4 years
          
          
            Internet: SF to UK
            81 ms
            8 years
          
          
            Internet: SF to Australia
            183 ms
            19 years
          
          
            OS virtualization reboot
            4 s
            423 years
          
          
            SCSI command time-out
            30 s
            3000 years
          
          
            Hardware virtualization reboot
            40 s
            4000 years
          
          
            Physical system reboot
            5 m
            32 millenia
          
        
      
      […]
      The late, great  Jim Gray  …also  had an interesting way of explaining this  . If the CPU registers are how long it takes you to fetch data from your brain, then going to disk is the equivalent of fetching data from Pluto.
        
    
    Gray presented this slide while at Microsoft, to give context to that that “Olympia, Washington” reference. Let me extend his analogy:
    
    Suppose you were a college student interning for the summer at Microsoft in Redmond, and you were packing clothes at home in Olympia. Now Seattle summers can be quite finicky — it could be blustery and rainy, or hot and sunny. It’s often hard to know what the weather will be like until the morning of. To that end, the prudent course of action would not be to pack only one set of clothes, but rather to pack clothes for either possibility. After all, it is far faster to change clothes from a suitcase than it is to drive home to Olympia every time the weather changes.
   
    This is where the analogy starts to fall apart: what modern processors do to alleviate the time it takes to fetch data is not only fetch more data than they might need, but actually do calculations on that data ahead-of-time. This is known as speculative execution, and it is the heart of these vulnerabilities. To put this analogy in algorithmic form:
    
      Check the weather (execute multiple sub-processes that trigger sensors, relay data, etc.)         
          If the weather is sunny, wear shorts-and-t-shirt
          Else wear jeans-and-sweatshirt
        
      
    
    Remember, computers are stupid, but they are stupid fast: executing “wear shorts-and-t-shirt” or “wear jeans-and-sweatshirt” takes nanoseconds — what takes time is waiting for the weather observation. So to save time the processor will get you dressed before it knows the weather, usually based on history — what was the weather the last several days? That means you can decide on footwear, accessories, etc., all while waiting for the weather observation. That’s the other thing about processors: they can do a lot of things at the same time. To that end the fastest possible way to get something done is to guess what the final outcome will be and backtrack if necessary.
     Meltdown 
    Now, imagine the algorithm was changed to the following:
    
      Check your manager’s calendar to see if they will be in the office         
          If they will be in the office, wear slacks and collared-shirt
          If they will not be in the office, wear shorts-and-t-shirt
        
      
    
    There’s just one problem: you’re not supposed to have access to your manager’s calendar. Keep in mind that computers are stupid: the processor doesn’t know this implicitly, it has to actually check if you have access. So in practice this algorithm is more like this:
    
      Check your manager’s calendar to see if they will be in the office         
          Check if this intern has access to their manager’s calendar             
              If the intern has access, access the calendar                 
                  If they will be in the office, wear slacks and collared-shirt
                  If they will not be in the office, wear shorts-and-t-shirt
                
              
              If the intern does not have access, stop getting dressed
            
          
        
      
    
    Remember, though, computers are very good at doing lots of things at once, and not very good at looking up data; in this case the processor will, under certain conditions, look at the manager’s calendar and decide what to wear 
    before it knows whether or not it should look at the calendar
    . If it later realizes it shouldn’t have access to the calendar it will undo everything, but the clothes might end up slightly disheveled, which means you might be able to back out the answer you weren’t supposed to know.
    I already said that the analogy was falling apart; it is now in complete tatters but this, in broad-strokes, is Meltdown: the processor will speculatively fetch and execute privileged data before it knows if it should or not; that process, though, leaves traces in cache, and those traces can be captured by a non-privileged user.
     Explaining Spectre 
    Spectre is even more devious, but harder to pull off: remember, multiple users are using the same processor — roommates, if you will. Suppose I pack my suitcase the same as you, and then I “train” the processor to always expect sunny days (perhaps I run a simulation program and make every day sunny). The processor will start choosing shorts-and-t-shirt ahead of time. Then, when you wake up, the processor will have already chosen shorts-and-t-shirt; if it is actually rainy, it will put the shorts-and-t-shirt back, but ever-so-slightly disheveled.
    This analogy has gone from tatters to total disintegration — it really doesn’t work here. Your data isn’t simply retrieved from main memory speculatively, it is momentarily parked in cache while the processor follows the wrong branch; it is quickly removed once the processor fixes it error, but I can still figure out what data was there — which means I’ve now stolen your data.
    Meltdown is easier to explain because — Intel’s protestation to the contrary (Meltdown also affects Apple’s processors) — it is due to a design flaw. The processor is responsible for checking if data can be accessed, and to check too slowly, such that the data can be stolen, is a bug. That is also why Meltdown can be worked around in software (basically, there will be an extra step checking permissions before using the data, which is why the patch causes a performance hit).
    Spectre is something else entirely: this is the processor acting 
    as designed
    . Computers do basic calculations unfathomably quickly, but take forever to get the data to make those calculations: therefore doing calculations without waiting for bottlenecks, based on best guesses, is the best possible way to leverage this fundamental imbalance. Most of the time you will get results far more quickly, and if you guess wrong you are no slower than you would have been had you done everything in order.
    This, too, is why Spectre affects all processors: the speed gains from leveraging modern processors’ parallelism and execution speed are so massive that speculative execution is an obvious choice; that the branch predictor might be trained by another user such that cache changes could be tracked simply didn’t occur to anyone  until the last year  (that we know of).
    And, by extension, Spectre can’t be fixed by software: specific implementations can be blocked, but the vulnerability is built-in. New processors will need to be designed, but the billions of processors in use aren’t going anywhere. We’re going to have to muddle through.
     Spectre and the State of Technology 
    I ended 2017 without my customary “State of Technology” post, and just as well: Spectre is a far better representation than anything I might have written. Faced with a fundamental imbalance (data fetch slowness versus execution speed), processor engineers devised an ingenious system optimized for performance, but having failed to envision the possibility of bad actors abusing the system, everyone was left vulnerable.
    The analogy is obvious: faced with a fundamental imbalance (the difficulty of gaining and retaining users versus the ease of rapid iteration and optimization), Internet companies devised ingenious systems optimized for engagement, but having  failed to envision the possibility of bad actors abusing the system  , everyone was left vulnerable.
    Spectre, though, helps illustrate why these issues are so vexing:
    
      I don’t believe anyone intended to create this vulnerability
      The vulnerability might be worth it — the gains from faster processors have been absolutely massive!
      Regardless, decisions made in the past are in the past: the best we can do is muddle through
    
    So it is with the effects of Facebook, Google/YouTube, etc., and the Internet broadly. Power comes from  giving people what they want  — hardly a bad motivation! — and the benefits still may — probably? — outweigh the downsides. Regardless, our only choice is to move forward.
    
    I wrote a follow-up to this article in
    
     this Daily Update
    
    .
   
    
      
         Share 
        
          
              Facebook  
              Twitter  
              LinkedIn  
              Email  
            
          
        
      
    
    
       
     Related
     
    
  
  

&tags=觀點" class="ssk ssk-tumblr"></a>
    <a href="https://buffer.com/add?text=Meltdown, Spectre, and the State of Technology&url=https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/" class="ssk ssk-buffer"></a>
</div>


    <div id="main" role="main" class="container">
      
  <!-- Html Elements for Search -->
  <ul id="results-container" class="searched" style="color: #2980B9;"></ul>

  <script src="/opinion/assets/js/simple-jekyll-search.min.js"></script>

  <!-- Configuration -->
  <script>
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    json: '/opinion/search.json',
    searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a><time>{date}</time><a class="tag">{category}</a></li>',
    noResultsText: '没找到',
    limit: 100,
    fuzzy: false,
    exclude: ['Welcome']
  })

  </script>

      







  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    


  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    



<article class="post">
  <h1>Meltdown, Spectre, and the State of Technology</h1>
  <!-- Look the author details up from the site config. -->
  

  <div>
    <span class="date">
      2018-01-08
    </span>

    <!-- Output author details if some exist. -->
    
      
        <span>
            <!-- Personal Info. -->
            <a  style="font-size:14px;">作者: Ben Thompson</a>
        </span>
      
    


    <ul class="tag">
      <li>
        <a href="https://nodebe4.github.io/opinion/categories/#Stratechery">
          Stratechery
        </a>
      </li>
    </ul>

    
        <span>
            <!-- Personal Info. -->
            <a href="https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/" style="font-size:14px;">原文</a>
        </span>
    

    <span style="float: right;" title="Stratechery的其它文章">
      <a style="font-size: 14px;" rel="nofollow" href="#sametag" class="tags">#Stratechery 的其它文章</a>
    </span>

  </div>

  <div class="entry">
    
    
    
    <article class="post-2990 post type-post status-publish format-standard has-post-thumbnail hentry category-articles topics-cloud-computing topics-processors topics-technologies concepts-privacy concepts-technology-and-society concepts-unintended-consequence companies-intel" id="post-2990">
  <header class="entry-header">
    <h1 class="entry-title" id="meltdown-spectre-and-the-state-of-technology-"> Meltdown, Spectre, and the State of Technology </h1>
    <div class="entry-meta">
<span class="posted-on"> <span class="screen-reader-text"> Posted on </span>           <time class="entry-date published" datetime="2018-01-08T04:21:08-08:00"> Monday, January 8, 2018 </time>
           <time class="updated" datetime="2018-06-15T13:10:03-07:00"> Friday, June 15, 2018 </time>
 </span> <span class="byline"> <span class="author vcard"> <span class="screen-reader-text"> Author </span> by <a class="url fn n" href="https://stratechery.com/author/stratechery/"> Ben Thompson </a> </span> </span>
    </div>
    <!-- .entry-meta -->
  </header>
  <!-- .entry-header -->
  <div class="entry-content">
    <p>You’ve heard the adage “It’s all 1s and 0s”, but that’s not a figure of speech: the transistor, the fundamental building block of computers, is simply a switch that is either on (“1”) or off (“0”). It turns out, though, as Chris Dixon chronicled in a wonderful essay entitled <a href="https://www.theatlantic.com/technology/archive/2017/03/aristotle-computer/518697/"> How Aristotle Created the Computer </a> , that 1s and 0s, through the combination of mathematical logic and transistors, are all you need:</p>
    <blockquote>
      <p>The history of computers is often told as a history of objects, from the abacus to the Babbage engine up through the code-breaking machines of World War II. In fact, it is better understood as a history of ideas, mainly ideas that emerged from mathematical logic, an obscure and cult-like discipline that first developed in the 19th century.</p>
    </blockquote>
    <p>Dixon’s essay — which <a href="https://stratechery.com/2017/the-arrival-of-artificial-intelligence/"> I’ve linked to previously </a> — is well worth a read, but the relevant point for this article is perhaps a surprising one: computers are really stupid; what makes them useful is that they are stupid really quickly.</p>
    <h4 id="the-problem-with-processor-vulnerabilities-"> The Problem with Processor Vulnerabilities </h4>
    <p>Last week the technology world was shaken by <a href="https://security.googleblog.com/2018/01/todays-cpu-vulnerability-what-you-need.html?m=1"> the disclosure of two vulnerabilities in modern processors </a> : Meltdown and Spectre. The announcement was a bit haphazard, thanks to the fact that the disclosure date was moved up by a week due to widespread speculation about the nature of the vulnerability (probably driven by updates to the Linux kernel), but also because Meltdown and Spectre are similar in some respects, but different in others.</p>
    <p>Start with the similarities: the outcome for both vulnerabilities is the same — a non-privileged user can access information on the computer they should not be able to, like secret keys or passwords or any other type of data owned by other users. This is a particularly big problem for cloud services like AWS, where multiple “tenants” use the same physical hardware:</p>
    <p><a href="https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-2.png"> <img alt="" class="aligncenter size-large wp-image-2991" height="480" sizes="(max-width: 640px) 100vw, 640px" src="https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-2-1024x768.png" srcset="https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-2-1024x768.png 1024w, https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-2-300x225.png 300w, https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-2-768x576.png 768w, https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-2-840x630.png 840w" width="640" /> </a></p>
    <p>This multi-tenant architecture is achieved through the use of virtual machines: there is specialized software that runs on a single physical computer that allows each individual user to operate as if they have their own computer, when in fact they are sharing. This is a win-win: single-user computers sit idle the vast majority of the time (they are stupid really quickly), but if multiple users can use one computer then the hardware can be utilized far more efficiently. And, in the case of cloud services, that same concept can be scaled up to millions of physical computers sharing even more fundamental infrastructure like cooling, networking, administration, etc.</p>
    <p>The entire edifice, though, is predicated on a fundamental assumption: that users in one virtual machine cannot access data from another. That assumption, by extension, relies on trust in the integrity of the virtual machine software, which relies on trust in the integrity of the underlying operating system, which ultimately relies on trust in the processor at the heart of a server. From the <a href="https://meltdownattack.com/meltdown.pdf"> Meltdown white paper </a> ( <em>
    emphasis mine
   </em> ):</p>
    <blockquote>
      <p>To load data from the main memory into a register, the data in the main memory is referenced using a virtual address. In parallel to translating a virtual address into a physical address, the CPU also checks the permission bits of the virtual address, i.e., whether this virtual address is user accessible or only accessible by the kernel. As already discussed in Section 2.2, <strong>
     this hardware-based isolation through a permission bit is considered secure and recommended by the hardware vendors. Hence, modern operating systems always map the entire kernel into the virtual address space of every user process.
    </strong> As a consequence, all kernel addresses lead to a valid physical address when translating them, and the CPU can access the content of such addresses. The only difference to accessing a user space address is that the CPU raises an exception as the current permission level does not allow to access such an address. Hence, the user space cannot simply read the contents of such an address.</p>
    </blockquote>
    <p>The kernel is the core part of the operating system that should be inaccessible by normal users; it has its own memory to store not only core system data but also data from all of the users (for example, when it has to be written to or read from permanent storage). Even here, though, the system relies on virtualization — that memory is the same physical memory users utilize for their applications. It is up to the CPU to keep track of what parts of memory belong to whom, and this is where the vulnerabilities come in.</p>
    <h4 id="speculative-execution-"> Speculative Execution </h4>
    <p>I just referenced three critical parts of a computer: the processor, memory, and permanent storage. In fact, the architecture for storing data is even more complex than that:</p>
    <p><a href="https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1.jpg"> <img alt="" class="aligncenter size-large wp-image-2987" height="418" sizes="(max-width: 640px) 100vw, 640px" src="https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-1024x668.jpg" srcset="https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-1024x668.jpg 1024w, https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-300x196.jpg 300w, https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-768x501.jpg 768w, https://stratechery.com/wp-content/uploads/2018/01/Paper.stratechery-Year-One.1-966x630.jpg 966w" width="640" /> </a></p>
    <ul>
      <li>Registers are the fastest form of memory, accessible every single clock cycle (that is, a 2.0 GHz processor can access registers two billion times a second). They are also the smallest, usually only containing the inputs and outputs for the current calculation.</li>
      <li>There are then various levels of cache (L1, L2, etc.) that are increasingly slower and, on the flipside, increasingly larger and less expensive. This cache is located in a hierarchy: data that is needed immediately will be moved from the registers to L1 cache, for example; slightly less necessary data will be in L2, then L3, etc.</li>
      <li>The next major part of the memory hierarchy is main memory, that is system RAM. While the amount of cache is dependent on the processor model, the amount of memory is up to the overall system builder. This memory is massively slower than cache, but it is also massively larger and far less expensive.</li>
      <li>The last part of the memory hierarchy, at least on a single computer, is permanent storage — the hard drive. Solid-state drives (SSDs) have made a huge difference in speed here, but even then permanent memory is massively slower than main memory, with the same tradeoffs: you can have a lot more of it at a much lower price.</li>
      <li>While not part of the traditional memory hierarchy, cloud applications often have permanent memory on a separate physical server on the same network; the usual tradeoffs apply — very slow access in exchange for other benefits, in this case keeping data separate from its application.</li>
    </ul>
    <p>To be sure, “very slow” is all relative — we are talking about nanoseconds here. <a href="https://blog.codinghorror.com/the-infinite-space-between-words/"> This post by Jeff Atwood </a> puts it in human terms:</p>
    <blockquote>
      <p>That infinite space “between” what we humans feel as time is where computers spend all their time. It’s an entirely different timescale. The book <a href="http://www.amazon.com/dp/0133390098/"> Systems Performance: Enterprise and the Cloud </a> has a great table that illustrates just how enormous these time differentials are. Just translate computer time into arbitrary seconds:</p>
      <table>
        <tbody>
          <tr>
            <td>1 CPU cycle</td>
            <td>0.3 ns</td>
            <td>1 s</td>
          </tr>
          <tr>
            <td>Level 1 cache access</td>
            <td>0.9 ns</td>
            <td>3 s</td>
          </tr>
          <tr>
            <td>Level 2 cache access</td>
            <td>2.8 ns</td>
            <td>9 s</td>
          </tr>
          <tr>
            <td>Level 3 cache access</td>
            <td>12.9 ns</td>
            <td>43 s</td>
          </tr>
          <tr>
            <td>Main memory access</td>
            <td>120 ns</td>
            <td>6 min</td>
          </tr>
          <tr>
            <td>Solid-state disk I/O</td>
            <td>50-150 μs</td>
            <td>2-6 days</td>
          </tr>
          <tr>
            <td>Rotational disk I/O</td>
            <td>1-10 ms</td>
            <td>1-12 months</td>
          </tr>
          <tr>
            <td>Internet: SF to NYC</td>
            <td>40 ms</td>
            <td>4 years</td>
          </tr>
          <tr>
            <td>Internet: SF to UK</td>
            <td>81 ms</td>
            <td>8 years</td>
          </tr>
          <tr>
            <td>Internet: SF to Australia</td>
            <td>183 ms</td>
            <td>19 years</td>
          </tr>
          <tr>
            <td>OS virtualization reboot</td>
            <td>4 s</td>
            <td>423 years</td>
          </tr>
          <tr>
            <td>SCSI command time-out</td>
            <td>30 s</td>
            <td>3000 years</td>
          </tr>
          <tr>
            <td>Hardware virtualization reboot</td>
            <td>40 s</td>
            <td>4000 years</td>
          </tr>
          <tr>
            <td>Physical system reboot</td>
            <td>5 m</td>
            <td>32 millenia</td>
          </tr>
        </tbody>
      </table>
      <p>[…]</p>
      <p>The late, great <a href="http://en.wikipedia.org/wiki/Jim_Gray_(computer_scientist)"> Jim Gray </a> …also <a href="http://loci.cs.utk.edu/dsi/netstore99/docs/presentations/keynote/sld023.htm"> had an interesting way of explaining this </a> . If the CPU registers are how long it takes you to fetch data from your brain, then going to disk is the equivalent of fetching data from Pluto.</p>
      <p><a href="http://loci.cs.utk.edu/dsi/netstore99/docs/presentations/keynote/sld023.htm"> <img alt="" class="aligncenter size-full wp-image-2989" height="547" sizes="(max-width: 666px) 100vw, 666px" src="https://stratechery.com/wp-content/uploads/2018/01/storage-latency-how-far-away-is-the-data.png" srcset="https://stratechery.com/wp-content/uploads/2018/01/storage-latency-how-far-away-is-the-data.png 666w, https://stratechery.com/wp-content/uploads/2018/01/storage-latency-how-far-away-is-the-data-300x246.png 300w" width="666" /> </a></p>
    </blockquote>
    <p>Gray presented this slide while at Microsoft, to give context to that that “Olympia, Washington” reference. Let me extend his analogy:</p>
    <p><em>
    Suppose you were a college student interning for the summer at Microsoft in Redmond, and you were packing clothes at home in Olympia. Now Seattle summers can be quite finicky — it could be blustery and rainy, or hot and sunny. It’s often hard to know what the weather will be like until the morning of. To that end, the prudent course of action would not be to pack only one set of clothes, but rather to pack clothes for either possibility. After all, it is far faster to change clothes from a suitcase than it is to drive home to Olympia every time the weather changes.
   </em></p>
    <p>This is where the analogy starts to fall apart: what modern processors do to alleviate the time it takes to fetch data is not only fetch more data than they might need, but actually do calculations on that data ahead-of-time. This is known as speculative execution, and it is the heart of these vulnerabilities. To put this analogy in algorithmic form:</p>
    <ul>
      <li>Check the weather (execute multiple sub-processes that trigger sensors, relay data, etc.)         <ul>
          <li>If the weather is sunny, wear shorts-and-t-shirt</li>
          <li>Else wear jeans-and-sweatshirt</li>
        </ul>
      </li>
    </ul>
    <p>Remember, computers are stupid, but they are stupid fast: executing “wear shorts-and-t-shirt” or “wear jeans-and-sweatshirt” takes nanoseconds — what takes time is waiting for the weather observation. So to save time the processor will get you dressed before it knows the weather, usually based on history — what was the weather the last several days? That means you can decide on footwear, accessories, etc., all while waiting for the weather observation. That’s the other thing about processors: they can do a lot of things at the same time. To that end the fastest possible way to get something done is to guess what the final outcome will be and backtrack if necessary.</p>
    <h4 id="meltdown-"> Meltdown </h4>
    <p>Now, imagine the algorithm was changed to the following:</p>
    <ul>
      <li>Check your manager’s calendar to see if they will be in the office         <ul>
          <li>If they will be in the office, wear slacks and collared-shirt</li>
          <li>If they will not be in the office, wear shorts-and-t-shirt</li>
        </ul>
      </li>
    </ul>
    <p>There’s just one problem: you’re not supposed to have access to your manager’s calendar. Keep in mind that computers are stupid: the processor doesn’t know this implicitly, it has to actually check if you have access. So in practice this algorithm is more like this:</p>
    <ul>
      <li>Check your manager’s calendar to see if they will be in the office         <ul>
          <li>Check if this intern has access to their manager’s calendar             <ul>
              <li>If the intern has access, access the calendar                 <ul>
                  <li>If they will be in the office, wear slacks and collared-shirt</li>
                  <li>If they will not be in the office, wear shorts-and-t-shirt</li>
                </ul>
              </li>
              <li>If the intern does not have access, stop getting dressed</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
    <p>Remember, though, computers are very good at doing lots of things at once, and not very good at looking up data; in this case the processor will, under certain conditions, look at the manager’s calendar and decide what to wear <em>
    before it knows whether or not it should look at the calendar
   </em> . If it later realizes it shouldn’t have access to the calendar it will undo everything, but the clothes might end up slightly disheveled, which means you might be able to back out the answer you weren’t supposed to know.</p>
    <p>I already said that the analogy was falling apart; it is now in complete tatters but this, in broad-strokes, is Meltdown: the processor will speculatively fetch and execute privileged data before it knows if it should or not; that process, though, leaves traces in cache, and those traces can be captured by a non-privileged user.</p>
    <h4 id="explaining-spectre-"> Explaining Spectre </h4>
    <p>Spectre is even more devious, but harder to pull off: remember, multiple users are using the same processor — roommates, if you will. Suppose I pack my suitcase the same as you, and then I “train” the processor to always expect sunny days (perhaps I run a simulation program and make every day sunny). The processor will start choosing shorts-and-t-shirt ahead of time. Then, when you wake up, the processor will have already chosen shorts-and-t-shirt; if it is actually rainy, it will put the shorts-and-t-shirt back, but ever-so-slightly disheveled.</p>
    <p>This analogy has gone from tatters to total disintegration — it really doesn’t work here. Your data isn’t simply retrieved from main memory speculatively, it is momentarily parked in cache while the processor follows the wrong branch; it is quickly removed once the processor fixes it error, but I can still figure out what data was there — which means I’ve now stolen your data.</p>
    <p>Meltdown is easier to explain because — Intel’s protestation to the contrary (Meltdown also affects Apple’s processors) — it is due to a design flaw. The processor is responsible for checking if data can be accessed, and to check too slowly, such that the data can be stolen, is a bug. That is also why Meltdown can be worked around in software (basically, there will be an extra step checking permissions before using the data, which is why the patch causes a performance hit).</p>
    <p>Spectre is something else entirely: this is the processor acting <em>
    as designed
   </em> . Computers do basic calculations unfathomably quickly, but take forever to get the data to make those calculations: therefore doing calculations without waiting for bottlenecks, based on best guesses, is the best possible way to leverage this fundamental imbalance. Most of the time you will get results far more quickly, and if you guess wrong you are no slower than you would have been had you done everything in order.</p>
    <p>This, too, is why Spectre affects all processors: the speed gains from leveraging modern processors’ parallelism and execution speed are so massive that speculative execution is an obvious choice; that the branch predictor might be trained by another user such that cache changes could be tracked simply didn’t occur to anyone <a href="https://www.wired.com/story/meltdown-spectre-bug-collision-intel-chip-flaw-discovery/"> until the last year </a> (that we know of).</p>
    <p>And, by extension, Spectre can’t be fixed by software: specific implementations can be blocked, but the vulnerability is built-in. New processors will need to be designed, but the billions of processors in use aren’t going anywhere. We’re going to have to muddle through.</p>
    <h4 id="spectre-and-the-state-of-technology-"> Spectre and the State of Technology </h4>
    <p>I ended 2017 without my customary “State of Technology” post, and just as well: Spectre is a far better representation than anything I might have written. Faced with a fundamental imbalance (data fetch slowness versus execution speed), processor engineers devised an ingenious system optimized for performance, but having failed to envision the possibility of bad actors abusing the system, everyone was left vulnerable.</p>
    <p>The analogy is obvious: faced with a fundamental imbalance (the difficulty of gaining and retaining users versus the ease of rapid iteration and optimization), Internet companies devised ingenious systems optimized for engagement, but having <a href="https://stratechery.com/2017/the-pollyannish-assumption/"> failed to envision the possibility of bad actors abusing the system </a> , everyone was left vulnerable.</p>
    <p>Spectre, though, helps illustrate why these issues are so vexing:</p>
    <ul>
      <li>I don’t believe anyone intended to create this vulnerability</li>
      <li>The vulnerability might be worth it — the gains from faster processors have been absolutely massive!</li>
      <li>Regardless, decisions made in the past are in the past: the best we can do is muddle through</li>
    </ul>
    <p>So it is with the effects of Facebook, Google/YouTube, etc., and the Internet broadly. Power comes from <a href="https://stratechery.com/2015/aggregation-theory/"> giving people what they want </a> — hardly a bad motivation! — and the benefits still may — probably? — outweigh the downsides. Regardless, our only choice is to move forward.</p>
    <p><em>
    I wrote a follow-up to this article in
    <a href="https://stratechery.com/2018/vulnerabilities-philosophies-and-ad-blockers-intels-response-the-advantage-of-serverless/">
     this Daily Update
    </a>
    .
   </em></p>
    <div class="sharedaddy sd-sharing-enabled">
      <div class="robots-nocontent sd-block sd-social sd-social-icon-text sd-sharing">
        <h3 class="sd-title" id="share-"> Share </h3>
        <div class="sd-content">
          <ul>
            <li class="share-facebook"><a class="share-facebook sd-button share-icon" data-shared="sharing-facebook-2990" href="https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/?share=facebook" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Facebook"> <span> Facebook </span> </a></li>
            <li class="share-twitter"><a class="share-twitter sd-button share-icon" data-shared="sharing-twitter-2990" href="https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/?share=twitter" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Twitter"> <span> Twitter </span> </a></li>
            <li class="share-linkedin"><a class="share-linkedin sd-button share-icon" data-shared="sharing-linkedin-2990" href="https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/?share=linkedin" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on LinkedIn"> <span> LinkedIn </span> </a></li>
            <li class="share-email"><a class="share-email sd-button share-icon" data-shared="" href="https://stratechery.com/2018/meltdown-spectre-and-the-state-of-technology/?share=email" rel="nofollow noopener noreferrer" target="_blank" title="Click to email this to a friend"> <span> Email </span> </a></li>
            <li class="share-end"></li>
          </ul>
        </div>
      </div>
    </div>
    <div class="jp-relatedposts" id="jp-relatedposts">
      <h3 class="jp-relatedposts-headline" id="related"> <em>
     Related
    </em> </h3>
    </div>
  </div>
  <!-- .entry-content -->
</article>


  </div>

  <hr style="border-top:1px solid #28323C;"/>

<font size=2px>
  文章版权归原作者所有。
</font>

<div style="text-align:center"><img width="1px" src="https://i.imgur.com/HSw56Ez.png" alt="二维码分享本站" style="text-align:center"/></div>

  <div id="sametag">
    <h4 style="display: inline-block;">#Stratechery 的其它文章</h4>
    <span>--<a href="https://nodebe4.github.io/opinion/2025-02-27/An-Interview-with-Benedict-Evans-About-AI-Unknowns/">最新</a>-</span>
    <span>-<a href="https://nodebe4.github.io/opinion/2009-12-09/Dropbox_and_the_Entrepreneurs_Blindspot/">最早</a>--</span>
    
      <li>
        <time>2018-01-23</time>
        <a href="https://nodebe4.github.io/opinion/2018-01-23/Amazon_Go_and_the_Future/">
          Amazon Go and the Future
        </a>
      </li>
    
    
      <li>
        <time>2018-01-17</time>
        <a href="https://nodebe4.github.io/opinion/2018-01-17/Facebooks_Motivations/">
          Facebook’s Motivations
        </a>
      </li>
    
    
      <li>
        <time>2017-12-20</time>
        <a href="https://nodebe4.github.io/opinion/2017-12-20/The_2017_Stratechery_Year_in_Review/">
          The 2017 Stratechery Year in Review
        </a>
      </li>
    
    
      <li>
        <time>2017-12-12</time>
        <a href="https://nodebe4.github.io/opinion/2017-12-12/Disney_and_Fox/">
          Disney and Fox
        </a>
      </li>
    
  </div>


  <hr>
  <div class="pagination">
    
      <span class="prev" >
          <a href="https://nodebe4.github.io/opinion/2018-01-08/%E7%8E%8B%E9%95%BF%E6%B1%9F-%E6%94%BF%E6%B2%BB%E9%A2%86%E5%9F%9F%E6%9B%B4%E9%9C%80%E8%A6%81-%E4%BE%9B%E7%BB%99%E4%BE%A7%E6%94%B9%E9%9D%A9/">
            前一篇：王长江：政治领域更需要“供给侧改革”
          </a>
      </span>
    
    
      <span class="next" >
          <a href="https://nodebe4.github.io/opinion/2018-01-09/%E7%A0%B4%E7%A2%8E%E7%9A%84%E5%9B%A2%E7%BB%93-%E9%9D%9E%E6%AD%A3%E5%BC%8F%E5%8A%B3%E5%B7%A5%E7%9A%84%E7%A4%BE%E4%BC%9A%E8%BF%90%E5%8A%A8/">
            後一篇：破碎的团结: 非正式劳工的社会运动
          </a>
      </span>
    

    <script>
    /* post pagination keyboard shortcuts */
    document.body.onkeyup = function(e){
      if (e.keyCode == '37') { window.location = 'https://nodebe4.github.io/opinion/2018-01-08/%E7%8E%8B%E9%95%BF%E6%B1%9F-%E6%94%BF%E6%B2%BB%E9%A2%86%E5%9F%9F%E6%9B%B4%E9%9C%80%E8%A6%81-%E4%BE%9B%E7%BB%99%E4%BE%A7%E6%94%B9%E9%9D%A9/'; } // left arrow key
      if (e.keyCode == '39') { window.location = 'https://nodebe4.github.io/opinion/2018-01-09/%E7%A0%B4%E7%A2%8E%E7%9A%84%E5%9B%A2%E7%BB%93-%E9%9D%9E%E6%AD%A3%E5%BC%8F%E5%8A%B3%E5%B7%A5%E7%9A%84%E7%A4%BE%E4%BC%9A%E8%BF%90%E5%8A%A8/'; } // right arrow key
      if (e.keyCode == '45') { window.location = 'https://nodebe4.github.io/opinion/2018-01-17/Facebooks_Motivations/'; } // insert key
      if (e.keyCode == '46') { window.location = 'https://nodebe4.github.io/opinion/2017-12-20/The_2017_Stratechery_Year_in_Review/'; } // delete key
    };
    </script>
    <link rel="stylesheet" type="text/css" href="/opinion/assets/css/fab.css" />

<div class="fab-wrapper">
  <div class="fab-wheel">
    
    
    
    <a class="fab-action fab-action-1" title="上一篇(热键 &#8594;)" href="https://nodebe4.github.io/opinion/2018-01-08/%E7%8E%8B%E9%95%BF%E6%B1%9F-%E6%94%BF%E6%B2%BB%E9%A2%86%E5%9F%9F%E6%9B%B4%E9%9C%80%E8%A6%81-%E4%BE%9B%E7%BB%99%E4%BE%A7%E6%94%B9%E9%9D%A9/">
      <i>后</i>
    </a>
    
    
    <a class="fab-action fab-action-2" title="下一篇(热键 &#8592;)" href="https://nodebe4.github.io/opinion/2018-01-09/%E7%A0%B4%E7%A2%8E%E7%9A%84%E5%9B%A2%E7%BB%93-%E9%9D%9E%E6%AD%A3%E5%BC%8F%E5%8A%B3%E5%B7%A5%E7%9A%84%E7%A4%BE%E4%BC%9A%E8%BF%90%E5%8A%A8/">
      <i>前</i>
    </a>
    
    
    <a class="fab-action fab-action-3" title="<Stratechery>上一篇(热键 ins)" href="https://nodebe4.github.io/opinion/2018-01-17/Facebooks_Motivations/">
      <i>左</i>
    </a>
    
    
    <a class="fab-action fab-action-4" title="<Stratechery>下一篇(热键 del)" href="https://nodebe4.github.io/opinion/2017-12-20/The_2017_Stratechery_Year_in_Review/">
      <i>右</i>
    </a>
    
  </div>
</div>


  </div>


  

</article>

    </div>

    <div style="z-index:2;">
<script src="/opinion/assets/js/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
  diameter: 56,
  cornerOffset: 20, // px
  id: 'back-to-top',
  backgroundColor: '#ddd',
  textColor: 'red'
})</script>
</div>


    <div class="wrapper-footer" id="footer">
      <div class="container">
        <footer class="footer">
          <img width="200px" src="https://i.imgur.com/HSw56Ez.png" alt="二维码分享本站"/>
<font size=2px>二维码分享本站</font>

<!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

  

  

  
  <li><a href="mailto:beauti4@protonmail.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
  

  

  

  
  <li><a href="https://github.com/NodeBE4/opinion" class="icon-13 github" title="GitHub"><svg viewBox="0 0 512 512"><path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z"/></svg><!--[if lt IE 9]><em>GitHub</em><![endif]--></a></li>
  

  

  

  

  

  
  <li><a href="/opinion/feed.xml" class="icon-21 rss" title="RSS"><svg viewBox="0 0 512 512"><path d="M201.8 347.2c0 20.3-16.5 36.8-36.8 36.8 -20.3 0-36.8-16.5-36.8-36.8s16.5-36.8 36.8-36.8C185.3 310.4 201.8 326.8 201.8 347.2zM128.2 204.7v54.5c68.5 0.7 124 56.3 124.7 124.7h54.5C306.7 285.3 226.9 205.4 128.2 204.7zM128.2 166.6c57.9 0.3 112.3 22.9 153.2 63.9 41 41 63.7 95.5 63.9 153.5h54.5c-0.3-149.9-121.7-271.4-271.6-271.9V166.6L128.2 166.6z"/></svg><!--[if lt IE 9]><em>RSS</em><![endif]--></a></li>
  

  

  

  

  

    
</ul>





<p><span style="color:blue">内容每小时更新一次.</span> Powered by <a href="https://github.com/AWEEKJ/kiko-now">Kiko Now</a> & <a href="https://github.com/gitalk/gitalk">Gitalk</a> & <a href="https://github.com/duty-machine/news">duty-machine</a>, 站务 <a href="https://be4.herokuapp.com">NodeBE4</a>（<span style="color:red">被墙</span>）</p>





        </footer>
      </div>
    </div>

    



  </body>
</html>
