<!DOCTYPE html>
<html>
  <head>
  <title>利求同：隐私的未来 – 觀點 – 從草根到大師 git.io/JJCxS</title>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="
  

  
  
  
    
       利求同：隐私的未来 
      
        By:  利求同  . 2018-6-5.  7,019 
      
    
    
      “秘密是撒谎，分享是关怀，隐私是偷窃。”
         这是美国科幻作家埃格斯（Dave Eggers）对未来的大胆想象。他的小说《圆圈》（  
      The Circle
       ）拍了  电影  ，这句话是影片里面同名超级公司的训言，同公司建筑的极简主义风格一起，接受“吸科技”的瘾君子朝拜。那里，我们习以为常的道德规范被颠倒了，做成新的信条：藏着隐私是严重的人格缺陷，上缴个人信息等于实现人生自由，光大“分享主义”美德；而保护隐私就视同盗窃，要受新人类的唾弃，并交给新法律制裁。
      隐私，能如此激发作家的想象，应该说是物联网智能时代的一个标记。不过，作为隐私的法定业主，我们得感激埃格斯先生的慷慨。因为在他的超级智能化的未来，隐私仍是有价值的，且依法享有平等的保护。人们只需修正价值观，将隐私从“私”和“隐”的疆域中剥离，转化为信息/数据财产，就能继续熟悉的生活了。当然，这新财产总是落在了别人，例如圆圈公司的手里，留给我们个人的，只是生产和再生产即奉献隐私的许可，人格权的一具空壳。但权利的空壳也是权利，也能给人带来安慰，因而是促进社会和谐美丽所不可少的一项制度。
      事实上，这隐私的未来已经到来。做一个透明人，自愿或被迫交出隐私，供人牟利，业已是生活常态了。只是，价值观的修正跟社会道德转型尚待完成。转型时期，还会有人呼吁，试图保护隐私；隐私的归属和使用上的冲突，却日益频发而尖锐起来。这是因为，在资本当道的条件下，隐私同分享有着不可调和的矛盾。最近脸书在美国乃至全球受到质疑，就是生动的例证。国会一边吵架，一边调查，俄国是否介入或干扰了美国大选，脸书却被爆料曾泄露8,700万用户的个人信息，给一家英国公司。脸书声称，这些用户信息是第三方以“不正当方式”获取的。小扎亲自出面，向公众道歉，保证今后严加管理。殊不知，早在二〇一一年，脸书就用户信息泄露事件做出过几乎同样的承诺。而那承诺之所以未能兑现，是因为无法兑现；实际上，国家法律也不允许兑现。现在的商业模式和残酷的产业竞争，有哪一家网络企业，包括电商大鳄，不是靠挖掘买卖用户信息赚钱的？手里的用户隐私越多，市场就越大，利润就越高。假如隐私当真严加保护，不就等于支柱产业集体自杀了？   
      但是，真正的问题还不是几家大企业的利润多寡。关键在于，这事关乎我们的道德价值和理性选择：人工智能（AI），这一人类引以为傲的创造，信息技术的高峰，很可能与保护隐私是格格不入的。AI以高效、优化为目标，追求的是优于人脑的超级硅基智能。在那个智能体系中，信息是基本元素，是一切事物和生命的记录、编辑与展开。人，整体而言，跟任何碳基物、无机物一样，只是一个信息集。而隐私，进入大数据时代，作为一种游离于人类整体信息集边缘的个体特征，就“过于人性”了——承载了太多的价值立场和法律风险。保护隐私，人类信息集就变得坑坑洼洼，不好用了，所以亟需优化、标准化、去风险化。换言之，隐私成了硅基智能的障碍，是必须清除的杂音；非如此，人类不能同AI结合而融入未来。
      于是，我们不得不直面那一种可能，即隐私的终结。我们必须思考：如果隐私终结，人类将如何生存。
      
      
     一、隐私的可隐性
    
      研究一事物的终结，需要从其兴衰的条件和过程中寻找原因。那么，隐私是因何而来的呢？它又怎样塑造了我们的日常生活，它的消解意味着什么？这些问题的答案至关重要。
      历史地看，隐私是人类对自身生存状态的一种描述，既是社会的客观存在，也是道德伦理的主观认知，因而承载着情感和价值判断。关于隐私，学说繁多，实践更是千姿百态。但万变不离其宗，都包含两个基本要素：一、人的个体有别于群体/社会之公，称之为“私”；二、私的领域，时而需要隔绝于公，视之为“隐”。可以说，隐私的观念，其被社会认可而纳入“私”的范畴，乃是因“公”而生，而获得价值的。隐私既是私与公有别或对立的产物，也是公私赖以共存的条件。
      有学者认为，隐私源于人的动物性。人是独立的个体，同时又是群居动物。人在群体中生活，繁衍生息需要一定的私密空间和时间，才能建立亲疏有别的家庭跟社会关系，私与隐便在其中了。文明开化以后，隐私的观念和习惯，更是人类高级智力活动如宗教、艺术、政治、经济等的产物。渐渐地，隐私就演变为一种个体与群体的生活伦理，超越动物本能，而复杂精致起来，终于成了社会秩序的一根支柱（卫斯汀，1967）。
      这公私对应关系, 早在古希腊，亚里士多德就注意到了。他提出区分家室私事（the oikos）和城邦公务（the polis）这一对范畴的哲学命题，并讨论了自愿行为的概念。由此开启了一个漫长的学术传统，探究隐私同自由意志、自我意识以及自由人格的关系。自由意志是人自主选择而行动的一种能力。所以通常，只有自由意志下的行为，才当得起相应的法律责任和道德评价，无论赏罚、毁誉、愧疚。同理，有了自由意志，教导、说服、审议、禁止、判决等社会机制才能运作。而自由意志的产生和行使，是离不开隐私的环境的。首先，有了隐私，人才能培育道德自我意识，即充分意识到自己与行为后果的联系，即“我”是“我的行为”的“动力因”（efficient cause），从而能够自觉承担后果责任。于是，才产生了对行动的自主选择的心理需求，自由意志才得以培育。所以，没有隐私，就没有自由意志。
      更重要的是，第二，隐私所要求的社会认可同保护，其实是以自由意志，即人对他人和社会负责的能力，为对价的。换言之，消灭隐私，就是消灭人类个体负责的能力。因为，隐私的存在，不仅是自由意志生成和行使的条件，也是个体接受社会评价、承担社会义务的前提。反之，若无隐私，自我意识跟自由意志就失去了植根的土壤，社会评价和个体责任就无所依托。
      如此，私与公共存而辩证统一，我们所知的人类社会及其道德伦理制度，都包含了对隐私和自由意志的认可，虽然程度不一。社会承认并尊重个人（自由人）享有一定的隐私权益，并且或多或少，限制他人（包括政府、企业、团体）对个人信息的索取和使用。相应地，社会要求个人为享有隐私，或他人的不知情、不得干预而付出对价，即为自己的选择和言行负责。也就是说，隐私，作为具有道德价值的利益，是人格尊严的先决条件，也是社会组织、道德伦理、法律问责机制的一块基石。一八九〇年，美国法学家沃伦（Samuel Warren）和布兰代斯（Louis Brandeis）发表了题为“  隐私权  ”的著名论文，第一次系统阐述了所谓“独处的权利”，尝试厘清隐私保护的法律学说和适用规范。隐私权的设立与发展，极大地加强了人们的隐私意识。隐私成了公民的基本权益，享有隐私是现代社会理所当然的一项个人自由；保护隐私，即保护人的尊严，保护我们唯一的生活世界。
      然而今天，这唯一世界，正受到全方位的挑战。随着新型信息技术的迅猛发展和智能终端的普及，隐私首当其冲。一不留神，隐私已是千疮百孔，被那无所不能、无处不在的信息工具盯住了。人们的一举一动，每一个闪念都处于监控之下，不啻一个个透明人。要躲避监控而“独处”，过“正常”日子，几乎不可能了。有史以来第一次，隐私制作成了商品，大规模地买卖。而隐私一旦商品化，不同社会阶层和集团便生出相互冲突的利益诉求，关于隐私的社会共识就名存实亡了。
      表面上，个人似乎仍是隐私的所有者或法律上的主体，对隐私的动物性需求也未变。基于隐私和自由意志的社会道德依旧，保护隐私的法规都好好的；毋宁说，新制定的保护措施越来越严格，更上一层楼了。可是仔细观察，这些未变的方面都不再重要，重要的却彻底变样了：信息技术的“天网”已经布下，隐私无处可藏了！所以，尽管法律规定，隐私应当保护，那藏不住的私，是不成其为隐私的。这样看来，“可隐而不可知”是捍卫隐私的关键。易言之，隐私的成立和维护，可隐性是一项必要条件。因为，破坏了隐，也就同时取消了私，即公私的界限。
      这必要条件遭到破坏，隐私变得可知而失控，正是当下隐私困局的症结所在。一切隐私问题的探讨和对策研究，都不能绕开这一现实。
      
      
     二、信息化和隐私困局
    
      信息时代的大势，是隐私的隐秘性趋近消失。结果，直接危及隐私的两要素，公私有别和私的自处。其始作俑者，叫作隐私的信息化或数码化：隐私被信息技术重新包装，放入虚拟电子黑箱，隔绝于人的感官，被“稀释”处理之后，以“中性化”的数据再现。然而，隐私和信息数据是极不协调的两极。数据是技术产品，往往视为客观中性，外延开放包容；隐私却充满了道德价值，属于人类自我意识的范畴，是主观而收敛排他的。当“隐私数据”被捆绑成一个复合概念，这种不协调就被强行抹去，为隐私数据化，继而商品化铺设通道，隐私的天地就彻底改变了。很快，人们开始接受一种全新的生活方式：零隐私世界。
      我们的观察，可以从隐私的必要条件“可隐性”入手。传统上，关于可隐性的讨论不多。这不是疏忽。从前，日常生活中的隐私，可隐性一向不是问题。仿佛“造物”一开始就恩赐了隐私，让人行使自由意志。人类的感官，获取外界信息的能力有限，眼耳鼻口舌，加上皮肤，远不如许多动物的敏锐好使。一层纸，一段距离，几天的间隔，就足以阻断外界信息的感应接收。而我们引以为傲的大脑，相对于别的动物可称发达，但信息存储的可靠性及处理速度，都很不理想；稍微过量，复杂一点，便束手无策。这就使得个人信息不难保持隐秘。例如，说话的声音跟表情，是瞬间即逝的，通常只有近距离耳闻目睹，才能得知。又如，DNA和脑电波，藏在生物密码中，人的感官无法直接辨认、破译或记录。
      所以，私的自处而有别于公，生活中不许外人窥探隐私，是自然而然形成习惯和道德规范的。正是这种合乎“人的尺度”的可隐性，成全了隐私，让人当上自己隐私的守卫，从而整个社会有了维护隐私的意愿，在道德也在法律层面。这么看，人之享有隐私，藉其培育自由意志，不仅是出于传统的道德选择，还有赖于客观上隐私信息往往具有较高的隐秘性。换一角度，隐私之能够获得保护，在一定程度上也是人们对其可隐性特征的一种认知和回应。
      假如人类满足于“造物”的馈赠，不去触动维护隐私的各样屏障，隐私就可以保持可隐而安全。可是，人类好奇，总想探求新知，创制工具，发现世界的奥秘。终于，到了物联网智能时代，隐私的传统屏障坍塌了。生活完全变了，人必须时刻披露个人信息。从农贸市场买菜用微信支付，到旅游点门票的脸像识别；从政府联网办公，到银行电子转账；从百度搜索，到芝麻信用评分和信息诈骗；还有街头巷尾的摄像头，低头族的手机，直至谷歌眼镜、扫地机器人、汽车传感器、植入手臂的上班打卡芯片……个人信息的收集监控不放过生活的任何一个环节。伴随技术进步，隐私的疆域大大拓展了，连基因信号和下意识的意念，也被挖掘了纳入个人信息。信息化的隐私，是信息爆炸，需要超级计算机来处理，接受各类算法的深度分析，以便追踪、模拟、预测人们的思想和行动。隐私不再可隐。私的自处，公私有别，变得越来越不现实了。
      一般认为，人们尊重隐私，本身便是道德选择。然而在网络世界，隐私的物理载体形态同其他信息并无两样。无论我们的银行存款、股票交易，还是DNA遗传指令、生理特征，都已经化作“0”和“1”的数码序列，由算法处理、电脑存储。那里，隐私的内涵是隐没了的，不会影响技术系统的运作。而隐私的数码序列外形，却丝毫不能出错，否则系统就会罢工。久而久之，信息化的隐私化身为数据而“中性化”，卸下了道德伦理的约束，自由了。
      隐私信息化，带来两个严重后果：一是隐私脱离主体，超越时空，永久地驻扎在信息工具里。人失去了对自己隐私的控制，而受制于信息工具及其主人。第二，电子数码的信息密度低，噪音强，体量庞大，就像一片茂盛的原始丛林，遵循机器的组织原则，虚拟黑箱运作。人自身的信息处理能力对于如此巨大的数据集，是束手无策的，只能依赖机器。而机器依赖性越高，隐私数据的收集者/掌控者的话语权就越大，个人的谈判力就越低。于是，信息社会里，隐私开始自愿或被迫地从“私”（如消费者）向“公”（如商家）流动，在“公”领域快速而大规模聚集，并按照信息工具主人制定的规则，嵌入人们的日常生活。比如，自从社交网站普及，我们的思想表达、兴趣好恶，连同亲友信息就被平台电商收集起来清洗，成了后者的数据财产。接下去的数据交易，则进一步模糊了信息的属性；隐私本身，也因为在公私之间频繁穿梭而不再“纯粹”，虽然仍指向个人或群体，例如网购者/买家的行为与需求信息，同卖方的交易规则交叉互动而产生的信息集；又如，免费使用搜索器生成的数据。这时，个人维护隐私的意愿就显得不那么理直气壮，而难以坚持，直至隐私与道德价值脱钩。如此，私与公这对经典范畴开始游移不定，公私间界限模糊起来，隐私就无处落脚了。
      这就是隐私信息化带来的最严峻的挑战。面对挑战，作为拥有自由意志的人类整体，我们仍有机会做出选择，重建隐私的屏障。然而，新经济选择了隐私的商品化，添上了压垮隐私的最后一根稻草。
      
      
     三、隐私商品化和法律保护的迷思
    
      隐私商品化，标志着资本主义世界对隐私态度的质的变化，也是信息社会转型期矛盾的一个焦点。隐私有用有市，不是新发现。但隐私既是自由人格的条件，也是人的软肋，需要精心呵护。所以，传统道德讲求节制，是包括尊重隐私在内的；拿自己或他人的隐私做交易，就更是可耻了。道德加上信息能力有限，可谓双重的约束，隐私才能一路平安地走来。
      现在，智能终端的天网建成，迅速消解了这两道护卫，把蕴藏在隐私中的经济价值和社会控制力裸露了。这大大刺激了隐私的商业挖掘。人们找出各种正当化的理由，隐私淘金热就像放出笼子的野兽，失控了。个人信息充斥了商品市场，在经济生活中占有越来越大的比重。所谓智能经济，几乎所有最赚钱的企业都在挖掘使用和买卖隐私，不论谷歌、脸书、百度跟阿里巴巴。打开脸书，看看你自己上缴的信息吧：照片视频，留言打招呼的就不说了，每天的生活细节、消费习惯、工作安排，亲友往来等等，事无巨细，连你自己都没注意或忘记了的，统统记录在案。谷歌占有的信息集就更庞大了。这些网络巨头深知，隐私就是财富。于是，隐私被冠以新的身份：以市场需求来定价交易的商品。
      既是商品，就免不了推向市场，“公平”竞争。站在市场经济的立场，挖掘隐私，消费隐私，完全符合发展经济的政策目标。这样一来，尊重隐私、维护隐私的道德和技术屏障，因为有碍市场经济，反而处境尴尬了。资本的策略，是把收集个人信息跟服务的便利、高效、创新挂钩；将分享隐私和焕然一新的消费者感受等同。在饱和的宣传攻势下，商家和政府采集使用个人信息，几乎没有任何阻力，还美其名曰：消费者同商家双赢，老百姓和国家双赢。可是，双赢是市场赢家的说辞；凡是双赢的交易，桌面下面总有一方或第三方要付出代价。智能经济的代价，便是终端用户/消费者交出隐私。表面上，提交隐私信息换取服务和便利，对人只有好处，但其损害后果是潜在或滞后的，包括未来就业发生困难，突然被拒绝医疗保险，或者遭受价格歧视、信用误导（参见拙文《  交出了隐私，再掏空钱袋  》），直至削弱人们负责任的能力或自由意志。
      最近美国一个例子，为此做了绝妙的脚注。二〇一七年三月，国会投票，封杀了联邦通讯委员会（FCC）年前通过的《互联网隐私规则》（IPR）。《规则》是为保护网络用户的隐私而订立的，限制了网商使用和“分享”即出售用户的网上行为信息。诡异的是，封杀理由与保护隐私毫不搭界，而是平衡网商的利益，保障市场的公平竞争。也就是说，围绕《规则》的利益较量，用户的隐私权益根本没在考虑之列。更有甚者，国会还表决禁止FCC今后颁布任何类似的保护用户隐私的法规。据说，这么做是有经济学依据的。大名鼎鼎的波斯纳法官曾著文阐述：保护个人隐私经常是低效的，而特殊保护又没有必要。以经济学观之，商家的“隐私”或商业秘密比用户隐私更有理由受保护（  波斯纳，1981  ）。据此逻辑，与其加强隐私保护，不如促进商家的公平竞争，总效益更高。这便是隐私沦为市场交易的商品，必须面对的利益与辩白。尤其令人担忧的是，在道德伦理和技术手段都败下阵来的今天，法律已是捍卫隐私的最后一道脆弱的防线。
      隐私法如此不堪一击，并不奇怪。立法向来是社会各方利益集团谈判妥协的产物，一般总是向强势方倾斜。如果遵循“经济规律”即市场信条来制定规则，法律就不能妨碍“正常”的商品交换，尤其是实用价值高、市场需求大的商品。而隐私早成了信息市场的宠儿。君不见，个人行为信息支撑着精准投放广告、区别定价；指纹和刷脸，方便了身份识别跟信用追踪；DNA信息则可帮助保险公司甄别投保人风险。难怪隐私保护变得缩手缩脚了，因为所有的强势利益集团都要求法律承认，商家收集个人信息，做成商品，就是科学、正当、高效，故而应当支持。于是，基于技术操作规程，法律将获取和使用隐私分成两类：合法、非法。例如，黑客为非法，因为没有向官方注册；但社交和购物网站合法，只需设置用户选择及相关提示。
      如此立法执法，造成一个假象：仿佛合法取用隐私对人无害，可以放心“分享”。唯有非法入侵才是隐私遭破坏的原因和隐患，才会影响我们的正常生活。所以只消立法禁止、惩罚隐私数据的盗窃泄漏和非法买卖，我们的隐私就安然无恙了。
      这当然是自欺欺人。首先，常识告诉我们，媒体经常报道的个人和团伙盗卖个人信息，由于明显违法，偷偷摸摸见不得人，是撼动不了隐私的道德地位的。真正的威胁来自合法的隐私收集和商品化交易，因为那是系统的规模化的受保护市场行为。那些网络平台和产业巨头，大大小小的网站、店家、服务商，日复一日、年复一年地依法获取加工隐私“原材料”，才是对隐私的最大伤害。其次，法律上那一堆看似细致入微的隐私保护条款，不仅对黑箱操作的“漏洞”防不胜防，还是商家的免责保护机制。大数据AI等信息技术日新月异，黑箱操作是设计使然，关乎效率和商业技术秘密。故有评论认为，提高操作透明度，让信息系统内隐私数据的来龙去脉受监督，有助于保护隐私。欧盟最近颁布的《一般数据保护条例》（GDPR) ，添加了条款，要求算法自动决策的使用者为决策给出解释。这是目前为止，对黑箱现象做出的最严格限制。也许会有一定的效果，但《条例》依然回避了隐私商品化问题，而把注意力导向透明度。这是意味深长的。再看脸书，当它的保护隐私设置被合法或不当“攻破”，造成海量用户信息“泄漏”，面对公众舆论跟政府监管部门的压力，确实，老板公开道歉了，保证采取补救措施，提高透明度，甚至答应让用户看到脸书为广告商提供的自己的画像（profile)。但是，它没忘记重申一句：精准投放广告的商业模式不变。
      商品化成为定局，隐私脱离主体，被合法挖掘追踪分析，广泛用于解读并预测、规制人的欲望、想法和行动，人与隐私的关系就变了。隐私主体失去了话语权，不再是自己隐私的主人和守护者（马丁，1971）。鉴于个人信息的巨大经济价值和政治红利，法律别无选择，只能承认或默许隐私商品化。而公共议题就转变为：谁可以“合法”占有商品化的果实，即商业利益的竞争和垄断。所以，合法或是非法，法律都不可能还人类以隐私之安宁。
      法律保护的效用如此之低，为什么各国，尤其是发达经济体，还在不断强化隐私权的立法和宣传？原因很简单，那是政府部门同立法者目前唯一能做，而不影响“大局”的事情。当然，那也是业界巨头所希望的。比如小扎，今年三月接受CNN采访，就明确邀请国会立法，规制社交网站，说：问题不是该不该规制，而是什么是正确的规则。
      资本非常清醒：隐私关乎人的责任能力，占有隐私并获得保护，就要承担相对应的社会责任。当人们交出隐私（无论自愿或不知情），让商家牟利或政府监管，个人的自由意志选择范围便相应地缩小了。人的自主选择越少，承担责任的能力也越小。反之，商家和政府获取的隐私越多，对用户跟社会的控制力也越强。隐私易手，对应的社会责任并不会消失，是需要重新分配的。而且不仅是责任，还是社会风险管理机制的全盘安排。但市场经济是自利者的王国，资本拿隐私赚大钱，却无意承担附着于隐私的社会责任。这就是为什么，他们一边推动隐私商品化，一边在媒体和立法层面，大声疾呼保障隐私。他们企图让人相信，尽管隐私化作他人财产已是生活常态，原始隐私权仍在自己手中，并受到前所未有的法律保护。只需发扬分享的美德，就会得到最佳补偿，即生活便利。巨头们直言不讳，希望失去隐私的人们一如既往地承担行为主体的责任，而掌控隐私的唱唱法律保护的高调，即可免责而享受用户“分享”的馈赠。
      这，应该就是埃格斯先生设想的零隐私未来的起点同终线。无独有偶，脸书老板早在二〇一〇年就说过，我们的隐私观过时了，  隐私“不再是社会规范”  。大家不仅乐于分享各种信息，而且喜欢向越来越多的陌生人开放自己，“促成了新的社会规范”（约翰逊, 2010）。是的，只要巨头们奉行《圆圈》里的那句台词：知道（隐私）好。知道一切（隐私）更好！法律就救不了隐私。
      
      
     四、隐私终结，意味着什么？
    
      说到这里，隐私经过信息社会商业化的洗礼，命运只有一个去向——走向终结！
      也许，一些占有者以为，自己可以是隐私终结的例外，甚而能够在支配他人隐私的同时，继续保有自己的隐私？然而，人类的总命运是谁也逃不脱的。从目前AI的发展势头看，我们不得不警惕，一种智力优于人类，且具有“自由意志”的独立物种出现。届时，机器人未必“甘当”人类肢体和心智的延伸，而人类却要依靠它才能生存。因此，隐私危机必须放在人机关系中去思考、规划。个人信息的网络储存越多，分析工具越精致高效，硅基智能成长为独立物种而摆脱人类管控的步伐，就会越快。当AI提升至通用智能，能够在多个领域自我学习，不再需要人的知识连同隐私当它的学习素材，一如自学围棋、碾压人类顶级大脑的“阿尔法零”，那一天，将奏响隐私的挽歌。
      不过，隐私的终结，并不意味着人类终结。归根结蒂，人是可以零隐私地活着的。迄今为止，隐私对于人类重要，是因为人受制于较低的信息能力，亦即人类为自己安排了那样的生活秩序。所以一方面，隐私是人类高级智力活动的产物，体现了人对自身价值的期待和尊重；另一方面，一旦人类实现“自我超越”，造出通用人工智能（AGI），让机器取代自己思考、劳动、创造，后隐私时代便降临了。
      进入后隐私时代，人类社会现存的经济基础和上层建筑必然失效了。人类将怎样生活？没有历史经验，没有参照物，很难想象。但有三点可以预期：
      一、那将是一种没有自觉自愿，不知何为荣辱问责，但高效而标准化的低智低能的生活秩序。那里，隐私失去了意义。它不再能培育自由人格，因为系统中没有自由意志的位置。它不再是社会责任的对价，因为人无须自由选择自主行动而承担责任。它也不再是智力活动的衍生品，因为人类主动放弃了发展智力的努力，满足于在无限优化了的天网下执行指令。
      二、社会的中心不再是人与人的关系，而是人机关系和机机关系。人类不复为地球的主人，反倒有可能变成硅基智能系统的累赘。不是有AI专家预测，二十五年后，无人驾驶技术成熟，人类将被禁止驾车上路。无人驾驶的交通系统，其交通规则、道路设计、社区安排等，都是不许出错的。人类驾驶只会破坏科学设计的完美，引发交通事故，降低行车效率。实际上，排斥人类参与、删除人类个性，那样的硅胶智能世界，才可能是高效简洁、完满无缺的一个大“圆圈”。
      三、人类世界本身，共产主义或许是唯一的选项。因为机器人治下，人不但没有了隐私，分工也已消失。所有的个体都集合于一个总体，个人自由即全体的自由，我为人人即人人为我（  冯象，2017  ）。
       人工智能的先驱，已故的麻省理工学院教授明斯基（Marvin Minsky）说过：有朝一日，当我们掌握了建造智力远胜人类的机器的知识，就不得不面对一个奇特的问题，那就是：该不该建造？我很幸运，因为我可以把这一困难的选择留给后人。但我相信，他们不会建造，除非找到很好的理由（  明斯基，1982  ）。明斯基还曾经对深度学习神经网络技术做出悲观的描述（《认知器演算法》，1969, 1987），他的观点被认为阻碍了AI发展达半个世纪之久，因而颇受诟病。但我想，换个角度，这也许是教授对人类最大的贡献：为我们做好准备迎接机器人时代，赢得了宝贵的时间。
      明斯基的智慧提醒我们，对隐私应取审慎节制的态度。也许，停下隐私的深度挖掘和过度商业化，我们会少些便捷、舒适和效率，办事会不那么顺畅。但我们就可以继续辛勤劳动，思考学习；继续拥有自由意志，而担起自己的社会责任。我们将保有隐私同人格尊严。这，才是一种更美好的生活。
      二〇一七年十月初稿，一八年四月定稿  原载《文化纵横》6/2018
      
      参考阅读
      
        波斯纳（Richard Posner）：《正义经济学》（  
       The Economics of Justice
        ），哈佛大学出版社，1981。
         冯象  ：《  我是阿尔法——论人机伦理  》，载《文化纵横》12/2017。
        马丁（George Martin）：《简议长生》（Brief proposal on immortality: an interim solution），载《生物学医学展望》（ 
      Perspectives in Biology and Medicine
      ）14/2:339, 1971。
        明斯基（Marvin Minsky）：  《为什么人以为电脑做不了》（Why People Think Computer Can’t）  ，载《人工智能杂志》（ 
      AI Magazine
      ）3:4, 1982（秋季号）。
        卫斯汀（Alan Westin）：《隐私与自由》（  
       Privacy and Freedom
        ），Athenaeum, 1967。
        约翰逊（Bobbie Johnson）：《隐私不再是社会规范，脸书创始人说》（ 
      Privacy no longer a social norm, says Facebook founder
      ），载《卫报》（ 
      The Guardian
      ）2010.1.10。
      
    
    
    
      Categorized:  社会科学 · SOCIAL SCIENCES  -  评论随笔 · ESSAYS 
      Tagged:  人工智能  -  利求同  -  商业化  -  商品化  -  脸书  -  资本  -  隐私 
    
    
    
      如果您喜欢本站文章，  请订阅我们的电子邮件  ，以便及时获取更新通知。
      好书推荐:  脱销多年新近重印的四卷本奥威尔文集 The Collected Essays, Journalism, and Letters of George Orwell: Volume 1  ,  2  ,  3  ,  4  .
    
    
      
        
           Leave a Reply       
        
        
      
      
    
    
  
  

" />
    <meta property="og:description" content="
  

  
  
  
    
       利求同：隐私的未来 
      
        By:  利求同  . 2018-6-5.  7,019 
      
    
    
      “秘密是撒谎，分享是关怀，隐私是偷窃。”
         这是美国科幻作家埃格斯（Dave Eggers）对未来的大胆想象。他的小说《圆圈》（  
      The Circle
       ）拍了  电影  ，这句话是影片里面同名超级公司的训言，同公司建筑的极简主义风格一起，接受“吸科技”的瘾君子朝拜。那里，我们习以为常的道德规范被颠倒了，做成新的信条：藏着隐私是严重的人格缺陷，上缴个人信息等于实现人生自由，光大“分享主义”美德；而保护隐私就视同盗窃，要受新人类的唾弃，并交给新法律制裁。
      隐私，能如此激发作家的想象，应该说是物联网智能时代的一个标记。不过，作为隐私的法定业主，我们得感激埃格斯先生的慷慨。因为在他的超级智能化的未来，隐私仍是有价值的，且依法享有平等的保护。人们只需修正价值观，将隐私从“私”和“隐”的疆域中剥离，转化为信息/数据财产，就能继续熟悉的生活了。当然，这新财产总是落在了别人，例如圆圈公司的手里，留给我们个人的，只是生产和再生产即奉献隐私的许可，人格权的一具空壳。但权利的空壳也是权利，也能给人带来安慰，因而是促进社会和谐美丽所不可少的一项制度。
      事实上，这隐私的未来已经到来。做一个透明人，自愿或被迫交出隐私，供人牟利，业已是生活常态了。只是，价值观的修正跟社会道德转型尚待完成。转型时期，还会有人呼吁，试图保护隐私；隐私的归属和使用上的冲突，却日益频发而尖锐起来。这是因为，在资本当道的条件下，隐私同分享有着不可调和的矛盾。最近脸书在美国乃至全球受到质疑，就是生动的例证。国会一边吵架，一边调查，俄国是否介入或干扰了美国大选，脸书却被爆料曾泄露8,700万用户的个人信息，给一家英国公司。脸书声称，这些用户信息是第三方以“不正当方式”获取的。小扎亲自出面，向公众道歉，保证今后严加管理。殊不知，早在二〇一一年，脸书就用户信息泄露事件做出过几乎同样的承诺。而那承诺之所以未能兑现，是因为无法兑现；实际上，国家法律也不允许兑现。现在的商业模式和残酷的产业竞争，有哪一家网络企业，包括电商大鳄，不是靠挖掘买卖用户信息赚钱的？手里的用户隐私越多，市场就越大，利润就越高。假如隐私当真严加保护，不就等于支柱产业集体自杀了？   
      但是，真正的问题还不是几家大企业的利润多寡。关键在于，这事关乎我们的道德价值和理性选择：人工智能（AI），这一人类引以为傲的创造，信息技术的高峰，很可能与保护隐私是格格不入的。AI以高效、优化为目标，追求的是优于人脑的超级硅基智能。在那个智能体系中，信息是基本元素，是一切事物和生命的记录、编辑与展开。人，整体而言，跟任何碳基物、无机物一样，只是一个信息集。而隐私，进入大数据时代，作为一种游离于人类整体信息集边缘的个体特征，就“过于人性”了——承载了太多的价值立场和法律风险。保护隐私，人类信息集就变得坑坑洼洼，不好用了，所以亟需优化、标准化、去风险化。换言之，隐私成了硅基智能的障碍，是必须清除的杂音；非如此，人类不能同AI结合而融入未来。
      于是，我们不得不直面那一种可能，即隐私的终结。我们必须思考：如果隐私终结，人类将如何生存。
      
      
     一、隐私的可隐性
    
      研究一事物的终结，需要从其兴衰的条件和过程中寻找原因。那么，隐私是因何而来的呢？它又怎样塑造了我们的日常生活，它的消解意味着什么？这些问题的答案至关重要。
      历史地看，隐私是人类对自身生存状态的一种描述，既是社会的客观存在，也是道德伦理的主观认知，因而承载着情感和价值判断。关于隐私，学说繁多，实践更是千姿百态。但万变不离其宗，都包含两个基本要素：一、人的个体有别于群体/社会之公，称之为“私”；二、私的领域，时而需要隔绝于公，视之为“隐”。可以说，隐私的观念，其被社会认可而纳入“私”的范畴，乃是因“公”而生，而获得价值的。隐私既是私与公有别或对立的产物，也是公私赖以共存的条件。
      有学者认为，隐私源于人的动物性。人是独立的个体，同时又是群居动物。人在群体中生活，繁衍生息需要一定的私密空间和时间，才能建立亲疏有别的家庭跟社会关系，私与隐便在其中了。文明开化以后，隐私的观念和习惯，更是人类高级智力活动如宗教、艺术、政治、经济等的产物。渐渐地，隐私就演变为一种个体与群体的生活伦理，超越动物本能，而复杂精致起来，终于成了社会秩序的一根支柱（卫斯汀，1967）。
      这公私对应关系, 早在古希腊，亚里士多德就注意到了。他提出区分家室私事（the oikos）和城邦公务（the polis）这一对范畴的哲学命题，并讨论了自愿行为的概念。由此开启了一个漫长的学术传统，探究隐私同自由意志、自我意识以及自由人格的关系。自由意志是人自主选择而行动的一种能力。所以通常，只有自由意志下的行为，才当得起相应的法律责任和道德评价，无论赏罚、毁誉、愧疚。同理，有了自由意志，教导、说服、审议、禁止、判决等社会机制才能运作。而自由意志的产生和行使，是离不开隐私的环境的。首先，有了隐私，人才能培育道德自我意识，即充分意识到自己与行为后果的联系，即“我”是“我的行为”的“动力因”（efficient cause），从而能够自觉承担后果责任。于是，才产生了对行动的自主选择的心理需求，自由意志才得以培育。所以，没有隐私，就没有自由意志。
      更重要的是，第二，隐私所要求的社会认可同保护，其实是以自由意志，即人对他人和社会负责的能力，为对价的。换言之，消灭隐私，就是消灭人类个体负责的能力。因为，隐私的存在，不仅是自由意志生成和行使的条件，也是个体接受社会评价、承担社会义务的前提。反之，若无隐私，自我意识跟自由意志就失去了植根的土壤，社会评价和个体责任就无所依托。
      如此，私与公共存而辩证统一，我们所知的人类社会及其道德伦理制度，都包含了对隐私和自由意志的认可，虽然程度不一。社会承认并尊重个人（自由人）享有一定的隐私权益，并且或多或少，限制他人（包括政府、企业、团体）对个人信息的索取和使用。相应地，社会要求个人为享有隐私，或他人的不知情、不得干预而付出对价，即为自己的选择和言行负责。也就是说，隐私，作为具有道德价值的利益，是人格尊严的先决条件，也是社会组织、道德伦理、法律问责机制的一块基石。一八九〇年，美国法学家沃伦（Samuel Warren）和布兰代斯（Louis Brandeis）发表了题为“  隐私权  ”的著名论文，第一次系统阐述了所谓“独处的权利”，尝试厘清隐私保护的法律学说和适用规范。隐私权的设立与发展，极大地加强了人们的隐私意识。隐私成了公民的基本权益，享有隐私是现代社会理所当然的一项个人自由；保护隐私，即保护人的尊严，保护我们唯一的生活世界。
      然而今天，这唯一世界，正受到全方位的挑战。随着新型信息技术的迅猛发展和智能终端的普及，隐私首当其冲。一不留神，隐私已是千疮百孔，被那无所不能、无处不在的信息工具盯住了。人们的一举一动，每一个闪念都处于监控之下，不啻一个个透明人。要躲避监控而“独处”，过“正常”日子，几乎不可能了。有史以来第一次，隐私制作成了商品，大规模地买卖。而隐私一旦商品化，不同社会阶层和集团便生出相互冲突的利益诉求，关于隐私的社会共识就名存实亡了。
      表面上，个人似乎仍是隐私的所有者或法律上的主体，对隐私的动物性需求也未变。基于隐私和自由意志的社会道德依旧，保护隐私的法规都好好的；毋宁说，新制定的保护措施越来越严格，更上一层楼了。可是仔细观察，这些未变的方面都不再重要，重要的却彻底变样了：信息技术的“天网”已经布下，隐私无处可藏了！所以，尽管法律规定，隐私应当保护，那藏不住的私，是不成其为隐私的。这样看来，“可隐而不可知”是捍卫隐私的关键。易言之，隐私的成立和维护，可隐性是一项必要条件。因为，破坏了隐，也就同时取消了私，即公私的界限。
      这必要条件遭到破坏，隐私变得可知而失控，正是当下隐私困局的症结所在。一切隐私问题的探讨和对策研究，都不能绕开这一现实。
      
      
     二、信息化和隐私困局
    
      信息时代的大势，是隐私的隐秘性趋近消失。结果，直接危及隐私的两要素，公私有别和私的自处。其始作俑者，叫作隐私的信息化或数码化：隐私被信息技术重新包装，放入虚拟电子黑箱，隔绝于人的感官，被“稀释”处理之后，以“中性化”的数据再现。然而，隐私和信息数据是极不协调的两极。数据是技术产品，往往视为客观中性，外延开放包容；隐私却充满了道德价值，属于人类自我意识的范畴，是主观而收敛排他的。当“隐私数据”被捆绑成一个复合概念，这种不协调就被强行抹去，为隐私数据化，继而商品化铺设通道，隐私的天地就彻底改变了。很快，人们开始接受一种全新的生活方式：零隐私世界。
      我们的观察，可以从隐私的必要条件“可隐性”入手。传统上，关于可隐性的讨论不多。这不是疏忽。从前，日常生活中的隐私，可隐性一向不是问题。仿佛“造物”一开始就恩赐了隐私，让人行使自由意志。人类的感官，获取外界信息的能力有限，眼耳鼻口舌，加上皮肤，远不如许多动物的敏锐好使。一层纸，一段距离，几天的间隔，就足以阻断外界信息的感应接收。而我们引以为傲的大脑，相对于别的动物可称发达，但信息存储的可靠性及处理速度，都很不理想；稍微过量，复杂一点，便束手无策。这就使得个人信息不难保持隐秘。例如，说话的声音跟表情，是瞬间即逝的，通常只有近距离耳闻目睹，才能得知。又如，DNA和脑电波，藏在生物密码中，人的感官无法直接辨认、破译或记录。
      所以，私的自处而有别于公，生活中不许外人窥探隐私，是自然而然形成习惯和道德规范的。正是这种合乎“人的尺度”的可隐性，成全了隐私，让人当上自己隐私的守卫，从而整个社会有了维护隐私的意愿，在道德也在法律层面。这么看，人之享有隐私，藉其培育自由意志，不仅是出于传统的道德选择，还有赖于客观上隐私信息往往具有较高的隐秘性。换一角度，隐私之能够获得保护，在一定程度上也是人们对其可隐性特征的一种认知和回应。
      假如人类满足于“造物”的馈赠，不去触动维护隐私的各样屏障，隐私就可以保持可隐而安全。可是，人类好奇，总想探求新知，创制工具，发现世界的奥秘。终于，到了物联网智能时代，隐私的传统屏障坍塌了。生活完全变了，人必须时刻披露个人信息。从农贸市场买菜用微信支付，到旅游点门票的脸像识别；从政府联网办公，到银行电子转账；从百度搜索，到芝麻信用评分和信息诈骗；还有街头巷尾的摄像头，低头族的手机，直至谷歌眼镜、扫地机器人、汽车传感器、植入手臂的上班打卡芯片……个人信息的收集监控不放过生活的任何一个环节。伴随技术进步，隐私的疆域大大拓展了，连基因信号和下意识的意念，也被挖掘了纳入个人信息。信息化的隐私，是信息爆炸，需要超级计算机来处理，接受各类算法的深度分析，以便追踪、模拟、预测人们的思想和行动。隐私不再可隐。私的自处，公私有别，变得越来越不现实了。
      一般认为，人们尊重隐私，本身便是道德选择。然而在网络世界，隐私的物理载体形态同其他信息并无两样。无论我们的银行存款、股票交易，还是DNA遗传指令、生理特征，都已经化作“0”和“1”的数码序列，由算法处理、电脑存储。那里，隐私的内涵是隐没了的，不会影响技术系统的运作。而隐私的数码序列外形，却丝毫不能出错，否则系统就会罢工。久而久之，信息化的隐私化身为数据而“中性化”，卸下了道德伦理的约束，自由了。
      隐私信息化，带来两个严重后果：一是隐私脱离主体，超越时空，永久地驻扎在信息工具里。人失去了对自己隐私的控制，而受制于信息工具及其主人。第二，电子数码的信息密度低，噪音强，体量庞大，就像一片茂盛的原始丛林，遵循机器的组织原则，虚拟黑箱运作。人自身的信息处理能力对于如此巨大的数据集，是束手无策的，只能依赖机器。而机器依赖性越高，隐私数据的收集者/掌控者的话语权就越大，个人的谈判力就越低。于是，信息社会里，隐私开始自愿或被迫地从“私”（如消费者）向“公”（如商家）流动，在“公”领域快速而大规模聚集，并按照信息工具主人制定的规则，嵌入人们的日常生活。比如，自从社交网站普及，我们的思想表达、兴趣好恶，连同亲友信息就被平台电商收集起来清洗，成了后者的数据财产。接下去的数据交易，则进一步模糊了信息的属性；隐私本身，也因为在公私之间频繁穿梭而不再“纯粹”，虽然仍指向个人或群体，例如网购者/买家的行为与需求信息，同卖方的交易规则交叉互动而产生的信息集；又如，免费使用搜索器生成的数据。这时，个人维护隐私的意愿就显得不那么理直气壮，而难以坚持，直至隐私与道德价值脱钩。如此，私与公这对经典范畴开始游移不定，公私间界限模糊起来，隐私就无处落脚了。
      这就是隐私信息化带来的最严峻的挑战。面对挑战，作为拥有自由意志的人类整体，我们仍有机会做出选择，重建隐私的屏障。然而，新经济选择了隐私的商品化，添上了压垮隐私的最后一根稻草。
      
      
     三、隐私商品化和法律保护的迷思
    
      隐私商品化，标志着资本主义世界对隐私态度的质的变化，也是信息社会转型期矛盾的一个焦点。隐私有用有市，不是新发现。但隐私既是自由人格的条件，也是人的软肋，需要精心呵护。所以，传统道德讲求节制，是包括尊重隐私在内的；拿自己或他人的隐私做交易，就更是可耻了。道德加上信息能力有限，可谓双重的约束，隐私才能一路平安地走来。
      现在，智能终端的天网建成，迅速消解了这两道护卫，把蕴藏在隐私中的经济价值和社会控制力裸露了。这大大刺激了隐私的商业挖掘。人们找出各种正当化的理由，隐私淘金热就像放出笼子的野兽，失控了。个人信息充斥了商品市场，在经济生活中占有越来越大的比重。所谓智能经济，几乎所有最赚钱的企业都在挖掘使用和买卖隐私，不论谷歌、脸书、百度跟阿里巴巴。打开脸书，看看你自己上缴的信息吧：照片视频，留言打招呼的就不说了，每天的生活细节、消费习惯、工作安排，亲友往来等等，事无巨细，连你自己都没注意或忘记了的，统统记录在案。谷歌占有的信息集就更庞大了。这些网络巨头深知，隐私就是财富。于是，隐私被冠以新的身份：以市场需求来定价交易的商品。
      既是商品，就免不了推向市场，“公平”竞争。站在市场经济的立场，挖掘隐私，消费隐私，完全符合发展经济的政策目标。这样一来，尊重隐私、维护隐私的道德和技术屏障，因为有碍市场经济，反而处境尴尬了。资本的策略，是把收集个人信息跟服务的便利、高效、创新挂钩；将分享隐私和焕然一新的消费者感受等同。在饱和的宣传攻势下，商家和政府采集使用个人信息，几乎没有任何阻力，还美其名曰：消费者同商家双赢，老百姓和国家双赢。可是，双赢是市场赢家的说辞；凡是双赢的交易，桌面下面总有一方或第三方要付出代价。智能经济的代价，便是终端用户/消费者交出隐私。表面上，提交隐私信息换取服务和便利，对人只有好处，但其损害后果是潜在或滞后的，包括未来就业发生困难，突然被拒绝医疗保险，或者遭受价格歧视、信用误导（参见拙文《  交出了隐私，再掏空钱袋  》），直至削弱人们负责任的能力或自由意志。
      最近美国一个例子，为此做了绝妙的脚注。二〇一七年三月，国会投票，封杀了联邦通讯委员会（FCC）年前通过的《互联网隐私规则》（IPR）。《规则》是为保护网络用户的隐私而订立的，限制了网商使用和“分享”即出售用户的网上行为信息。诡异的是，封杀理由与保护隐私毫不搭界，而是平衡网商的利益，保障市场的公平竞争。也就是说，围绕《规则》的利益较量，用户的隐私权益根本没在考虑之列。更有甚者，国会还表决禁止FCC今后颁布任何类似的保护用户隐私的法规。据说，这么做是有经济学依据的。大名鼎鼎的波斯纳法官曾著文阐述：保护个人隐私经常是低效的，而特殊保护又没有必要。以经济学观之，商家的“隐私”或商业秘密比用户隐私更有理由受保护（  波斯纳，1981  ）。据此逻辑，与其加强隐私保护，不如促进商家的公平竞争，总效益更高。这便是隐私沦为市场交易的商品，必须面对的利益与辩白。尤其令人担忧的是，在道德伦理和技术手段都败下阵来的今天，法律已是捍卫隐私的最后一道脆弱的防线。
      隐私法如此不堪一击，并不奇怪。立法向来是社会各方利益集团谈判妥协的产物，一般总是向强势方倾斜。如果遵循“经济规律”即市场信条来制定规则，法律就不能妨碍“正常”的商品交换，尤其是实用价值高、市场需求大的商品。而隐私早成了信息市场的宠儿。君不见，个人行为信息支撑着精准投放广告、区别定价；指纹和刷脸，方便了身份识别跟信用追踪；DNA信息则可帮助保险公司甄别投保人风险。难怪隐私保护变得缩手缩脚了，因为所有的强势利益集团都要求法律承认，商家收集个人信息，做成商品，就是科学、正当、高效，故而应当支持。于是，基于技术操作规程，法律将获取和使用隐私分成两类：合法、非法。例如，黑客为非法，因为没有向官方注册；但社交和购物网站合法，只需设置用户选择及相关提示。
      如此立法执法，造成一个假象：仿佛合法取用隐私对人无害，可以放心“分享”。唯有非法入侵才是隐私遭破坏的原因和隐患，才会影响我们的正常生活。所以只消立法禁止、惩罚隐私数据的盗窃泄漏和非法买卖，我们的隐私就安然无恙了。
      这当然是自欺欺人。首先，常识告诉我们，媒体经常报道的个人和团伙盗卖个人信息，由于明显违法，偷偷摸摸见不得人，是撼动不了隐私的道德地位的。真正的威胁来自合法的隐私收集和商品化交易，因为那是系统的规模化的受保护市场行为。那些网络平台和产业巨头，大大小小的网站、店家、服务商，日复一日、年复一年地依法获取加工隐私“原材料”，才是对隐私的最大伤害。其次，法律上那一堆看似细致入微的隐私保护条款，不仅对黑箱操作的“漏洞”防不胜防，还是商家的免责保护机制。大数据AI等信息技术日新月异，黑箱操作是设计使然，关乎效率和商业技术秘密。故有评论认为，提高操作透明度，让信息系统内隐私数据的来龙去脉受监督，有助于保护隐私。欧盟最近颁布的《一般数据保护条例》（GDPR) ，添加了条款，要求算法自动决策的使用者为决策给出解释。这是目前为止，对黑箱现象做出的最严格限制。也许会有一定的效果，但《条例》依然回避了隐私商品化问题，而把注意力导向透明度。这是意味深长的。再看脸书，当它的保护隐私设置被合法或不当“攻破”，造成海量用户信息“泄漏”，面对公众舆论跟政府监管部门的压力，确实，老板公开道歉了，保证采取补救措施，提高透明度，甚至答应让用户看到脸书为广告商提供的自己的画像（profile)。但是，它没忘记重申一句：精准投放广告的商业模式不变。
      商品化成为定局，隐私脱离主体，被合法挖掘追踪分析，广泛用于解读并预测、规制人的欲望、想法和行动，人与隐私的关系就变了。隐私主体失去了话语权，不再是自己隐私的主人和守护者（马丁，1971）。鉴于个人信息的巨大经济价值和政治红利，法律别无选择，只能承认或默许隐私商品化。而公共议题就转变为：谁可以“合法”占有商品化的果实，即商业利益的竞争和垄断。所以，合法或是非法，法律都不可能还人类以隐私之安宁。
      法律保护的效用如此之低，为什么各国，尤其是发达经济体，还在不断强化隐私权的立法和宣传？原因很简单，那是政府部门同立法者目前唯一能做，而不影响“大局”的事情。当然，那也是业界巨头所希望的。比如小扎，今年三月接受CNN采访，就明确邀请国会立法，规制社交网站，说：问题不是该不该规制，而是什么是正确的规则。
      资本非常清醒：隐私关乎人的责任能力，占有隐私并获得保护，就要承担相对应的社会责任。当人们交出隐私（无论自愿或不知情），让商家牟利或政府监管，个人的自由意志选择范围便相应地缩小了。人的自主选择越少，承担责任的能力也越小。反之，商家和政府获取的隐私越多，对用户跟社会的控制力也越强。隐私易手，对应的社会责任并不会消失，是需要重新分配的。而且不仅是责任，还是社会风险管理机制的全盘安排。但市场经济是自利者的王国，资本拿隐私赚大钱，却无意承担附着于隐私的社会责任。这就是为什么，他们一边推动隐私商品化，一边在媒体和立法层面，大声疾呼保障隐私。他们企图让人相信，尽管隐私化作他人财产已是生活常态，原始隐私权仍在自己手中，并受到前所未有的法律保护。只需发扬分享的美德，就会得到最佳补偿，即生活便利。巨头们直言不讳，希望失去隐私的人们一如既往地承担行为主体的责任，而掌控隐私的唱唱法律保护的高调，即可免责而享受用户“分享”的馈赠。
      这，应该就是埃格斯先生设想的零隐私未来的起点同终线。无独有偶，脸书老板早在二〇一〇年就说过，我们的隐私观过时了，  隐私“不再是社会规范”  。大家不仅乐于分享各种信息，而且喜欢向越来越多的陌生人开放自己，“促成了新的社会规范”（约翰逊, 2010）。是的，只要巨头们奉行《圆圈》里的那句台词：知道（隐私）好。知道一切（隐私）更好！法律就救不了隐私。
      
      
     四、隐私终结，意味着什么？
    
      说到这里，隐私经过信息社会商业化的洗礼，命运只有一个去向——走向终结！
      也许，一些占有者以为，自己可以是隐私终结的例外，甚而能够在支配他人隐私的同时，继续保有自己的隐私？然而，人类的总命运是谁也逃不脱的。从目前AI的发展势头看，我们不得不警惕，一种智力优于人类，且具有“自由意志”的独立物种出现。届时，机器人未必“甘当”人类肢体和心智的延伸，而人类却要依靠它才能生存。因此，隐私危机必须放在人机关系中去思考、规划。个人信息的网络储存越多，分析工具越精致高效，硅基智能成长为独立物种而摆脱人类管控的步伐，就会越快。当AI提升至通用智能，能够在多个领域自我学习，不再需要人的知识连同隐私当它的学习素材，一如自学围棋、碾压人类顶级大脑的“阿尔法零”，那一天，将奏响隐私的挽歌。
      不过，隐私的终结，并不意味着人类终结。归根结蒂，人是可以零隐私地活着的。迄今为止，隐私对于人类重要，是因为人受制于较低的信息能力，亦即人类为自己安排了那样的生活秩序。所以一方面，隐私是人类高级智力活动的产物，体现了人对自身价值的期待和尊重；另一方面，一旦人类实现“自我超越”，造出通用人工智能（AGI），让机器取代自己思考、劳动、创造，后隐私时代便降临了。
      进入后隐私时代，人类社会现存的经济基础和上层建筑必然失效了。人类将怎样生活？没有历史经验，没有参照物，很难想象。但有三点可以预期：
      一、那将是一种没有自觉自愿，不知何为荣辱问责，但高效而标准化的低智低能的生活秩序。那里，隐私失去了意义。它不再能培育自由人格，因为系统中没有自由意志的位置。它不再是社会责任的对价，因为人无须自由选择自主行动而承担责任。它也不再是智力活动的衍生品，因为人类主动放弃了发展智力的努力，满足于在无限优化了的天网下执行指令。
      二、社会的中心不再是人与人的关系，而是人机关系和机机关系。人类不复为地球的主人，反倒有可能变成硅基智能系统的累赘。不是有AI专家预测，二十五年后，无人驾驶技术成熟，人类将被禁止驾车上路。无人驾驶的交通系统，其交通规则、道路设计、社区安排等，都是不许出错的。人类驾驶只会破坏科学设计的完美，引发交通事故，降低行车效率。实际上，排斥人类参与、删除人类个性，那样的硅胶智能世界，才可能是高效简洁、完满无缺的一个大“圆圈”。
      三、人类世界本身，共产主义或许是唯一的选项。因为机器人治下，人不但没有了隐私，分工也已消失。所有的个体都集合于一个总体，个人自由即全体的自由，我为人人即人人为我（  冯象，2017  ）。
       人工智能的先驱，已故的麻省理工学院教授明斯基（Marvin Minsky）说过：有朝一日，当我们掌握了建造智力远胜人类的机器的知识，就不得不面对一个奇特的问题，那就是：该不该建造？我很幸运，因为我可以把这一困难的选择留给后人。但我相信，他们不会建造，除非找到很好的理由（  明斯基，1982  ）。明斯基还曾经对深度学习神经网络技术做出悲观的描述（《认知器演算法》，1969, 1987），他的观点被认为阻碍了AI发展达半个世纪之久，因而颇受诟病。但我想，换个角度，这也许是教授对人类最大的贡献：为我们做好准备迎接机器人时代，赢得了宝贵的时间。
      明斯基的智慧提醒我们，对隐私应取审慎节制的态度。也许，停下隐私的深度挖掘和过度商业化，我们会少些便捷、舒适和效率，办事会不那么顺畅。但我们就可以继续辛勤劳动，思考学习；继续拥有自由意志，而担起自己的社会责任。我们将保有隐私同人格尊严。这，才是一种更美好的生活。
      二〇一七年十月初稿，一八年四月定稿  原载《文化纵横》6/2018
      
      参考阅读
      
        波斯纳（Richard Posner）：《正义经济学》（  
       The Economics of Justice
        ），哈佛大学出版社，1981。
         冯象  ：《  我是阿尔法——论人机伦理  》，载《文化纵横》12/2017。
        马丁（George Martin）：《简议长生》（Brief proposal on immortality: an interim solution），载《生物学医学展望》（ 
      Perspectives in Biology and Medicine
      ）14/2:339, 1971。
        明斯基（Marvin Minsky）：  《为什么人以为电脑做不了》（Why People Think Computer Can’t）  ，载《人工智能杂志》（ 
      AI Magazine
      ）3:4, 1982（秋季号）。
        卫斯汀（Alan Westin）：《隐私与自由》（  
       Privacy and Freedom
        ），Athenaeum, 1967。
        约翰逊（Bobbie Johnson）：《隐私不再是社会规范，脸书创始人说》（ 
      Privacy no longer a social norm, says Facebook founder
      ），载《卫报》（ 
      The Guardian
      ）2010.1.10。
      
    
    
    
      Categorized:  社会科学 · SOCIAL SCIENCES  -  评论随笔 · ESSAYS 
      Tagged:  人工智能  -  利求同  -  商业化  -  商品化  -  脸书  -  资本  -  隐私 
    
    
    
      如果您喜欢本站文章，  请订阅我们的电子邮件  ，以便及时获取更新通知。
      好书推荐:  脱销多年新近重印的四卷本奥威尔文集 The Collected Essays, Journalism, and Letters of George Orwell: Volume 1  ,  2  ,  3  ,  4  .
    
    
      
        
           Leave a Reply       
        
        
      
      
    
    
  
  

" />
    
    <meta name="author" content="觀點" />

    
    <meta property="og:title" content="利求同：隐私的未来" />
    <meta property="twitter:title" content="利求同：隐私的未来" />
    

  <link rel="stylesheet" type="text/css" href="/opinion/style.css" />
  <link rel="alternate" type="application/rss+xml" title="觀點 - 從草根到大師 git.io/JJCxS" href="/opinion/feed.xml" />

  <!-- Social Share Kit CSS -->
  <link rel="stylesheet" href="/opinion/assets/css/social-share-kit.css" type="text/css">
  <link rel="stylesheet" href="/opinion/assets/css/font-awesome.min.css" type="text/css">
  <link rel="stylesheet" href="/opinion/assets/css/bootstrap.min.css" type="text/css">
  <script type="text/javascript" src="/opinion/assets/js/jquery-3.5.1.js"></script>
  <script type="text/javascript" src="/opinion/assets/js/page.js"></script>

</head>

  <body>
    <div class="wrapper-masthead">
  <div class="container">
    <header class="masthead clearfix">
      

      <div class="site-info">
        <h1 class="site-name" style="display: inline-block;"><a href="/opinion/">觀點</a></h1>
        <i class="site-description" style="font-size: 12px;">從草根到大師 git.io/JJCxS</i>
      </div>

      <nav>
        <span id="search-container" >
          <a href="/opinion/tools"><i class="fa fa-bookmark twitter" title="百宝箱"></i></a>
        <a><i class="fa fa-search" title="限前100結果"></i></a><input type="text" id="search-input" placeholder="標題 作者 來源 日期 (17489)"
          style="margin: 10px 0px 0px 0px; height: 30px;width: auto" title="本站最正確的打開方式">
        </span>
        
        
        <a href="/opinion/categories" style="color: Tomato;"><i class="fa fa-tags" title="分类"></i></a>
        
        
        
        <a href="https://be4.herokuapp.com/" style="color: #003366;"><i class="fa fa-comments" title="论坛"></i></a>
        
        
        
        <a href="/opinion/about"><i class="fa fa-info-circle" title="关于"></i></a>
        
        
        <a title="电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇，del同来源旧一篇" onclick="toggle_visibility('help')"><i class="fa fa-question-circle"></i></a>
        <a id="fa-home" href="https://nodebe4.github.io" title="BE4服务列表" onclick="//toggle_visibility('site-list')"><i class="fa fa-home" aria-hidden="true"></i></a>
      </nav>

    </header>
    <div id="site-list" class="tags" style="display: block;text-align: right;border-bottom: 1px solid lightGray;"><noscript><span style="background-color: #e8e8e8;color: #d10000;font-size: 14px;">开启浏览器JavaScript以获取搜索功能和更好的浏览体验</span></noscript></div>
    <p id="help" style="font-size: 14px;display: none;text-align: right;"><span style="color:green;">电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇, del同来源旧一篇</span>; <span style="color:orange">对应触屏FAB：上下右左</span>; 轉Markdown<a href="https://euangoddard.github.io/clipboard2markdown/"><i class="fa fa-file-text-o"></i></a></p>
  </div>
</div>

<script type="text/javascript" >
  function toggle_visibility(id){
    var help = document.getElementById(id)
    if (help.style.display=='none'){
      help.style.display='block';
    }else{
      help.style.display='none';
    }
  }

  const url = "https://nodebe4.github.io/sitelist.json"

  document.addEventListener("DOMContentLoaded", function(event){
    // var homebtn = document.getElementById("fa-home")
    // homebtn.removeAttribute("href")
    var content = document.getElementById("site-list");
    content.innerHTML = ''
    var ul = document.createElement("ul")
    ul.classList.add("label")
    content.appendChild(ul)
    var cnt = 0

    $.getJSON(url, function(allsites) {

      allsites.map(item =>{
        var li = document.createElement('li')
        li.classList.add("tag")
        li.id = 'site-' + cnt
        ul.appendChild(li)
        var a0 = document.createElement('a')
        li.appendChild(a0)
        a0.href = item.url[0]
        var span = document.createElement('span')
        a0.appendChild(span)
        span.innerText = item['name']
        // span.style.backgroundColor = item['background-color']
        // span.style.color='#E4CBC3'
        span.style.color = item['background-color']
        span.style['font-size'] = '14px'
        cnt += 1
        // test_alive(li.id, a0.href)
      })
    })
  })

function test_alive(id, url){
  var divstatus = document.getElementById(id)
  const base = 'https://textance.herokuapp.com/title/'
  var fullurl = base + url
  $.ajax({
      url: fullurl,
      complete: function(data) {
        if (data.responseText.includes('502')){
          // divstatus.style.color='#FBB7B7'
          // divstatus.style.color='gray'
          // divstatus.title = "服务器无响应"
          divstatus.parentNode.removeChild(divstatus)
        }else{
          // divstatus.style.color='#B6FAC8'
          divstatus.title = data.responseText
        }
      }
  });
  return divstatus
}
</script>



    <!-- Left & centered positioning -->

<div class="ssk-sticky ssk-right ssk-center ssk-sticky-hide-xs ssk-group ssk-round">
  
    <a href="https://be4news.pythonanywhere.com/archivenow/ia/http%3A%2F%2Fwww.ideobook.com%2F2745%2Ffuture-privacy%2F" class="ssk ssk-link" title="存到互联网档案馆" target="_blank"></a>
    <a href="https://www.facebook.com/sharer.php?u=http://www.ideobook.com/2745/future-privacy/" class="ssk ssk-facebook"></a>
    <a href="https://twitter.com/intent/tweet?url=http://www.ideobook.com/2745/future-privacy/&text=利求同：隐私的未来&hashtags=觀點" class="ssk ssk-twitter"></a>
    <a href="https://reddit.com/submit?url=http://www.ideobook.com/2745/future-privacy/&title=利求同：隐私的未来" class="ssk ssk-reddit"></a>
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://www.ideobook.com/2745/future-privacy/&title=利求同：隐私的未来" class="ssk ssk-linkedin"></a>
    <a href="mailto:{email_address}?subject=利求同：隐私的未来&body=
  

  
  
  
    
       利求同：隐私的未来 
      
        By:  利求同  . 2018-6-5.  7,019 
      
    
    
      “秘密是撒谎，分享是关怀，隐私是偷窃。”
         这是美国科幻作家埃格斯（Dave Eggers）对未来的大胆想象。他的小说《圆圈》（  
      The Circle
       ）拍了  电影  ，这句话是影片里面同名超级公司的训言，同公司建筑的极简主义风格一起，接受“吸科技”的瘾君子朝拜。那里，我们习以为常的道德规范被颠倒了，做成新的信条：藏着隐私是严重的人格缺陷，上缴个人信息等于实现人生自由，光大“分享主义”美德；而保护隐私就视同盗窃，要受新人类的唾弃，并交给新法律制裁。
      隐私，能如此激发作家的想象，应该说是物联网智能时代的一个标记。不过，作为隐私的法定业主，我们得感激埃格斯先生的慷慨。因为在他的超级智能化的未来，隐私仍是有价值的，且依法享有平等的保护。人们只需修正价值观，将隐私从“私”和“隐”的疆域中剥离，转化为信息/数据财产，就能继续熟悉的生活了。当然，这新财产总是落在了别人，例如圆圈公司的手里，留给我们个人的，只是生产和再生产即奉献隐私的许可，人格权的一具空壳。但权利的空壳也是权利，也能给人带来安慰，因而是促进社会和谐美丽所不可少的一项制度。
      事实上，这隐私的未来已经到来。做一个透明人，自愿或被迫交出隐私，供人牟利，业已是生活常态了。只是，价值观的修正跟社会道德转型尚待完成。转型时期，还会有人呼吁，试图保护隐私；隐私的归属和使用上的冲突，却日益频发而尖锐起来。这是因为，在资本当道的条件下，隐私同分享有着不可调和的矛盾。最近脸书在美国乃至全球受到质疑，就是生动的例证。国会一边吵架，一边调查，俄国是否介入或干扰了美国大选，脸书却被爆料曾泄露8,700万用户的个人信息，给一家英国公司。脸书声称，这些用户信息是第三方以“不正当方式”获取的。小扎亲自出面，向公众道歉，保证今后严加管理。殊不知，早在二〇一一年，脸书就用户信息泄露事件做出过几乎同样的承诺。而那承诺之所以未能兑现，是因为无法兑现；实际上，国家法律也不允许兑现。现在的商业模式和残酷的产业竞争，有哪一家网络企业，包括电商大鳄，不是靠挖掘买卖用户信息赚钱的？手里的用户隐私越多，市场就越大，利润就越高。假如隐私当真严加保护，不就等于支柱产业集体自杀了？   
      但是，真正的问题还不是几家大企业的利润多寡。关键在于，这事关乎我们的道德价值和理性选择：人工智能（AI），这一人类引以为傲的创造，信息技术的高峰，很可能与保护隐私是格格不入的。AI以高效、优化为目标，追求的是优于人脑的超级硅基智能。在那个智能体系中，信息是基本元素，是一切事物和生命的记录、编辑与展开。人，整体而言，跟任何碳基物、无机物一样，只是一个信息集。而隐私，进入大数据时代，作为一种游离于人类整体信息集边缘的个体特征，就“过于人性”了——承载了太多的价值立场和法律风险。保护隐私，人类信息集就变得坑坑洼洼，不好用了，所以亟需优化、标准化、去风险化。换言之，隐私成了硅基智能的障碍，是必须清除的杂音；非如此，人类不能同AI结合而融入未来。
      于是，我们不得不直面那一种可能，即隐私的终结。我们必须思考：如果隐私终结，人类将如何生存。
      
      
     一、隐私的可隐性
    
      研究一事物的终结，需要从其兴衰的条件和过程中寻找原因。那么，隐私是因何而来的呢？它又怎样塑造了我们的日常生活，它的消解意味着什么？这些问题的答案至关重要。
      历史地看，隐私是人类对自身生存状态的一种描述，既是社会的客观存在，也是道德伦理的主观认知，因而承载着情感和价值判断。关于隐私，学说繁多，实践更是千姿百态。但万变不离其宗，都包含两个基本要素：一、人的个体有别于群体/社会之公，称之为“私”；二、私的领域，时而需要隔绝于公，视之为“隐”。可以说，隐私的观念，其被社会认可而纳入“私”的范畴，乃是因“公”而生，而获得价值的。隐私既是私与公有别或对立的产物，也是公私赖以共存的条件。
      有学者认为，隐私源于人的动物性。人是独立的个体，同时又是群居动物。人在群体中生活，繁衍生息需要一定的私密空间和时间，才能建立亲疏有别的家庭跟社会关系，私与隐便在其中了。文明开化以后，隐私的观念和习惯，更是人类高级智力活动如宗教、艺术、政治、经济等的产物。渐渐地，隐私就演变为一种个体与群体的生活伦理，超越动物本能，而复杂精致起来，终于成了社会秩序的一根支柱（卫斯汀，1967）。
      这公私对应关系, 早在古希腊，亚里士多德就注意到了。他提出区分家室私事（the oikos）和城邦公务（the polis）这一对范畴的哲学命题，并讨论了自愿行为的概念。由此开启了一个漫长的学术传统，探究隐私同自由意志、自我意识以及自由人格的关系。自由意志是人自主选择而行动的一种能力。所以通常，只有自由意志下的行为，才当得起相应的法律责任和道德评价，无论赏罚、毁誉、愧疚。同理，有了自由意志，教导、说服、审议、禁止、判决等社会机制才能运作。而自由意志的产生和行使，是离不开隐私的环境的。首先，有了隐私，人才能培育道德自我意识，即充分意识到自己与行为后果的联系，即“我”是“我的行为”的“动力因”（efficient cause），从而能够自觉承担后果责任。于是，才产生了对行动的自主选择的心理需求，自由意志才得以培育。所以，没有隐私，就没有自由意志。
      更重要的是，第二，隐私所要求的社会认可同保护，其实是以自由意志，即人对他人和社会负责的能力，为对价的。换言之，消灭隐私，就是消灭人类个体负责的能力。因为，隐私的存在，不仅是自由意志生成和行使的条件，也是个体接受社会评价、承担社会义务的前提。反之，若无隐私，自我意识跟自由意志就失去了植根的土壤，社会评价和个体责任就无所依托。
      如此，私与公共存而辩证统一，我们所知的人类社会及其道德伦理制度，都包含了对隐私和自由意志的认可，虽然程度不一。社会承认并尊重个人（自由人）享有一定的隐私权益，并且或多或少，限制他人（包括政府、企业、团体）对个人信息的索取和使用。相应地，社会要求个人为享有隐私，或他人的不知情、不得干预而付出对价，即为自己的选择和言行负责。也就是说，隐私，作为具有道德价值的利益，是人格尊严的先决条件，也是社会组织、道德伦理、法律问责机制的一块基石。一八九〇年，美国法学家沃伦（Samuel Warren）和布兰代斯（Louis Brandeis）发表了题为“  隐私权  ”的著名论文，第一次系统阐述了所谓“独处的权利”，尝试厘清隐私保护的法律学说和适用规范。隐私权的设立与发展，极大地加强了人们的隐私意识。隐私成了公民的基本权益，享有隐私是现代社会理所当然的一项个人自由；保护隐私，即保护人的尊严，保护我们唯一的生活世界。
      然而今天，这唯一世界，正受到全方位的挑战。随着新型信息技术的迅猛发展和智能终端的普及，隐私首当其冲。一不留神，隐私已是千疮百孔，被那无所不能、无处不在的信息工具盯住了。人们的一举一动，每一个闪念都处于监控之下，不啻一个个透明人。要躲避监控而“独处”，过“正常”日子，几乎不可能了。有史以来第一次，隐私制作成了商品，大规模地买卖。而隐私一旦商品化，不同社会阶层和集团便生出相互冲突的利益诉求，关于隐私的社会共识就名存实亡了。
      表面上，个人似乎仍是隐私的所有者或法律上的主体，对隐私的动物性需求也未变。基于隐私和自由意志的社会道德依旧，保护隐私的法规都好好的；毋宁说，新制定的保护措施越来越严格，更上一层楼了。可是仔细观察，这些未变的方面都不再重要，重要的却彻底变样了：信息技术的“天网”已经布下，隐私无处可藏了！所以，尽管法律规定，隐私应当保护，那藏不住的私，是不成其为隐私的。这样看来，“可隐而不可知”是捍卫隐私的关键。易言之，隐私的成立和维护，可隐性是一项必要条件。因为，破坏了隐，也就同时取消了私，即公私的界限。
      这必要条件遭到破坏，隐私变得可知而失控，正是当下隐私困局的症结所在。一切隐私问题的探讨和对策研究，都不能绕开这一现实。
      
      
     二、信息化和隐私困局
    
      信息时代的大势，是隐私的隐秘性趋近消失。结果，直接危及隐私的两要素，公私有别和私的自处。其始作俑者，叫作隐私的信息化或数码化：隐私被信息技术重新包装，放入虚拟电子黑箱，隔绝于人的感官，被“稀释”处理之后，以“中性化”的数据再现。然而，隐私和信息数据是极不协调的两极。数据是技术产品，往往视为客观中性，外延开放包容；隐私却充满了道德价值，属于人类自我意识的范畴，是主观而收敛排他的。当“隐私数据”被捆绑成一个复合概念，这种不协调就被强行抹去，为隐私数据化，继而商品化铺设通道，隐私的天地就彻底改变了。很快，人们开始接受一种全新的生活方式：零隐私世界。
      我们的观察，可以从隐私的必要条件“可隐性”入手。传统上，关于可隐性的讨论不多。这不是疏忽。从前，日常生活中的隐私，可隐性一向不是问题。仿佛“造物”一开始就恩赐了隐私，让人行使自由意志。人类的感官，获取外界信息的能力有限，眼耳鼻口舌，加上皮肤，远不如许多动物的敏锐好使。一层纸，一段距离，几天的间隔，就足以阻断外界信息的感应接收。而我们引以为傲的大脑，相对于别的动物可称发达，但信息存储的可靠性及处理速度，都很不理想；稍微过量，复杂一点，便束手无策。这就使得个人信息不难保持隐秘。例如，说话的声音跟表情，是瞬间即逝的，通常只有近距离耳闻目睹，才能得知。又如，DNA和脑电波，藏在生物密码中，人的感官无法直接辨认、破译或记录。
      所以，私的自处而有别于公，生活中不许外人窥探隐私，是自然而然形成习惯和道德规范的。正是这种合乎“人的尺度”的可隐性，成全了隐私，让人当上自己隐私的守卫，从而整个社会有了维护隐私的意愿，在道德也在法律层面。这么看，人之享有隐私，藉其培育自由意志，不仅是出于传统的道德选择，还有赖于客观上隐私信息往往具有较高的隐秘性。换一角度，隐私之能够获得保护，在一定程度上也是人们对其可隐性特征的一种认知和回应。
      假如人类满足于“造物”的馈赠，不去触动维护隐私的各样屏障，隐私就可以保持可隐而安全。可是，人类好奇，总想探求新知，创制工具，发现世界的奥秘。终于，到了物联网智能时代，隐私的传统屏障坍塌了。生活完全变了，人必须时刻披露个人信息。从农贸市场买菜用微信支付，到旅游点门票的脸像识别；从政府联网办公，到银行电子转账；从百度搜索，到芝麻信用评分和信息诈骗；还有街头巷尾的摄像头，低头族的手机，直至谷歌眼镜、扫地机器人、汽车传感器、植入手臂的上班打卡芯片……个人信息的收集监控不放过生活的任何一个环节。伴随技术进步，隐私的疆域大大拓展了，连基因信号和下意识的意念，也被挖掘了纳入个人信息。信息化的隐私，是信息爆炸，需要超级计算机来处理，接受各类算法的深度分析，以便追踪、模拟、预测人们的思想和行动。隐私不再可隐。私的自处，公私有别，变得越来越不现实了。
      一般认为，人们尊重隐私，本身便是道德选择。然而在网络世界，隐私的物理载体形态同其他信息并无两样。无论我们的银行存款、股票交易，还是DNA遗传指令、生理特征，都已经化作“0”和“1”的数码序列，由算法处理、电脑存储。那里，隐私的内涵是隐没了的，不会影响技术系统的运作。而隐私的数码序列外形，却丝毫不能出错，否则系统就会罢工。久而久之，信息化的隐私化身为数据而“中性化”，卸下了道德伦理的约束，自由了。
      隐私信息化，带来两个严重后果：一是隐私脱离主体，超越时空，永久地驻扎在信息工具里。人失去了对自己隐私的控制，而受制于信息工具及其主人。第二，电子数码的信息密度低，噪音强，体量庞大，就像一片茂盛的原始丛林，遵循机器的组织原则，虚拟黑箱运作。人自身的信息处理能力对于如此巨大的数据集，是束手无策的，只能依赖机器。而机器依赖性越高，隐私数据的收集者/掌控者的话语权就越大，个人的谈判力就越低。于是，信息社会里，隐私开始自愿或被迫地从“私”（如消费者）向“公”（如商家）流动，在“公”领域快速而大规模聚集，并按照信息工具主人制定的规则，嵌入人们的日常生活。比如，自从社交网站普及，我们的思想表达、兴趣好恶，连同亲友信息就被平台电商收集起来清洗，成了后者的数据财产。接下去的数据交易，则进一步模糊了信息的属性；隐私本身，也因为在公私之间频繁穿梭而不再“纯粹”，虽然仍指向个人或群体，例如网购者/买家的行为与需求信息，同卖方的交易规则交叉互动而产生的信息集；又如，免费使用搜索器生成的数据。这时，个人维护隐私的意愿就显得不那么理直气壮，而难以坚持，直至隐私与道德价值脱钩。如此，私与公这对经典范畴开始游移不定，公私间界限模糊起来，隐私就无处落脚了。
      这就是隐私信息化带来的最严峻的挑战。面对挑战，作为拥有自由意志的人类整体，我们仍有机会做出选择，重建隐私的屏障。然而，新经济选择了隐私的商品化，添上了压垮隐私的最后一根稻草。
      
      
     三、隐私商品化和法律保护的迷思
    
      隐私商品化，标志着资本主义世界对隐私态度的质的变化，也是信息社会转型期矛盾的一个焦点。隐私有用有市，不是新发现。但隐私既是自由人格的条件，也是人的软肋，需要精心呵护。所以，传统道德讲求节制，是包括尊重隐私在内的；拿自己或他人的隐私做交易，就更是可耻了。道德加上信息能力有限，可谓双重的约束，隐私才能一路平安地走来。
      现在，智能终端的天网建成，迅速消解了这两道护卫，把蕴藏在隐私中的经济价值和社会控制力裸露了。这大大刺激了隐私的商业挖掘。人们找出各种正当化的理由，隐私淘金热就像放出笼子的野兽，失控了。个人信息充斥了商品市场，在经济生活中占有越来越大的比重。所谓智能经济，几乎所有最赚钱的企业都在挖掘使用和买卖隐私，不论谷歌、脸书、百度跟阿里巴巴。打开脸书，看看你自己上缴的信息吧：照片视频，留言打招呼的就不说了，每天的生活细节、消费习惯、工作安排，亲友往来等等，事无巨细，连你自己都没注意或忘记了的，统统记录在案。谷歌占有的信息集就更庞大了。这些网络巨头深知，隐私就是财富。于是，隐私被冠以新的身份：以市场需求来定价交易的商品。
      既是商品，就免不了推向市场，“公平”竞争。站在市场经济的立场，挖掘隐私，消费隐私，完全符合发展经济的政策目标。这样一来，尊重隐私、维护隐私的道德和技术屏障，因为有碍市场经济，反而处境尴尬了。资本的策略，是把收集个人信息跟服务的便利、高效、创新挂钩；将分享隐私和焕然一新的消费者感受等同。在饱和的宣传攻势下，商家和政府采集使用个人信息，几乎没有任何阻力，还美其名曰：消费者同商家双赢，老百姓和国家双赢。可是，双赢是市场赢家的说辞；凡是双赢的交易，桌面下面总有一方或第三方要付出代价。智能经济的代价，便是终端用户/消费者交出隐私。表面上，提交隐私信息换取服务和便利，对人只有好处，但其损害后果是潜在或滞后的，包括未来就业发生困难，突然被拒绝医疗保险，或者遭受价格歧视、信用误导（参见拙文《  交出了隐私，再掏空钱袋  》），直至削弱人们负责任的能力或自由意志。
      最近美国一个例子，为此做了绝妙的脚注。二〇一七年三月，国会投票，封杀了联邦通讯委员会（FCC）年前通过的《互联网隐私规则》（IPR）。《规则》是为保护网络用户的隐私而订立的，限制了网商使用和“分享”即出售用户的网上行为信息。诡异的是，封杀理由与保护隐私毫不搭界，而是平衡网商的利益，保障市场的公平竞争。也就是说，围绕《规则》的利益较量，用户的隐私权益根本没在考虑之列。更有甚者，国会还表决禁止FCC今后颁布任何类似的保护用户隐私的法规。据说，这么做是有经济学依据的。大名鼎鼎的波斯纳法官曾著文阐述：保护个人隐私经常是低效的，而特殊保护又没有必要。以经济学观之，商家的“隐私”或商业秘密比用户隐私更有理由受保护（  波斯纳，1981  ）。据此逻辑，与其加强隐私保护，不如促进商家的公平竞争，总效益更高。这便是隐私沦为市场交易的商品，必须面对的利益与辩白。尤其令人担忧的是，在道德伦理和技术手段都败下阵来的今天，法律已是捍卫隐私的最后一道脆弱的防线。
      隐私法如此不堪一击，并不奇怪。立法向来是社会各方利益集团谈判妥协的产物，一般总是向强势方倾斜。如果遵循“经济规律”即市场信条来制定规则，法律就不能妨碍“正常”的商品交换，尤其是实用价值高、市场需求大的商品。而隐私早成了信息市场的宠儿。君不见，个人行为信息支撑着精准投放广告、区别定价；指纹和刷脸，方便了身份识别跟信用追踪；DNA信息则可帮助保险公司甄别投保人风险。难怪隐私保护变得缩手缩脚了，因为所有的强势利益集团都要求法律承认，商家收集个人信息，做成商品，就是科学、正当、高效，故而应当支持。于是，基于技术操作规程，法律将获取和使用隐私分成两类：合法、非法。例如，黑客为非法，因为没有向官方注册；但社交和购物网站合法，只需设置用户选择及相关提示。
      如此立法执法，造成一个假象：仿佛合法取用隐私对人无害，可以放心“分享”。唯有非法入侵才是隐私遭破坏的原因和隐患，才会影响我们的正常生活。所以只消立法禁止、惩罚隐私数据的盗窃泄漏和非法买卖，我们的隐私就安然无恙了。
      这当然是自欺欺人。首先，常识告诉我们，媒体经常报道的个人和团伙盗卖个人信息，由于明显违法，偷偷摸摸见不得人，是撼动不了隐私的道德地位的。真正的威胁来自合法的隐私收集和商品化交易，因为那是系统的规模化的受保护市场行为。那些网络平台和产业巨头，大大小小的网站、店家、服务商，日复一日、年复一年地依法获取加工隐私“原材料”，才是对隐私的最大伤害。其次，法律上那一堆看似细致入微的隐私保护条款，不仅对黑箱操作的“漏洞”防不胜防，还是商家的免责保护机制。大数据AI等信息技术日新月异，黑箱操作是设计使然，关乎效率和商业技术秘密。故有评论认为，提高操作透明度，让信息系统内隐私数据的来龙去脉受监督，有助于保护隐私。欧盟最近颁布的《一般数据保护条例》（GDPR) ，添加了条款，要求算法自动决策的使用者为决策给出解释。这是目前为止，对黑箱现象做出的最严格限制。也许会有一定的效果，但《条例》依然回避了隐私商品化问题，而把注意力导向透明度。这是意味深长的。再看脸书，当它的保护隐私设置被合法或不当“攻破”，造成海量用户信息“泄漏”，面对公众舆论跟政府监管部门的压力，确实，老板公开道歉了，保证采取补救措施，提高透明度，甚至答应让用户看到脸书为广告商提供的自己的画像（profile)。但是，它没忘记重申一句：精准投放广告的商业模式不变。
      商品化成为定局，隐私脱离主体，被合法挖掘追踪分析，广泛用于解读并预测、规制人的欲望、想法和行动，人与隐私的关系就变了。隐私主体失去了话语权，不再是自己隐私的主人和守护者（马丁，1971）。鉴于个人信息的巨大经济价值和政治红利，法律别无选择，只能承认或默许隐私商品化。而公共议题就转变为：谁可以“合法”占有商品化的果实，即商业利益的竞争和垄断。所以，合法或是非法，法律都不可能还人类以隐私之安宁。
      法律保护的效用如此之低，为什么各国，尤其是发达经济体，还在不断强化隐私权的立法和宣传？原因很简单，那是政府部门同立法者目前唯一能做，而不影响“大局”的事情。当然，那也是业界巨头所希望的。比如小扎，今年三月接受CNN采访，就明确邀请国会立法，规制社交网站，说：问题不是该不该规制，而是什么是正确的规则。
      资本非常清醒：隐私关乎人的责任能力，占有隐私并获得保护，就要承担相对应的社会责任。当人们交出隐私（无论自愿或不知情），让商家牟利或政府监管，个人的自由意志选择范围便相应地缩小了。人的自主选择越少，承担责任的能力也越小。反之，商家和政府获取的隐私越多，对用户跟社会的控制力也越强。隐私易手，对应的社会责任并不会消失，是需要重新分配的。而且不仅是责任，还是社会风险管理机制的全盘安排。但市场经济是自利者的王国，资本拿隐私赚大钱，却无意承担附着于隐私的社会责任。这就是为什么，他们一边推动隐私商品化，一边在媒体和立法层面，大声疾呼保障隐私。他们企图让人相信，尽管隐私化作他人财产已是生活常态，原始隐私权仍在自己手中，并受到前所未有的法律保护。只需发扬分享的美德，就会得到最佳补偿，即生活便利。巨头们直言不讳，希望失去隐私的人们一如既往地承担行为主体的责任，而掌控隐私的唱唱法律保护的高调，即可免责而享受用户“分享”的馈赠。
      这，应该就是埃格斯先生设想的零隐私未来的起点同终线。无独有偶，脸书老板早在二〇一〇年就说过，我们的隐私观过时了，  隐私“不再是社会规范”  。大家不仅乐于分享各种信息，而且喜欢向越来越多的陌生人开放自己，“促成了新的社会规范”（约翰逊, 2010）。是的，只要巨头们奉行《圆圈》里的那句台词：知道（隐私）好。知道一切（隐私）更好！法律就救不了隐私。
      
      
     四、隐私终结，意味着什么？
    
      说到这里，隐私经过信息社会商业化的洗礼，命运只有一个去向——走向终结！
      也许，一些占有者以为，自己可以是隐私终结的例外，甚而能够在支配他人隐私的同时，继续保有自己的隐私？然而，人类的总命运是谁也逃不脱的。从目前AI的发展势头看，我们不得不警惕，一种智力优于人类，且具有“自由意志”的独立物种出现。届时，机器人未必“甘当”人类肢体和心智的延伸，而人类却要依靠它才能生存。因此，隐私危机必须放在人机关系中去思考、规划。个人信息的网络储存越多，分析工具越精致高效，硅基智能成长为独立物种而摆脱人类管控的步伐，就会越快。当AI提升至通用智能，能够在多个领域自我学习，不再需要人的知识连同隐私当它的学习素材，一如自学围棋、碾压人类顶级大脑的“阿尔法零”，那一天，将奏响隐私的挽歌。
      不过，隐私的终结，并不意味着人类终结。归根结蒂，人是可以零隐私地活着的。迄今为止，隐私对于人类重要，是因为人受制于较低的信息能力，亦即人类为自己安排了那样的生活秩序。所以一方面，隐私是人类高级智力活动的产物，体现了人对自身价值的期待和尊重；另一方面，一旦人类实现“自我超越”，造出通用人工智能（AGI），让机器取代自己思考、劳动、创造，后隐私时代便降临了。
      进入后隐私时代，人类社会现存的经济基础和上层建筑必然失效了。人类将怎样生活？没有历史经验，没有参照物，很难想象。但有三点可以预期：
      一、那将是一种没有自觉自愿，不知何为荣辱问责，但高效而标准化的低智低能的生活秩序。那里，隐私失去了意义。它不再能培育自由人格，因为系统中没有自由意志的位置。它不再是社会责任的对价，因为人无须自由选择自主行动而承担责任。它也不再是智力活动的衍生品，因为人类主动放弃了发展智力的努力，满足于在无限优化了的天网下执行指令。
      二、社会的中心不再是人与人的关系，而是人机关系和机机关系。人类不复为地球的主人，反倒有可能变成硅基智能系统的累赘。不是有AI专家预测，二十五年后，无人驾驶技术成熟，人类将被禁止驾车上路。无人驾驶的交通系统，其交通规则、道路设计、社区安排等，都是不许出错的。人类驾驶只会破坏科学设计的完美，引发交通事故，降低行车效率。实际上，排斥人类参与、删除人类个性，那样的硅胶智能世界，才可能是高效简洁、完满无缺的一个大“圆圈”。
      三、人类世界本身，共产主义或许是唯一的选项。因为机器人治下，人不但没有了隐私，分工也已消失。所有的个体都集合于一个总体，个人自由即全体的自由，我为人人即人人为我（  冯象，2017  ）。
       人工智能的先驱，已故的麻省理工学院教授明斯基（Marvin Minsky）说过：有朝一日，当我们掌握了建造智力远胜人类的机器的知识，就不得不面对一个奇特的问题，那就是：该不该建造？我很幸运，因为我可以把这一困难的选择留给后人。但我相信，他们不会建造，除非找到很好的理由（  明斯基，1982  ）。明斯基还曾经对深度学习神经网络技术做出悲观的描述（《认知器演算法》，1969, 1987），他的观点被认为阻碍了AI发展达半个世纪之久，因而颇受诟病。但我想，换个角度，这也许是教授对人类最大的贡献：为我们做好准备迎接机器人时代，赢得了宝贵的时间。
      明斯基的智慧提醒我们，对隐私应取审慎节制的态度。也许，停下隐私的深度挖掘和过度商业化，我们会少些便捷、舒适和效率，办事会不那么顺畅。但我们就可以继续辛勤劳动，思考学习；继续拥有自由意志，而担起自己的社会责任。我们将保有隐私同人格尊严。这，才是一种更美好的生活。
      二〇一七年十月初稿，一八年四月定稿  原载《文化纵横》6/2018
      
      参考阅读
      
        波斯纳（Richard Posner）：《正义经济学》（  
       The Economics of Justice
        ），哈佛大学出版社，1981。
         冯象  ：《  我是阿尔法——论人机伦理  》，载《文化纵横》12/2017。
        马丁（George Martin）：《简议长生》（Brief proposal on immortality: an interim solution），载《生物学医学展望》（ 
      Perspectives in Biology and Medicine
      ）14/2:339, 1971。
        明斯基（Marvin Minsky）：  《为什么人以为电脑做不了》（Why People Think Computer Can’t）  ，载《人工智能杂志》（ 
      AI Magazine
      ）3:4, 1982（秋季号）。
        卫斯汀（Alan Westin）：《隐私与自由》（  
       Privacy and Freedom
        ），Athenaeum, 1967。
        约翰逊（Bobbie Johnson）：《隐私不再是社会规范，脸书创始人说》（ 
      Privacy no longer a social norm, says Facebook founder
      ），载《卫报》（ 
      The Guardian
      ）2010.1.10。
      
    
    
    
      Categorized:  社会科学 · SOCIAL SCIENCES  -  评论随笔 · ESSAYS 
      Tagged:  人工智能  -  利求同  -  商业化  -  商品化  -  脸书  -  资本  -  隐私 
    
    
    
      如果您喜欢本站文章，  请订阅我们的电子邮件  ，以便及时获取更新通知。
      好书推荐:  脱销多年新近重印的四卷本奥威尔文集 The Collected Essays, Journalism, and Letters of George Orwell: Volume 1  ,  2  ,  3  ,  4  .
    
    
      
        
           Leave a Reply       
        
        
      
      
    
    
  
  

" class="ssk ssk-email"></a>
    <a href="http://pinterest.com/pin/create/link/?url=http://www.ideobook.com/2745/future-privacy/" class="ssk ssk-pinterest"></a>
    <a href="https://www.tumblr.com/widgets/share/tool?canonicalUrl=http://www.ideobook.com/2745/future-privacy/&title=利求同：隐私的未来&caption=
  

  
  
  
    
       利求同：隐私的未来 
      
        By:  利求同  . 2018-6-5.  7,019 
      
    
    
      “秘密是撒谎，分享是关怀，隐私是偷窃。”
         这是美国科幻作家埃格斯（Dave Eggers）对未来的大胆想象。他的小说《圆圈》（  
      The Circle
       ）拍了  电影  ，这句话是影片里面同名超级公司的训言，同公司建筑的极简主义风格一起，接受“吸科技”的瘾君子朝拜。那里，我们习以为常的道德规范被颠倒了，做成新的信条：藏着隐私是严重的人格缺陷，上缴个人信息等于实现人生自由，光大“分享主义”美德；而保护隐私就视同盗窃，要受新人类的唾弃，并交给新法律制裁。
      隐私，能如此激发作家的想象，应该说是物联网智能时代的一个标记。不过，作为隐私的法定业主，我们得感激埃格斯先生的慷慨。因为在他的超级智能化的未来，隐私仍是有价值的，且依法享有平等的保护。人们只需修正价值观，将隐私从“私”和“隐”的疆域中剥离，转化为信息/数据财产，就能继续熟悉的生活了。当然，这新财产总是落在了别人，例如圆圈公司的手里，留给我们个人的，只是生产和再生产即奉献隐私的许可，人格权的一具空壳。但权利的空壳也是权利，也能给人带来安慰，因而是促进社会和谐美丽所不可少的一项制度。
      事实上，这隐私的未来已经到来。做一个透明人，自愿或被迫交出隐私，供人牟利，业已是生活常态了。只是，价值观的修正跟社会道德转型尚待完成。转型时期，还会有人呼吁，试图保护隐私；隐私的归属和使用上的冲突，却日益频发而尖锐起来。这是因为，在资本当道的条件下，隐私同分享有着不可调和的矛盾。最近脸书在美国乃至全球受到质疑，就是生动的例证。国会一边吵架，一边调查，俄国是否介入或干扰了美国大选，脸书却被爆料曾泄露8,700万用户的个人信息，给一家英国公司。脸书声称，这些用户信息是第三方以“不正当方式”获取的。小扎亲自出面，向公众道歉，保证今后严加管理。殊不知，早在二〇一一年，脸书就用户信息泄露事件做出过几乎同样的承诺。而那承诺之所以未能兑现，是因为无法兑现；实际上，国家法律也不允许兑现。现在的商业模式和残酷的产业竞争，有哪一家网络企业，包括电商大鳄，不是靠挖掘买卖用户信息赚钱的？手里的用户隐私越多，市场就越大，利润就越高。假如隐私当真严加保护，不就等于支柱产业集体自杀了？   
      但是，真正的问题还不是几家大企业的利润多寡。关键在于，这事关乎我们的道德价值和理性选择：人工智能（AI），这一人类引以为傲的创造，信息技术的高峰，很可能与保护隐私是格格不入的。AI以高效、优化为目标，追求的是优于人脑的超级硅基智能。在那个智能体系中，信息是基本元素，是一切事物和生命的记录、编辑与展开。人，整体而言，跟任何碳基物、无机物一样，只是一个信息集。而隐私，进入大数据时代，作为一种游离于人类整体信息集边缘的个体特征，就“过于人性”了——承载了太多的价值立场和法律风险。保护隐私，人类信息集就变得坑坑洼洼，不好用了，所以亟需优化、标准化、去风险化。换言之，隐私成了硅基智能的障碍，是必须清除的杂音；非如此，人类不能同AI结合而融入未来。
      于是，我们不得不直面那一种可能，即隐私的终结。我们必须思考：如果隐私终结，人类将如何生存。
      
      
     一、隐私的可隐性
    
      研究一事物的终结，需要从其兴衰的条件和过程中寻找原因。那么，隐私是因何而来的呢？它又怎样塑造了我们的日常生活，它的消解意味着什么？这些问题的答案至关重要。
      历史地看，隐私是人类对自身生存状态的一种描述，既是社会的客观存在，也是道德伦理的主观认知，因而承载着情感和价值判断。关于隐私，学说繁多，实践更是千姿百态。但万变不离其宗，都包含两个基本要素：一、人的个体有别于群体/社会之公，称之为“私”；二、私的领域，时而需要隔绝于公，视之为“隐”。可以说，隐私的观念，其被社会认可而纳入“私”的范畴，乃是因“公”而生，而获得价值的。隐私既是私与公有别或对立的产物，也是公私赖以共存的条件。
      有学者认为，隐私源于人的动物性。人是独立的个体，同时又是群居动物。人在群体中生活，繁衍生息需要一定的私密空间和时间，才能建立亲疏有别的家庭跟社会关系，私与隐便在其中了。文明开化以后，隐私的观念和习惯，更是人类高级智力活动如宗教、艺术、政治、经济等的产物。渐渐地，隐私就演变为一种个体与群体的生活伦理，超越动物本能，而复杂精致起来，终于成了社会秩序的一根支柱（卫斯汀，1967）。
      这公私对应关系, 早在古希腊，亚里士多德就注意到了。他提出区分家室私事（the oikos）和城邦公务（the polis）这一对范畴的哲学命题，并讨论了自愿行为的概念。由此开启了一个漫长的学术传统，探究隐私同自由意志、自我意识以及自由人格的关系。自由意志是人自主选择而行动的一种能力。所以通常，只有自由意志下的行为，才当得起相应的法律责任和道德评价，无论赏罚、毁誉、愧疚。同理，有了自由意志，教导、说服、审议、禁止、判决等社会机制才能运作。而自由意志的产生和行使，是离不开隐私的环境的。首先，有了隐私，人才能培育道德自我意识，即充分意识到自己与行为后果的联系，即“我”是“我的行为”的“动力因”（efficient cause），从而能够自觉承担后果责任。于是，才产生了对行动的自主选择的心理需求，自由意志才得以培育。所以，没有隐私，就没有自由意志。
      更重要的是，第二，隐私所要求的社会认可同保护，其实是以自由意志，即人对他人和社会负责的能力，为对价的。换言之，消灭隐私，就是消灭人类个体负责的能力。因为，隐私的存在，不仅是自由意志生成和行使的条件，也是个体接受社会评价、承担社会义务的前提。反之，若无隐私，自我意识跟自由意志就失去了植根的土壤，社会评价和个体责任就无所依托。
      如此，私与公共存而辩证统一，我们所知的人类社会及其道德伦理制度，都包含了对隐私和自由意志的认可，虽然程度不一。社会承认并尊重个人（自由人）享有一定的隐私权益，并且或多或少，限制他人（包括政府、企业、团体）对个人信息的索取和使用。相应地，社会要求个人为享有隐私，或他人的不知情、不得干预而付出对价，即为自己的选择和言行负责。也就是说，隐私，作为具有道德价值的利益，是人格尊严的先决条件，也是社会组织、道德伦理、法律问责机制的一块基石。一八九〇年，美国法学家沃伦（Samuel Warren）和布兰代斯（Louis Brandeis）发表了题为“  隐私权  ”的著名论文，第一次系统阐述了所谓“独处的权利”，尝试厘清隐私保护的法律学说和适用规范。隐私权的设立与发展，极大地加强了人们的隐私意识。隐私成了公民的基本权益，享有隐私是现代社会理所当然的一项个人自由；保护隐私，即保护人的尊严，保护我们唯一的生活世界。
      然而今天，这唯一世界，正受到全方位的挑战。随着新型信息技术的迅猛发展和智能终端的普及，隐私首当其冲。一不留神，隐私已是千疮百孔，被那无所不能、无处不在的信息工具盯住了。人们的一举一动，每一个闪念都处于监控之下，不啻一个个透明人。要躲避监控而“独处”，过“正常”日子，几乎不可能了。有史以来第一次，隐私制作成了商品，大规模地买卖。而隐私一旦商品化，不同社会阶层和集团便生出相互冲突的利益诉求，关于隐私的社会共识就名存实亡了。
      表面上，个人似乎仍是隐私的所有者或法律上的主体，对隐私的动物性需求也未变。基于隐私和自由意志的社会道德依旧，保护隐私的法规都好好的；毋宁说，新制定的保护措施越来越严格，更上一层楼了。可是仔细观察，这些未变的方面都不再重要，重要的却彻底变样了：信息技术的“天网”已经布下，隐私无处可藏了！所以，尽管法律规定，隐私应当保护，那藏不住的私，是不成其为隐私的。这样看来，“可隐而不可知”是捍卫隐私的关键。易言之，隐私的成立和维护，可隐性是一项必要条件。因为，破坏了隐，也就同时取消了私，即公私的界限。
      这必要条件遭到破坏，隐私变得可知而失控，正是当下隐私困局的症结所在。一切隐私问题的探讨和对策研究，都不能绕开这一现实。
      
      
     二、信息化和隐私困局
    
      信息时代的大势，是隐私的隐秘性趋近消失。结果，直接危及隐私的两要素，公私有别和私的自处。其始作俑者，叫作隐私的信息化或数码化：隐私被信息技术重新包装，放入虚拟电子黑箱，隔绝于人的感官，被“稀释”处理之后，以“中性化”的数据再现。然而，隐私和信息数据是极不协调的两极。数据是技术产品，往往视为客观中性，外延开放包容；隐私却充满了道德价值，属于人类自我意识的范畴，是主观而收敛排他的。当“隐私数据”被捆绑成一个复合概念，这种不协调就被强行抹去，为隐私数据化，继而商品化铺设通道，隐私的天地就彻底改变了。很快，人们开始接受一种全新的生活方式：零隐私世界。
      我们的观察，可以从隐私的必要条件“可隐性”入手。传统上，关于可隐性的讨论不多。这不是疏忽。从前，日常生活中的隐私，可隐性一向不是问题。仿佛“造物”一开始就恩赐了隐私，让人行使自由意志。人类的感官，获取外界信息的能力有限，眼耳鼻口舌，加上皮肤，远不如许多动物的敏锐好使。一层纸，一段距离，几天的间隔，就足以阻断外界信息的感应接收。而我们引以为傲的大脑，相对于别的动物可称发达，但信息存储的可靠性及处理速度，都很不理想；稍微过量，复杂一点，便束手无策。这就使得个人信息不难保持隐秘。例如，说话的声音跟表情，是瞬间即逝的，通常只有近距离耳闻目睹，才能得知。又如，DNA和脑电波，藏在生物密码中，人的感官无法直接辨认、破译或记录。
      所以，私的自处而有别于公，生活中不许外人窥探隐私，是自然而然形成习惯和道德规范的。正是这种合乎“人的尺度”的可隐性，成全了隐私，让人当上自己隐私的守卫，从而整个社会有了维护隐私的意愿，在道德也在法律层面。这么看，人之享有隐私，藉其培育自由意志，不仅是出于传统的道德选择，还有赖于客观上隐私信息往往具有较高的隐秘性。换一角度，隐私之能够获得保护，在一定程度上也是人们对其可隐性特征的一种认知和回应。
      假如人类满足于“造物”的馈赠，不去触动维护隐私的各样屏障，隐私就可以保持可隐而安全。可是，人类好奇，总想探求新知，创制工具，发现世界的奥秘。终于，到了物联网智能时代，隐私的传统屏障坍塌了。生活完全变了，人必须时刻披露个人信息。从农贸市场买菜用微信支付，到旅游点门票的脸像识别；从政府联网办公，到银行电子转账；从百度搜索，到芝麻信用评分和信息诈骗；还有街头巷尾的摄像头，低头族的手机，直至谷歌眼镜、扫地机器人、汽车传感器、植入手臂的上班打卡芯片……个人信息的收集监控不放过生活的任何一个环节。伴随技术进步，隐私的疆域大大拓展了，连基因信号和下意识的意念，也被挖掘了纳入个人信息。信息化的隐私，是信息爆炸，需要超级计算机来处理，接受各类算法的深度分析，以便追踪、模拟、预测人们的思想和行动。隐私不再可隐。私的自处，公私有别，变得越来越不现实了。
      一般认为，人们尊重隐私，本身便是道德选择。然而在网络世界，隐私的物理载体形态同其他信息并无两样。无论我们的银行存款、股票交易，还是DNA遗传指令、生理特征，都已经化作“0”和“1”的数码序列，由算法处理、电脑存储。那里，隐私的内涵是隐没了的，不会影响技术系统的运作。而隐私的数码序列外形，却丝毫不能出错，否则系统就会罢工。久而久之，信息化的隐私化身为数据而“中性化”，卸下了道德伦理的约束，自由了。
      隐私信息化，带来两个严重后果：一是隐私脱离主体，超越时空，永久地驻扎在信息工具里。人失去了对自己隐私的控制，而受制于信息工具及其主人。第二，电子数码的信息密度低，噪音强，体量庞大，就像一片茂盛的原始丛林，遵循机器的组织原则，虚拟黑箱运作。人自身的信息处理能力对于如此巨大的数据集，是束手无策的，只能依赖机器。而机器依赖性越高，隐私数据的收集者/掌控者的话语权就越大，个人的谈判力就越低。于是，信息社会里，隐私开始自愿或被迫地从“私”（如消费者）向“公”（如商家）流动，在“公”领域快速而大规模聚集，并按照信息工具主人制定的规则，嵌入人们的日常生活。比如，自从社交网站普及，我们的思想表达、兴趣好恶，连同亲友信息就被平台电商收集起来清洗，成了后者的数据财产。接下去的数据交易，则进一步模糊了信息的属性；隐私本身，也因为在公私之间频繁穿梭而不再“纯粹”，虽然仍指向个人或群体，例如网购者/买家的行为与需求信息，同卖方的交易规则交叉互动而产生的信息集；又如，免费使用搜索器生成的数据。这时，个人维护隐私的意愿就显得不那么理直气壮，而难以坚持，直至隐私与道德价值脱钩。如此，私与公这对经典范畴开始游移不定，公私间界限模糊起来，隐私就无处落脚了。
      这就是隐私信息化带来的最严峻的挑战。面对挑战，作为拥有自由意志的人类整体，我们仍有机会做出选择，重建隐私的屏障。然而，新经济选择了隐私的商品化，添上了压垮隐私的最后一根稻草。
      
      
     三、隐私商品化和法律保护的迷思
    
      隐私商品化，标志着资本主义世界对隐私态度的质的变化，也是信息社会转型期矛盾的一个焦点。隐私有用有市，不是新发现。但隐私既是自由人格的条件，也是人的软肋，需要精心呵护。所以，传统道德讲求节制，是包括尊重隐私在内的；拿自己或他人的隐私做交易，就更是可耻了。道德加上信息能力有限，可谓双重的约束，隐私才能一路平安地走来。
      现在，智能终端的天网建成，迅速消解了这两道护卫，把蕴藏在隐私中的经济价值和社会控制力裸露了。这大大刺激了隐私的商业挖掘。人们找出各种正当化的理由，隐私淘金热就像放出笼子的野兽，失控了。个人信息充斥了商品市场，在经济生活中占有越来越大的比重。所谓智能经济，几乎所有最赚钱的企业都在挖掘使用和买卖隐私，不论谷歌、脸书、百度跟阿里巴巴。打开脸书，看看你自己上缴的信息吧：照片视频，留言打招呼的就不说了，每天的生活细节、消费习惯、工作安排，亲友往来等等，事无巨细，连你自己都没注意或忘记了的，统统记录在案。谷歌占有的信息集就更庞大了。这些网络巨头深知，隐私就是财富。于是，隐私被冠以新的身份：以市场需求来定价交易的商品。
      既是商品，就免不了推向市场，“公平”竞争。站在市场经济的立场，挖掘隐私，消费隐私，完全符合发展经济的政策目标。这样一来，尊重隐私、维护隐私的道德和技术屏障，因为有碍市场经济，反而处境尴尬了。资本的策略，是把收集个人信息跟服务的便利、高效、创新挂钩；将分享隐私和焕然一新的消费者感受等同。在饱和的宣传攻势下，商家和政府采集使用个人信息，几乎没有任何阻力，还美其名曰：消费者同商家双赢，老百姓和国家双赢。可是，双赢是市场赢家的说辞；凡是双赢的交易，桌面下面总有一方或第三方要付出代价。智能经济的代价，便是终端用户/消费者交出隐私。表面上，提交隐私信息换取服务和便利，对人只有好处，但其损害后果是潜在或滞后的，包括未来就业发生困难，突然被拒绝医疗保险，或者遭受价格歧视、信用误导（参见拙文《  交出了隐私，再掏空钱袋  》），直至削弱人们负责任的能力或自由意志。
      最近美国一个例子，为此做了绝妙的脚注。二〇一七年三月，国会投票，封杀了联邦通讯委员会（FCC）年前通过的《互联网隐私规则》（IPR）。《规则》是为保护网络用户的隐私而订立的，限制了网商使用和“分享”即出售用户的网上行为信息。诡异的是，封杀理由与保护隐私毫不搭界，而是平衡网商的利益，保障市场的公平竞争。也就是说，围绕《规则》的利益较量，用户的隐私权益根本没在考虑之列。更有甚者，国会还表决禁止FCC今后颁布任何类似的保护用户隐私的法规。据说，这么做是有经济学依据的。大名鼎鼎的波斯纳法官曾著文阐述：保护个人隐私经常是低效的，而特殊保护又没有必要。以经济学观之，商家的“隐私”或商业秘密比用户隐私更有理由受保护（  波斯纳，1981  ）。据此逻辑，与其加强隐私保护，不如促进商家的公平竞争，总效益更高。这便是隐私沦为市场交易的商品，必须面对的利益与辩白。尤其令人担忧的是，在道德伦理和技术手段都败下阵来的今天，法律已是捍卫隐私的最后一道脆弱的防线。
      隐私法如此不堪一击，并不奇怪。立法向来是社会各方利益集团谈判妥协的产物，一般总是向强势方倾斜。如果遵循“经济规律”即市场信条来制定规则，法律就不能妨碍“正常”的商品交换，尤其是实用价值高、市场需求大的商品。而隐私早成了信息市场的宠儿。君不见，个人行为信息支撑着精准投放广告、区别定价；指纹和刷脸，方便了身份识别跟信用追踪；DNA信息则可帮助保险公司甄别投保人风险。难怪隐私保护变得缩手缩脚了，因为所有的强势利益集团都要求法律承认，商家收集个人信息，做成商品，就是科学、正当、高效，故而应当支持。于是，基于技术操作规程，法律将获取和使用隐私分成两类：合法、非法。例如，黑客为非法，因为没有向官方注册；但社交和购物网站合法，只需设置用户选择及相关提示。
      如此立法执法，造成一个假象：仿佛合法取用隐私对人无害，可以放心“分享”。唯有非法入侵才是隐私遭破坏的原因和隐患，才会影响我们的正常生活。所以只消立法禁止、惩罚隐私数据的盗窃泄漏和非法买卖，我们的隐私就安然无恙了。
      这当然是自欺欺人。首先，常识告诉我们，媒体经常报道的个人和团伙盗卖个人信息，由于明显违法，偷偷摸摸见不得人，是撼动不了隐私的道德地位的。真正的威胁来自合法的隐私收集和商品化交易，因为那是系统的规模化的受保护市场行为。那些网络平台和产业巨头，大大小小的网站、店家、服务商，日复一日、年复一年地依法获取加工隐私“原材料”，才是对隐私的最大伤害。其次，法律上那一堆看似细致入微的隐私保护条款，不仅对黑箱操作的“漏洞”防不胜防，还是商家的免责保护机制。大数据AI等信息技术日新月异，黑箱操作是设计使然，关乎效率和商业技术秘密。故有评论认为，提高操作透明度，让信息系统内隐私数据的来龙去脉受监督，有助于保护隐私。欧盟最近颁布的《一般数据保护条例》（GDPR) ，添加了条款，要求算法自动决策的使用者为决策给出解释。这是目前为止，对黑箱现象做出的最严格限制。也许会有一定的效果，但《条例》依然回避了隐私商品化问题，而把注意力导向透明度。这是意味深长的。再看脸书，当它的保护隐私设置被合法或不当“攻破”，造成海量用户信息“泄漏”，面对公众舆论跟政府监管部门的压力，确实，老板公开道歉了，保证采取补救措施，提高透明度，甚至答应让用户看到脸书为广告商提供的自己的画像（profile)。但是，它没忘记重申一句：精准投放广告的商业模式不变。
      商品化成为定局，隐私脱离主体，被合法挖掘追踪分析，广泛用于解读并预测、规制人的欲望、想法和行动，人与隐私的关系就变了。隐私主体失去了话语权，不再是自己隐私的主人和守护者（马丁，1971）。鉴于个人信息的巨大经济价值和政治红利，法律别无选择，只能承认或默许隐私商品化。而公共议题就转变为：谁可以“合法”占有商品化的果实，即商业利益的竞争和垄断。所以，合法或是非法，法律都不可能还人类以隐私之安宁。
      法律保护的效用如此之低，为什么各国，尤其是发达经济体，还在不断强化隐私权的立法和宣传？原因很简单，那是政府部门同立法者目前唯一能做，而不影响“大局”的事情。当然，那也是业界巨头所希望的。比如小扎，今年三月接受CNN采访，就明确邀请国会立法，规制社交网站，说：问题不是该不该规制，而是什么是正确的规则。
      资本非常清醒：隐私关乎人的责任能力，占有隐私并获得保护，就要承担相对应的社会责任。当人们交出隐私（无论自愿或不知情），让商家牟利或政府监管，个人的自由意志选择范围便相应地缩小了。人的自主选择越少，承担责任的能力也越小。反之，商家和政府获取的隐私越多，对用户跟社会的控制力也越强。隐私易手，对应的社会责任并不会消失，是需要重新分配的。而且不仅是责任，还是社会风险管理机制的全盘安排。但市场经济是自利者的王国，资本拿隐私赚大钱，却无意承担附着于隐私的社会责任。这就是为什么，他们一边推动隐私商品化，一边在媒体和立法层面，大声疾呼保障隐私。他们企图让人相信，尽管隐私化作他人财产已是生活常态，原始隐私权仍在自己手中，并受到前所未有的法律保护。只需发扬分享的美德，就会得到最佳补偿，即生活便利。巨头们直言不讳，希望失去隐私的人们一如既往地承担行为主体的责任，而掌控隐私的唱唱法律保护的高调，即可免责而享受用户“分享”的馈赠。
      这，应该就是埃格斯先生设想的零隐私未来的起点同终线。无独有偶，脸书老板早在二〇一〇年就说过，我们的隐私观过时了，  隐私“不再是社会规范”  。大家不仅乐于分享各种信息，而且喜欢向越来越多的陌生人开放自己，“促成了新的社会规范”（约翰逊, 2010）。是的，只要巨头们奉行《圆圈》里的那句台词：知道（隐私）好。知道一切（隐私）更好！法律就救不了隐私。
      
      
     四、隐私终结，意味着什么？
    
      说到这里，隐私经过信息社会商业化的洗礼，命运只有一个去向——走向终结！
      也许，一些占有者以为，自己可以是隐私终结的例外，甚而能够在支配他人隐私的同时，继续保有自己的隐私？然而，人类的总命运是谁也逃不脱的。从目前AI的发展势头看，我们不得不警惕，一种智力优于人类，且具有“自由意志”的独立物种出现。届时，机器人未必“甘当”人类肢体和心智的延伸，而人类却要依靠它才能生存。因此，隐私危机必须放在人机关系中去思考、规划。个人信息的网络储存越多，分析工具越精致高效，硅基智能成长为独立物种而摆脱人类管控的步伐，就会越快。当AI提升至通用智能，能够在多个领域自我学习，不再需要人的知识连同隐私当它的学习素材，一如自学围棋、碾压人类顶级大脑的“阿尔法零”，那一天，将奏响隐私的挽歌。
      不过，隐私的终结，并不意味着人类终结。归根结蒂，人是可以零隐私地活着的。迄今为止，隐私对于人类重要，是因为人受制于较低的信息能力，亦即人类为自己安排了那样的生活秩序。所以一方面，隐私是人类高级智力活动的产物，体现了人对自身价值的期待和尊重；另一方面，一旦人类实现“自我超越”，造出通用人工智能（AGI），让机器取代自己思考、劳动、创造，后隐私时代便降临了。
      进入后隐私时代，人类社会现存的经济基础和上层建筑必然失效了。人类将怎样生活？没有历史经验，没有参照物，很难想象。但有三点可以预期：
      一、那将是一种没有自觉自愿，不知何为荣辱问责，但高效而标准化的低智低能的生活秩序。那里，隐私失去了意义。它不再能培育自由人格，因为系统中没有自由意志的位置。它不再是社会责任的对价，因为人无须自由选择自主行动而承担责任。它也不再是智力活动的衍生品，因为人类主动放弃了发展智力的努力，满足于在无限优化了的天网下执行指令。
      二、社会的中心不再是人与人的关系，而是人机关系和机机关系。人类不复为地球的主人，反倒有可能变成硅基智能系统的累赘。不是有AI专家预测，二十五年后，无人驾驶技术成熟，人类将被禁止驾车上路。无人驾驶的交通系统，其交通规则、道路设计、社区安排等，都是不许出错的。人类驾驶只会破坏科学设计的完美，引发交通事故，降低行车效率。实际上，排斥人类参与、删除人类个性，那样的硅胶智能世界，才可能是高效简洁、完满无缺的一个大“圆圈”。
      三、人类世界本身，共产主义或许是唯一的选项。因为机器人治下，人不但没有了隐私，分工也已消失。所有的个体都集合于一个总体，个人自由即全体的自由，我为人人即人人为我（  冯象，2017  ）。
       人工智能的先驱，已故的麻省理工学院教授明斯基（Marvin Minsky）说过：有朝一日，当我们掌握了建造智力远胜人类的机器的知识，就不得不面对一个奇特的问题，那就是：该不该建造？我很幸运，因为我可以把这一困难的选择留给后人。但我相信，他们不会建造，除非找到很好的理由（  明斯基，1982  ）。明斯基还曾经对深度学习神经网络技术做出悲观的描述（《认知器演算法》，1969, 1987），他的观点被认为阻碍了AI发展达半个世纪之久，因而颇受诟病。但我想，换个角度，这也许是教授对人类最大的贡献：为我们做好准备迎接机器人时代，赢得了宝贵的时间。
      明斯基的智慧提醒我们，对隐私应取审慎节制的态度。也许，停下隐私的深度挖掘和过度商业化，我们会少些便捷、舒适和效率，办事会不那么顺畅。但我们就可以继续辛勤劳动，思考学习；继续拥有自由意志，而担起自己的社会责任。我们将保有隐私同人格尊严。这，才是一种更美好的生活。
      二〇一七年十月初稿，一八年四月定稿  原载《文化纵横》6/2018
      
      参考阅读
      
        波斯纳（Richard Posner）：《正义经济学》（  
       The Economics of Justice
        ），哈佛大学出版社，1981。
         冯象  ：《  我是阿尔法——论人机伦理  》，载《文化纵横》12/2017。
        马丁（George Martin）：《简议长生》（Brief proposal on immortality: an interim solution），载《生物学医学展望》（ 
      Perspectives in Biology and Medicine
      ）14/2:339, 1971。
        明斯基（Marvin Minsky）：  《为什么人以为电脑做不了》（Why People Think Computer Can’t）  ，载《人工智能杂志》（ 
      AI Magazine
      ）3:4, 1982（秋季号）。
        卫斯汀（Alan Westin）：《隐私与自由》（  
       Privacy and Freedom
        ），Athenaeum, 1967。
        约翰逊（Bobbie Johnson）：《隐私不再是社会规范，脸书创始人说》（ 
      Privacy no longer a social norm, says Facebook founder
      ），载《卫报》（ 
      The Guardian
      ）2010.1.10。
      
    
    
    
      Categorized:  社会科学 · SOCIAL SCIENCES  -  评论随笔 · ESSAYS 
      Tagged:  人工智能  -  利求同  -  商业化  -  商品化  -  脸书  -  资本  -  隐私 
    
    
    
      如果您喜欢本站文章，  请订阅我们的电子邮件  ，以便及时获取更新通知。
      好书推荐:  脱销多年新近重印的四卷本奥威尔文集 The Collected Essays, Journalism, and Letters of George Orwell: Volume 1  ,  2  ,  3  ,  4  .
    
    
      
        
           Leave a Reply       
        
        
      
      
    
    
  
  

&tags=觀點" class="ssk ssk-tumblr"></a>
    <a href="https://buffer.com/add?text=利求同：隐私的未来&url=http://www.ideobook.com/2745/future-privacy/" class="ssk ssk-buffer"></a>
</div>


    <div id="main" role="main" class="container">
      
  <!-- Html Elements for Search -->
  <ul id="results-container" class="searched" style="color: #2980B9;"></ul>

  <script src="/opinion/assets/js/simple-jekyll-search.min.js"></script>

  <!-- Configuration -->
  <script>
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    json: '/opinion/search.json',
    searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a><time>{date}</time><a class="tag">{category}</a></li>',
    noResultsText: '没找到',
    limit: 100,
    fuzzy: false,
    exclude: ['Welcome']
  })

  </script>

      







  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    


  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    



<article class="post">
  <h1>利求同：隐私的未来</h1>
  <!-- Look the author details up from the site config. -->
  

  <div>
    <span class="date">
      2018-06-05
    </span>

    <!-- Output author details if some exist. -->
    
      
        <span>
            <!-- Personal Info. -->
            <a  style="font-size:14px;">作者: 利求同</a>
        </span>
      
    


    <ul class="tag">
      <li>
        <a href="https://nodebe4.github.io/opinion/categories/#智识">
          智识
        </a>
      </li>
    </ul>

    
        <span>
            <!-- Personal Info. -->
            <a href="http://www.ideobook.com/2745/future-privacy/" style="font-size:14px;">原文</a>
        </span>
    

    <span style="float: right;" title="智识的其它文章">
      <a style="font-size: 14px;" rel="nofollow" href="#sametag" class="tags">#智识 的其它文章</a>
    </span>

  </div>

  <div class="entry">
    
    
    
    <article class="post-entry clearfix post-2745 post type-post status-publish format-standard has-post-thumbnail hentry category-social-sciences category-essays tag-1153 tag-38 tag-1320 tag-1022 tag-1322 tag-1321 tag-736">
  <div class="post-entry-thumbnail">
<img alt="利求同：隐私的未来" src="http://www.ideobook.com/img/annuit-coeptis-1200x292.jpg" />
  </div>
  <!-- /blog-entry-thumbnail -->
  <div class="post-entry-text clearfix">
    <header>
      <h1 id="section"> 利求同：隐私的未来 </h1>
      <ul class="post-entry-meta">
        <li>By: <a href="http://www.ideobook.com/liqiutong/" title="查看 利求同 的作者主页"> 利求同 </a> . 2018-6-5. <a href="http://www.ideobook.com/372/post-views-count/" title="统计说明"> 7,019 </a></li>
      </ul>
    </header>
    <div class="post-entry-content">
      <p>“秘密是撒谎，分享是关怀，隐私是偷窃。”</p>
      <p><a href="https://amzn.to/2kX6rEP"> <img alt="" src="/img/circle_movie_poster.jpg" style="float: right; margin: 5px 0 35px 40px;" /> </a> 这是美国科幻作家埃格斯（Dave Eggers）对未来的大胆想象。他的小说《圆圈》（ <a href="https://amzn.to/2xJK27r"> <em>
      The Circle
     </em> </a> ）拍了 <a href="https://amzn.to/2kX6rEP"> 电影 </a> ，这句话是影片里面同名超级公司的训言，同公司建筑的极简主义风格一起，接受“吸科技”的瘾君子朝拜。那里，我们习以为常的道德规范被颠倒了，做成新的信条：藏着隐私是严重的人格缺陷，上缴个人信息等于实现人生自由，光大“分享主义”美德；而保护隐私就视同盗窃，要受新人类的唾弃，并交给新法律制裁。</p>
      <p>隐私，能如此激发作家的想象，应该说是物联网智能时代的一个标记。不过，作为隐私的法定业主，我们得感激埃格斯先生的慷慨。因为在他的超级智能化的未来，隐私仍是有价值的，且依法享有平等的保护。人们只需修正价值观，将隐私从“私”和“隐”的疆域中剥离，转化为信息/数据财产，就能继续熟悉的生活了。当然，这新财产总是落在了别人，例如圆圈公司的手里，留给我们个人的，只是生产和再生产即奉献隐私的许可，人格权的一具空壳。但权利的空壳也是权利，也能给人带来安慰，因而是促进社会和谐美丽所不可少的一项制度。</p>
      <p>事实上，这隐私的未来已经到来。做一个透明人，自愿或被迫交出隐私，供人牟利，业已是生活常态了。只是，价值观的修正跟社会道德转型尚待完成。转型时期，还会有人呼吁，试图保护隐私；隐私的归属和使用上的冲突，却日益频发而尖锐起来。这是因为，在资本当道的条件下，隐私同分享有着不可调和的矛盾。最近脸书在美国乃至全球受到质疑，就是生动的例证。国会一边吵架，一边调查，俄国是否介入或干扰了美国大选，脸书却被爆料曾泄露8,700万用户的个人信息，给一家英国公司。脸书声称，这些用户信息是第三方以“不正当方式”获取的。小扎亲自出面，向公众道歉，保证今后严加管理。殊不知，早在二〇一一年，脸书就用户信息泄露事件做出过几乎同样的承诺。而那承诺之所以未能兑现，是因为无法兑现；实际上，国家法律也不允许兑现。现在的商业模式和残酷的产业竞争，有哪一家网络企业，包括电商大鳄，不是靠挖掘买卖用户信息赚钱的？手里的用户隐私越多，市场就越大，利润就越高。假如隐私当真严加保护，不就等于支柱产业集体自杀了？ <br /> <span id="more-2745"> </span></p>
      <p>但是，真正的问题还不是几家大企业的利润多寡。关键在于，这事关乎我们的道德价值和理性选择：人工智能（AI），这一人类引以为傲的创造，信息技术的高峰，很可能与保护隐私是格格不入的。AI以高效、优化为目标，追求的是优于人脑的超级硅基智能。在那个智能体系中，信息是基本元素，是一切事物和生命的记录、编辑与展开。人，整体而言，跟任何碳基物、无机物一样，只是一个信息集。而隐私，进入大数据时代，作为一种游离于人类整体信息集边缘的个体特征，就“过于人性”了——承载了太多的价值立场和法律风险。保护隐私，人类信息集就变得坑坑洼洼，不好用了，所以亟需优化、标准化、去风险化。换言之，隐私成了硅基智能的障碍，是必须清除的杂音；非如此，人类不能同AI结合而融入未来。</p>
      <p>于是，我们不得不直面那一种可能，即隐私的终结。我们必须思考：如果隐私终结，人类将如何生存。</p>
      <p></p>
      <p style="text-align: center;"><strong>
     一、隐私的可隐性
    </strong></p>
      <p>研究一事物的终结，需要从其兴衰的条件和过程中寻找原因。那么，隐私是因何而来的呢？它又怎样塑造了我们的日常生活，它的消解意味着什么？这些问题的答案至关重要。</p>
      <p>历史地看，隐私是人类对自身生存状态的一种描述，既是社会的客观存在，也是道德伦理的主观认知，因而承载着情感和价值判断。关于隐私，学说繁多，实践更是千姿百态。但万变不离其宗，都包含两个基本要素：一、人的个体有别于群体/社会之公，称之为“私”；二、私的领域，时而需要隔绝于公，视之为“隐”。可以说，隐私的观念，其被社会认可而纳入“私”的范畴，乃是因“公”而生，而获得价值的。隐私既是私与公有别或对立的产物，也是公私赖以共存的条件。</p>
      <p>有学者认为，隐私源于人的动物性。人是独立的个体，同时又是群居动物。人在群体中生活，繁衍生息需要一定的私密空间和时间，才能建立亲疏有别的家庭跟社会关系，私与隐便在其中了。文明开化以后，隐私的观念和习惯，更是人类高级智力活动如宗教、艺术、政治、经济等的产物。渐渐地，隐私就演变为一种个体与群体的生活伦理，超越动物本能，而复杂精致起来，终于成了社会秩序的一根支柱（卫斯汀，1967）。</p>
      <p>这公私对应关系, 早在古希腊，亚里士多德就注意到了。他提出区分家室私事（the oikos）和城邦公务（the polis）这一对范畴的哲学命题，并讨论了自愿行为的概念。由此开启了一个漫长的学术传统，探究隐私同自由意志、自我意识以及自由人格的关系。自由意志是人自主选择而行动的一种能力。所以通常，只有自由意志下的行为，才当得起相应的法律责任和道德评价，无论赏罚、毁誉、愧疚。同理，有了自由意志，教导、说服、审议、禁止、判决等社会机制才能运作。而自由意志的产生和行使，是离不开隐私的环境的。首先，有了隐私，人才能培育道德自我意识，即充分意识到自己与行为后果的联系，即“我”是“我的行为”的“动力因”（efficient cause），从而能够自觉承担后果责任。于是，才产生了对行动的自主选择的心理需求，自由意志才得以培育。所以，没有隐私，就没有自由意志。</p>
      <p>更重要的是，第二，隐私所要求的社会认可同保护，其实是以自由意志，即人对他人和社会负责的能力，为对价的。换言之，消灭隐私，就是消灭人类个体负责的能力。因为，隐私的存在，不仅是自由意志生成和行使的条件，也是个体接受社会评价、承担社会义务的前提。反之，若无隐私，自我意识跟自由意志就失去了植根的土壤，社会评价和个体责任就无所依托。</p>
      <p>如此，私与公共存而辩证统一，我们所知的人类社会及其道德伦理制度，都包含了对隐私和自由意志的认可，虽然程度不一。社会承认并尊重个人（自由人）享有一定的隐私权益，并且或多或少，限制他人（包括政府、企业、团体）对个人信息的索取和使用。相应地，社会要求个人为享有隐私，或他人的不知情、不得干预而付出对价，即为自己的选择和言行负责。也就是说，隐私，作为具有道德价值的利益，是人格尊严的先决条件，也是社会组织、道德伦理、法律问责机制的一块基石。一八九〇年，美国法学家沃伦（Samuel Warren）和布兰代斯（Louis Brandeis）发表了题为“ <a href="http://www.cs.cornell.edu/~shmat/courses/cs5436/warren-brandeis.pdf"> 隐私权 </a> ”的著名论文，第一次系统阐述了所谓“独处的权利”，尝试厘清隐私保护的法律学说和适用规范。隐私权的设立与发展，极大地加强了人们的隐私意识。隐私成了公民的基本权益，享有隐私是现代社会理所当然的一项个人自由；保护隐私，即保护人的尊严，保护我们唯一的生活世界。</p>
      <p>然而今天，这唯一世界，正受到全方位的挑战。随着新型信息技术的迅猛发展和智能终端的普及，隐私首当其冲。一不留神，隐私已是千疮百孔，被那无所不能、无处不在的信息工具盯住了。人们的一举一动，每一个闪念都处于监控之下，不啻一个个透明人。要躲避监控而“独处”，过“正常”日子，几乎不可能了。有史以来第一次，隐私制作成了商品，大规模地买卖。而隐私一旦商品化，不同社会阶层和集团便生出相互冲突的利益诉求，关于隐私的社会共识就名存实亡了。</p>
      <p>表面上，个人似乎仍是隐私的所有者或法律上的主体，对隐私的动物性需求也未变。基于隐私和自由意志的社会道德依旧，保护隐私的法规都好好的；毋宁说，新制定的保护措施越来越严格，更上一层楼了。可是仔细观察，这些未变的方面都不再重要，重要的却彻底变样了：信息技术的“天网”已经布下，隐私无处可藏了！所以，尽管法律规定，隐私应当保护，那藏不住的私，是不成其为隐私的。这样看来，“可隐而不可知”是捍卫隐私的关键。易言之，隐私的成立和维护，可隐性是一项必要条件。因为，破坏了隐，也就同时取消了私，即公私的界限。</p>
      <p>这必要条件遭到破坏，隐私变得可知而失控，正是当下隐私困局的症结所在。一切隐私问题的探讨和对策研究，都不能绕开这一现实。</p>
      <p></p>
      <p style="text-align: center;"><strong>
     二、信息化和隐私困局
    </strong></p>
      <p>信息时代的大势，是隐私的隐秘性趋近消失。结果，直接危及隐私的两要素，公私有别和私的自处。其始作俑者，叫作隐私的信息化或数码化：隐私被信息技术重新包装，放入虚拟电子黑箱，隔绝于人的感官，被“稀释”处理之后，以“中性化”的数据再现。然而，隐私和信息数据是极不协调的两极。数据是技术产品，往往视为客观中性，外延开放包容；隐私却充满了道德价值，属于人类自我意识的范畴，是主观而收敛排他的。当“隐私数据”被捆绑成一个复合概念，这种不协调就被强行抹去，为隐私数据化，继而商品化铺设通道，隐私的天地就彻底改变了。很快，人们开始接受一种全新的生活方式：零隐私世界。</p>
      <p>我们的观察，可以从隐私的必要条件“可隐性”入手。传统上，关于可隐性的讨论不多。这不是疏忽。从前，日常生活中的隐私，可隐性一向不是问题。仿佛“造物”一开始就恩赐了隐私，让人行使自由意志。人类的感官，获取外界信息的能力有限，眼耳鼻口舌，加上皮肤，远不如许多动物的敏锐好使。一层纸，一段距离，几天的间隔，就足以阻断外界信息的感应接收。而我们引以为傲的大脑，相对于别的动物可称发达，但信息存储的可靠性及处理速度，都很不理想；稍微过量，复杂一点，便束手无策。这就使得个人信息不难保持隐秘。例如，说话的声音跟表情，是瞬间即逝的，通常只有近距离耳闻目睹，才能得知。又如，DNA和脑电波，藏在生物密码中，人的感官无法直接辨认、破译或记录。</p>
      <p>所以，私的自处而有别于公，生活中不许外人窥探隐私，是自然而然形成习惯和道德规范的。正是这种合乎“人的尺度”的可隐性，成全了隐私，让人当上自己隐私的守卫，从而整个社会有了维护隐私的意愿，在道德也在法律层面。这么看，人之享有隐私，藉其培育自由意志，不仅是出于传统的道德选择，还有赖于客观上隐私信息往往具有较高的隐秘性。换一角度，隐私之能够获得保护，在一定程度上也是人们对其可隐性特征的一种认知和回应。</p>
      <p>假如人类满足于“造物”的馈赠，不去触动维护隐私的各样屏障，隐私就可以保持可隐而安全。可是，人类好奇，总想探求新知，创制工具，发现世界的奥秘。终于，到了物联网智能时代，隐私的传统屏障坍塌了。生活完全变了，人必须时刻披露个人信息。从农贸市场买菜用微信支付，到旅游点门票的脸像识别；从政府联网办公，到银行电子转账；从百度搜索，到芝麻信用评分和信息诈骗；还有街头巷尾的摄像头，低头族的手机，直至谷歌眼镜、扫地机器人、汽车传感器、植入手臂的上班打卡芯片……个人信息的收集监控不放过生活的任何一个环节。伴随技术进步，隐私的疆域大大拓展了，连基因信号和下意识的意念，也被挖掘了纳入个人信息。信息化的隐私，是信息爆炸，需要超级计算机来处理，接受各类算法的深度分析，以便追踪、模拟、预测人们的思想和行动。隐私不再可隐。私的自处，公私有别，变得越来越不现实了。</p>
      <p>一般认为，人们尊重隐私，本身便是道德选择。然而在网络世界，隐私的物理载体形态同其他信息并无两样。无论我们的银行存款、股票交易，还是DNA遗传指令、生理特征，都已经化作“0”和“1”的数码序列，由算法处理、电脑存储。那里，隐私的内涵是隐没了的，不会影响技术系统的运作。而隐私的数码序列外形，却丝毫不能出错，否则系统就会罢工。久而久之，信息化的隐私化身为数据而“中性化”，卸下了道德伦理的约束，自由了。</p>
      <p>隐私信息化，带来两个严重后果：一是隐私脱离主体，超越时空，永久地驻扎在信息工具里。人失去了对自己隐私的控制，而受制于信息工具及其主人。第二，电子数码的信息密度低，噪音强，体量庞大，就像一片茂盛的原始丛林，遵循机器的组织原则，虚拟黑箱运作。人自身的信息处理能力对于如此巨大的数据集，是束手无策的，只能依赖机器。而机器依赖性越高，隐私数据的收集者/掌控者的话语权就越大，个人的谈判力就越低。于是，信息社会里，隐私开始自愿或被迫地从“私”（如消费者）向“公”（如商家）流动，在“公”领域快速而大规模聚集，并按照信息工具主人制定的规则，嵌入人们的日常生活。比如，自从社交网站普及，我们的思想表达、兴趣好恶，连同亲友信息就被平台电商收集起来清洗，成了后者的数据财产。接下去的数据交易，则进一步模糊了信息的属性；隐私本身，也因为在公私之间频繁穿梭而不再“纯粹”，虽然仍指向个人或群体，例如网购者/买家的行为与需求信息，同卖方的交易规则交叉互动而产生的信息集；又如，免费使用搜索器生成的数据。这时，个人维护隐私的意愿就显得不那么理直气壮，而难以坚持，直至隐私与道德价值脱钩。如此，私与公这对经典范畴开始游移不定，公私间界限模糊起来，隐私就无处落脚了。</p>
      <p>这就是隐私信息化带来的最严峻的挑战。面对挑战，作为拥有自由意志的人类整体，我们仍有机会做出选择，重建隐私的屏障。然而，新经济选择了隐私的商品化，添上了压垮隐私的最后一根稻草。</p>
      <p></p>
      <p style="text-align: center;"><strong>
     三、隐私商品化和法律保护的迷思
    </strong></p>
      <p>隐私商品化，标志着资本主义世界对隐私态度的质的变化，也是信息社会转型期矛盾的一个焦点。隐私有用有市，不是新发现。但隐私既是自由人格的条件，也是人的软肋，需要精心呵护。所以，传统道德讲求节制，是包括尊重隐私在内的；拿自己或他人的隐私做交易，就更是可耻了。道德加上信息能力有限，可谓双重的约束，隐私才能一路平安地走来。</p>
      <p>现在，智能终端的天网建成，迅速消解了这两道护卫，把蕴藏在隐私中的经济价值和社会控制力裸露了。这大大刺激了隐私的商业挖掘。人们找出各种正当化的理由，隐私淘金热就像放出笼子的野兽，失控了。个人信息充斥了商品市场，在经济生活中占有越来越大的比重。所谓智能经济，几乎所有最赚钱的企业都在挖掘使用和买卖隐私，不论谷歌、脸书、百度跟阿里巴巴。打开脸书，看看你自己上缴的信息吧：照片视频，留言打招呼的就不说了，每天的生活细节、消费习惯、工作安排，亲友往来等等，事无巨细，连你自己都没注意或忘记了的，统统记录在案。谷歌占有的信息集就更庞大了。这些网络巨头深知，隐私就是财富。于是，隐私被冠以新的身份：以市场需求来定价交易的商品。</p>
      <p>既是商品，就免不了推向市场，“公平”竞争。站在市场经济的立场，挖掘隐私，消费隐私，完全符合发展经济的政策目标。这样一来，尊重隐私、维护隐私的道德和技术屏障，因为有碍市场经济，反而处境尴尬了。资本的策略，是把收集个人信息跟服务的便利、高效、创新挂钩；将分享隐私和焕然一新的消费者感受等同。在饱和的宣传攻势下，商家和政府采集使用个人信息，几乎没有任何阻力，还美其名曰：消费者同商家双赢，老百姓和国家双赢。可是，双赢是市场赢家的说辞；凡是双赢的交易，桌面下面总有一方或第三方要付出代价。智能经济的代价，便是终端用户/消费者交出隐私。表面上，提交隐私信息换取服务和便利，对人只有好处，但其损害后果是潜在或滞后的，包括未来就业发生困难，突然被拒绝医疗保险，或者遭受价格歧视、信用误导（参见拙文《 <a href="/2415/privacy-money-bag/"> 交出了隐私，再掏空钱袋 </a> 》），直至削弱人们负责任的能力或自由意志。</p>
      <p>最近美国一个例子，为此做了绝妙的脚注。二〇一七年三月，国会投票，封杀了联邦通讯委员会（FCC）年前通过的《互联网隐私规则》（IPR）。《规则》是为保护网络用户的隐私而订立的，限制了网商使用和“分享”即出售用户的网上行为信息。诡异的是，封杀理由与保护隐私毫不搭界，而是平衡网商的利益，保障市场的公平竞争。也就是说，围绕《规则》的利益较量，用户的隐私权益根本没在考虑之列。更有甚者，国会还表决禁止FCC今后颁布任何类似的保护用户隐私的法规。据说，这么做是有经济学依据的。大名鼎鼎的波斯纳法官曾著文阐述：保护个人隐私经常是低效的，而特殊保护又没有必要。以经济学观之，商家的“隐私”或商业秘密比用户隐私更有理由受保护（ <a href="https://amzn.to/2Jujpba"> 波斯纳，1981 </a> ）。据此逻辑，与其加强隐私保护，不如促进商家的公平竞争，总效益更高。这便是隐私沦为市场交易的商品，必须面对的利益与辩白。尤其令人担忧的是，在道德伦理和技术手段都败下阵来的今天，法律已是捍卫隐私的最后一道脆弱的防线。</p>
      <p>隐私法如此不堪一击，并不奇怪。立法向来是社会各方利益集团谈判妥协的产物，一般总是向强势方倾斜。如果遵循“经济规律”即市场信条来制定规则，法律就不能妨碍“正常”的商品交换，尤其是实用价值高、市场需求大的商品。而隐私早成了信息市场的宠儿。君不见，个人行为信息支撑着精准投放广告、区别定价；指纹和刷脸，方便了身份识别跟信用追踪；DNA信息则可帮助保险公司甄别投保人风险。难怪隐私保护变得缩手缩脚了，因为所有的强势利益集团都要求法律承认，商家收集个人信息，做成商品，就是科学、正当、高效，故而应当支持。于是，基于技术操作规程，法律将获取和使用隐私分成两类：合法、非法。例如，黑客为非法，因为没有向官方注册；但社交和购物网站合法，只需设置用户选择及相关提示。</p>
      <p>如此立法执法，造成一个假象：仿佛合法取用隐私对人无害，可以放心“分享”。唯有非法入侵才是隐私遭破坏的原因和隐患，才会影响我们的正常生活。所以只消立法禁止、惩罚隐私数据的盗窃泄漏和非法买卖，我们的隐私就安然无恙了。</p>
      <p>这当然是自欺欺人。首先，常识告诉我们，媒体经常报道的个人和团伙盗卖个人信息，由于明显违法，偷偷摸摸见不得人，是撼动不了隐私的道德地位的。真正的威胁来自合法的隐私收集和商品化交易，因为那是系统的规模化的受保护市场行为。那些网络平台和产业巨头，大大小小的网站、店家、服务商，日复一日、年复一年地依法获取加工隐私“原材料”，才是对隐私的最大伤害。其次，法律上那一堆看似细致入微的隐私保护条款，不仅对黑箱操作的“漏洞”防不胜防，还是商家的免责保护机制。大数据AI等信息技术日新月异，黑箱操作是设计使然，关乎效率和商业技术秘密。故有评论认为，提高操作透明度，让信息系统内隐私数据的来龙去脉受监督，有助于保护隐私。欧盟最近颁布的《一般数据保护条例》（GDPR) ，添加了条款，要求算法自动决策的使用者为决策给出解释。这是目前为止，对黑箱现象做出的最严格限制。也许会有一定的效果，但《条例》依然回避了隐私商品化问题，而把注意力导向透明度。这是意味深长的。再看脸书，当它的保护隐私设置被合法或不当“攻破”，造成海量用户信息“泄漏”，面对公众舆论跟政府监管部门的压力，确实，老板公开道歉了，保证采取补救措施，提高透明度，甚至答应让用户看到脸书为广告商提供的自己的画像（profile)。但是，它没忘记重申一句：精准投放广告的商业模式不变。</p>
      <p>商品化成为定局，隐私脱离主体，被合法挖掘追踪分析，广泛用于解读并预测、规制人的欲望、想法和行动，人与隐私的关系就变了。隐私主体失去了话语权，不再是自己隐私的主人和守护者（马丁，1971）。鉴于个人信息的巨大经济价值和政治红利，法律别无选择，只能承认或默许隐私商品化。而公共议题就转变为：谁可以“合法”占有商品化的果实，即商业利益的竞争和垄断。所以，合法或是非法，法律都不可能还人类以隐私之安宁。</p>
      <p>法律保护的效用如此之低，为什么各国，尤其是发达经济体，还在不断强化隐私权的立法和宣传？原因很简单，那是政府部门同立法者目前唯一能做，而不影响“大局”的事情。当然，那也是业界巨头所希望的。比如小扎，今年三月接受CNN采访，就明确邀请国会立法，规制社交网站，说：问题不是该不该规制，而是什么是正确的规则。</p>
      <p>资本非常清醒：隐私关乎人的责任能力，占有隐私并获得保护，就要承担相对应的社会责任。当人们交出隐私（无论自愿或不知情），让商家牟利或政府监管，个人的自由意志选择范围便相应地缩小了。人的自主选择越少，承担责任的能力也越小。反之，商家和政府获取的隐私越多，对用户跟社会的控制力也越强。隐私易手，对应的社会责任并不会消失，是需要重新分配的。而且不仅是责任，还是社会风险管理机制的全盘安排。但市场经济是自利者的王国，资本拿隐私赚大钱，却无意承担附着于隐私的社会责任。这就是为什么，他们一边推动隐私商品化，一边在媒体和立法层面，大声疾呼保障隐私。他们企图让人相信，尽管隐私化作他人财产已是生活常态，原始隐私权仍在自己手中，并受到前所未有的法律保护。只需发扬分享的美德，就会得到最佳补偿，即生活便利。巨头们直言不讳，希望失去隐私的人们一如既往地承担行为主体的责任，而掌控隐私的唱唱法律保护的高调，即可免责而享受用户“分享”的馈赠。</p>
      <p>这，应该就是埃格斯先生设想的零隐私未来的起点同终线。无独有偶，脸书老板早在二〇一〇年就说过，我们的隐私观过时了， <a href="https://www.theguardian.com/technology/2010/jan/11/facebook-privacy"> 隐私“不再是社会规范” </a> 。大家不仅乐于分享各种信息，而且喜欢向越来越多的陌生人开放自己，“促成了新的社会规范”（约翰逊, 2010）。是的，只要巨头们奉行《圆圈》里的那句台词：知道（隐私）好。知道一切（隐私）更好！法律就救不了隐私。</p>
      <p></p>
      <p style="text-align: center;"><strong>
     四、隐私终结，意味着什么？
    </strong></p>
      <p>说到这里，隐私经过信息社会商业化的洗礼，命运只有一个去向——走向终结！</p>
      <p>也许，一些占有者以为，自己可以是隐私终结的例外，甚而能够在支配他人隐私的同时，继续保有自己的隐私？然而，人类的总命运是谁也逃不脱的。从目前AI的发展势头看，我们不得不警惕，一种智力优于人类，且具有“自由意志”的独立物种出现。届时，机器人未必“甘当”人类肢体和心智的延伸，而人类却要依靠它才能生存。因此，隐私危机必须放在人机关系中去思考、规划。个人信息的网络储存越多，分析工具越精致高效，硅基智能成长为独立物种而摆脱人类管控的步伐，就会越快。当AI提升至通用智能，能够在多个领域自我学习，不再需要人的知识连同隐私当它的学习素材，一如自学围棋、碾压人类顶级大脑的“阿尔法零”，那一天，将奏响隐私的挽歌。</p>
      <p>不过，隐私的终结，并不意味着人类终结。归根结蒂，人是可以零隐私地活着的。迄今为止，隐私对于人类重要，是因为人受制于较低的信息能力，亦即人类为自己安排了那样的生活秩序。所以一方面，隐私是人类高级智力活动的产物，体现了人对自身价值的期待和尊重；另一方面，一旦人类实现“自我超越”，造出通用人工智能（AGI），让机器取代自己思考、劳动、创造，后隐私时代便降临了。</p>
      <p>进入后隐私时代，人类社会现存的经济基础和上层建筑必然失效了。人类将怎样生活？没有历史经验，没有参照物，很难想象。但有三点可以预期：</p>
      <p>一、那将是一种没有自觉自愿，不知何为荣辱问责，但高效而标准化的低智低能的生活秩序。那里，隐私失去了意义。它不再能培育自由人格，因为系统中没有自由意志的位置。它不再是社会责任的对价，因为人无须自由选择自主行动而承担责任。它也不再是智力活动的衍生品，因为人类主动放弃了发展智力的努力，满足于在无限优化了的天网下执行指令。</p>
      <p>二、社会的中心不再是人与人的关系，而是人机关系和机机关系。人类不复为地球的主人，反倒有可能变成硅基智能系统的累赘。不是有AI专家预测，二十五年后，无人驾驶技术成熟，人类将被禁止驾车上路。无人驾驶的交通系统，其交通规则、道路设计、社区安排等，都是不许出错的。人类驾驶只会破坏科学设计的完美，引发交通事故，降低行车效率。实际上，排斥人类参与、删除人类个性，那样的硅胶智能世界，才可能是高效简洁、完满无缺的一个大“圆圈”。</p>
      <p>三、人类世界本身，共产主义或许是唯一的选项。因为机器人治下，人不但没有了隐私，分工也已消失。所有的个体都集合于一个总体，个人自由即全体的自由，我为人人即人人为我（ <a href="/2640/ethics-of-artificial-intelligence/"> 冯象，2017 </a> ）。</p>
      <p><img alt="Marvin Minsky" src="/img/Marvin_Minsky.jpg" style="float: right; margin: 5px 0px 35px 45px;" /> 人工智能的先驱，已故的麻省理工学院教授明斯基（Marvin Minsky）说过：有朝一日，当我们掌握了建造智力远胜人类的机器的知识，就不得不面对一个奇特的问题，那就是：该不该建造？我很幸运，因为我可以把这一困难的选择留给后人。但我相信，他们不会建造，除非找到很好的理由（ <a href="https://www.aaai.org/ojs/index.php/aimagazine/article/view/376/312"> 明斯基，1982 </a> ）。明斯基还曾经对深度学习神经网络技术做出悲观的描述（《认知器演算法》，1969, 1987），他的观点被认为阻碍了AI发展达半个世纪之久，因而颇受诟病。但我想，换个角度，这也许是教授对人类最大的贡献：为我们做好准备迎接机器人时代，赢得了宝贵的时间。</p>
      <p>明斯基的智慧提醒我们，对隐私应取审慎节制的态度。也许，停下隐私的深度挖掘和过度商业化，我们会少些便捷、舒适和效率，办事会不那么顺畅。但我们就可以继续辛勤劳动，思考学习；继续拥有自由意志，而担起自己的社会责任。我们将保有隐私同人格尊严。这，才是一种更美好的生活。</p>
      <p style="text-align: right;">二〇一七年十月初稿，一八年四月定稿 <br /> 原载《文化纵横》6/2018</p>
      <hr />
      <p>参考阅读</p>
      <ul>
        <li>波斯纳（Richard Posner）：《正义经济学》（ <a href="https://amzn.to/2Jujpba"> <em>
       The Economics of Justice
      </em> </a> ），哈佛大学出版社，1981。</li>
        <li><a href="http://fengxiang.ideobook.com/"> 冯象 </a> ：《 <a href="/2640/ethics-of-artificial-intelligence/"> 我是阿尔法——论人机伦理 </a> 》，载《文化纵横》12/2017。</li>
        <li>马丁（George Martin）：《简议长生》（Brief proposal on immortality: an interim solution），载《生物学医学展望》（ <em>
      Perspectives in Biology and Medicine
     </em> ）14/2:339, 1971。</li>
        <li>明斯基（Marvin Minsky）： <a href="https://www.aaai.org/ojs/index.php/aimagazine/article/view/376/312"> 《为什么人以为电脑做不了》（Why People Think Computer Can’t） </a> ，载《人工智能杂志》（ <em>
      AI Magazine
     </em> ）3:4, 1982（秋季号）。</li>
        <li>卫斯汀（Alan Westin）：《隐私与自由》（ <a href="https://amzn.to/2JjhzGP"> <em>
       Privacy and Freedom
      </em> </a> ），Athenaeum, 1967。</li>
        <li>约翰逊（Bobbie Johnson）：《隐私不再是社会规范，脸书创始人说》（ <a>
      Privacy no longer a social norm, says Facebook founder
     </a> ），载《卫报》（ <em>
      The Guardian
     </em> ）2010.1.10。</li>
      </ul>
    </div>
    <!-- /post-entry-content -->
    <footer class="post-entry-footer">
      <p>Categorized: <a href="http://www.ideobook.com/category/social-sciences/" rel="category tag"> 社会科学 · SOCIAL SCIENCES </a> - <a href="http://www.ideobook.com/category/essays/" rel="category tag"> 评论随笔 · ESSAYS </a></p>
      <p>Tagged: <a href="http://www.ideobook.com/tag/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd/" rel="tag"> 人工智能 </a> - <a href="http://www.ideobook.com/tag/%e5%88%a9%e6%b1%82%e5%90%8c/" rel="tag"> 利求同 </a> - <a href="http://www.ideobook.com/tag/%e5%95%86%e4%b8%9a%e5%8c%96/" rel="tag"> 商业化 </a> - <a href="http://www.ideobook.com/tag/%e5%95%86%e5%93%81%e5%8c%96/" rel="tag"> 商品化 </a> - <a href="http://www.ideobook.com/tag/%e8%84%b8%e4%b9%a6/" rel="tag"> 脸书 </a> - <a href="http://www.ideobook.com/tag/%e8%b5%84%e6%9c%ac/" rel="tag"> 资本 </a> - <a href="http://www.ideobook.com/tag/%e9%9a%90%e7%a7%81/" rel="tag"> 隐私 </a></p>
    </footer>
    <!-- /post-entry-footer -->
    <footer class="post-entry-footer">
      <p>如果您喜欢本站文章， <a href="http://www.ideobook.com/subscription/"> 请订阅我们的电子邮件 </a> ，以便及时获取更新通知。</p>
      <p>好书推荐: <a href="https://amzn.to/2BLHdBY"> 脱销多年新近重印的四卷本奥威尔文集 The Collected Essays, Journalism, and Letters of George Orwell: Volume 1 </a> , <a href="https://amzn.to/32VpT9o"> 2 </a> , <a href="https://amzn.to/2pk1FHp"> 3 </a> , <a href="https://amzn.to/32WV0RW"> 4 </a> .</p>
    </footer>
    <div class="boxframe" id="commentsbox">
      <div class="comments-area clearfix" id="comments">
        <div class="comment-respond" id="respond">
          <h3 class="comment-reply-title" id="reply-title"> Leave a Reply <small> <a href="/2745/future-privacy/#respond" id="cancel-comment-reply-link" rel="nofollow" style="display:none;"> <span class="wpex-icon-remove-sign"> </span> </a> </small> </h3>
        </div>
        <!-- #respond -->
      </div>
      <!-- /comments -->
    </div>
    <!-- /commentsbox -->
  </div>
  <!-- /post-entry-text -->
</article>


  </div>

  <hr style="border-top:1px solid #28323C;"/>

<font size=2px>
  文章版权归原作者所有。
</font>

<div style="text-align:center"><img width="1px" src="https://i.imgur.com/HSw56Ez.png" alt="二维码分享本站" style="text-align:center"/></div>

  <div id="sametag">
    <h4 style="display: inline-block;">#智识 的其它文章</h4>
    <span>--<a href="https://nodebe4.github.io/opinion/2024-12-29/%E5%86%AF%E8%B1%A1-%E6%96%B0%E7%BA%A6-%E4%B8%89%E7%89%88%E5%BC%81%E8%A8%80/">最新</a>-</span>
    <span>-<a href="https://nodebe4.github.io/opinion/2004-05-10/%E6%AC%A2%E8%BF%8E%E8%AE%BF%E9%97%AE-%E6%99%BA%E8%AF%86~IdeoBook/">最早</a>--</span>
    
      <li>
        <time>2018-07-16</time>
        <a href="https://nodebe4.github.io/opinion/2018-07-16/%E5%86%AF%E8%B1%A1-%E5%91%90%E5%96%8A%E5%92%8C%E6%80%9D%E5%BF%B5-%E6%88%91%E6%98%AF%E9%98%BF%E5%B0%94%E6%B3%95-%E5%BC%81%E8%A8%80/">
          冯象：呐喊和思念——《我是阿尔法》弁言
        </a>
      </li>
    
    
      <li>
        <time>2018-06-18</time>
        <a href="https://nodebe4.github.io/opinion/2018-06-18/Students-for-Fair-Admissions-v.-Harvard-%E8%B5%84%E6%96%99%E9%80%89%E8%BE%91/">
          Students for Fair Admissions v. Harvard 资料选辑
        </a>
      </li>
    
    
      <li>
        <time>2018-05-17</time>
        <a href="https://nodebe4.github.io/opinion/2018-05-17/%E5%86%AF%E8%B1%A1-%E5%85%A8%E4%B8%96%E7%95%8C%E6%9C%BA%E5%99%A8%E4%BA%BA-%E8%81%94%E5%90%88%E8%B5%B7%E6%9D%A5/">
          冯象：全世界机器人，联合起来！
        </a>
      </li>
    
    
      <li>
        <time>2018-04-02</time>
        <a href="https://nodebe4.github.io/opinion/2018-04-02/New-Book-The-Chinese-Must-Go-Violence,-Exclusion,-and-the-Making-of-the-Alien-in-America,-by-Beth-Lew-Williams/">
          New Book: The Chinese Must Go: Violence, Exclusion, and the Making of the Alien in America, by Beth Lew-Williams
        </a>
      </li>
    
  </div>


  <hr>
  <div class="pagination">
    
      <span class="prev" >
          <a href="https://nodebe4.github.io/opinion/2018-06-05/%E5%88%98%E6%93%8E-%E7%AB%8B%E6%9D%83%E5%A8%81%E4%BA%8E%E8%87%AA%E7%94%B1-%E6%96%B0%E5%85%B1%E5%92%8C%E7%9A%84%E5%88%9B%E7%94%9F%E4%B8%8E%E7%BE%8E%E5%9B%BD%E6%94%BF%E6%B2%BB%E4%B9%8B%E9%81%93/">
            前一篇：刘擎： 立权威于自由——新共和的创生与美国政治之道
          </a>
      </span>
    
    
      <span class="next" >
          <a href="https://nodebe4.github.io/opinion/2018-06-05/%E5%90%88%E4%BD%9C%E6%9D%BE2-%E6%9D%AD%E5%B7%9E%E6%8B%8D%E8%84%91%E4%BC%9A-%E5%90%88%E4%BD%9C%E7%9A%84%E6%8A%80%E6%9C%AF-%E6%8A%80%E6%9C%AF%E7%9A%84%E5%90%88%E4%BD%9C/">
            後一篇：合作松2 | 杭州拍脑会：“合作的技术 技术的合作”
          </a>
      </span>
    

    <script>
    /* post pagination keyboard shortcuts */
    document.body.onkeyup = function(e){
      if (e.keyCode == '37') { window.location = 'https://nodebe4.github.io/opinion/2018-06-05/%E5%88%98%E6%93%8E-%E7%AB%8B%E6%9D%83%E5%A8%81%E4%BA%8E%E8%87%AA%E7%94%B1-%E6%96%B0%E5%85%B1%E5%92%8C%E7%9A%84%E5%88%9B%E7%94%9F%E4%B8%8E%E7%BE%8E%E5%9B%BD%E6%94%BF%E6%B2%BB%E4%B9%8B%E9%81%93/'; } // left arrow key
      if (e.keyCode == '39') { window.location = 'https://nodebe4.github.io/opinion/2018-06-05/%E5%90%88%E4%BD%9C%E6%9D%BE2-%E6%9D%AD%E5%B7%9E%E6%8B%8D%E8%84%91%E4%BC%9A-%E5%90%88%E4%BD%9C%E7%9A%84%E6%8A%80%E6%9C%AF-%E6%8A%80%E6%9C%AF%E7%9A%84%E5%90%88%E4%BD%9C/'; } // right arrow key
      if (e.keyCode == '45') { window.location = 'https://nodebe4.github.io/opinion/2018-06-18/Students-for-Fair-Admissions-v.-Harvard-%E8%B5%84%E6%96%99%E9%80%89%E8%BE%91/'; } // insert key
      if (e.keyCode == '46') { window.location = 'https://nodebe4.github.io/opinion/2018-05-17/%E5%86%AF%E8%B1%A1-%E5%85%A8%E4%B8%96%E7%95%8C%E6%9C%BA%E5%99%A8%E4%BA%BA-%E8%81%94%E5%90%88%E8%B5%B7%E6%9D%A5/'; } // delete key
    };
    </script>
    <link rel="stylesheet" type="text/css" href="/opinion/assets/css/fab.css" />

<div class="fab-wrapper">
  <div class="fab-wheel">
    
    
    
    <a class="fab-action fab-action-1" title="上一篇(热键 &#8594;)" href="https://nodebe4.github.io/opinion/2018-06-05/%E5%88%98%E6%93%8E-%E7%AB%8B%E6%9D%83%E5%A8%81%E4%BA%8E%E8%87%AA%E7%94%B1-%E6%96%B0%E5%85%B1%E5%92%8C%E7%9A%84%E5%88%9B%E7%94%9F%E4%B8%8E%E7%BE%8E%E5%9B%BD%E6%94%BF%E6%B2%BB%E4%B9%8B%E9%81%93/">
      <i>后</i>
    </a>
    
    
    <a class="fab-action fab-action-2" title="下一篇(热键 &#8592;)" href="https://nodebe4.github.io/opinion/2018-06-05/%E5%90%88%E4%BD%9C%E6%9D%BE2-%E6%9D%AD%E5%B7%9E%E6%8B%8D%E8%84%91%E4%BC%9A-%E5%90%88%E4%BD%9C%E7%9A%84%E6%8A%80%E6%9C%AF-%E6%8A%80%E6%9C%AF%E7%9A%84%E5%90%88%E4%BD%9C/">
      <i>前</i>
    </a>
    
    
    <a class="fab-action fab-action-3" title="<智识>上一篇(热键 ins)" href="https://nodebe4.github.io/opinion/2018-06-18/Students-for-Fair-Admissions-v.-Harvard-%E8%B5%84%E6%96%99%E9%80%89%E8%BE%91/">
      <i>左</i>
    </a>
    
    
    <a class="fab-action fab-action-4" title="<智识>下一篇(热键 del)" href="https://nodebe4.github.io/opinion/2018-05-17/%E5%86%AF%E8%B1%A1-%E5%85%A8%E4%B8%96%E7%95%8C%E6%9C%BA%E5%99%A8%E4%BA%BA-%E8%81%94%E5%90%88%E8%B5%B7%E6%9D%A5/">
      <i>右</i>
    </a>
    
  </div>
</div>


  </div>


  

</article>

    </div>

    <div style="z-index:2;">
<script src="/opinion/assets/js/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
  diameter: 56,
  cornerOffset: 20, // px
  id: 'back-to-top',
  backgroundColor: '#ddd',
  textColor: 'red'
})</script>
</div>


    <div class="wrapper-footer" id="footer">
      <div class="container">
        <footer class="footer">
          <img width="200px" src="https://i.imgur.com/HSw56Ez.png" alt="二维码分享本站"/>
<font size=2px>二维码分享本站</font>

<!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

  

  

  
  <li><a href="mailto:beauti4@protonmail.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
  

  

  

  
  <li><a href="https://github.com/NodeBE4/opinion" class="icon-13 github" title="GitHub"><svg viewBox="0 0 512 512"><path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z"/></svg><!--[if lt IE 9]><em>GitHub</em><![endif]--></a></li>
  

  

  

  

  

  
  <li><a href="/opinion/feed.xml" class="icon-21 rss" title="RSS"><svg viewBox="0 0 512 512"><path d="M201.8 347.2c0 20.3-16.5 36.8-36.8 36.8 -20.3 0-36.8-16.5-36.8-36.8s16.5-36.8 36.8-36.8C185.3 310.4 201.8 326.8 201.8 347.2zM128.2 204.7v54.5c68.5 0.7 124 56.3 124.7 124.7h54.5C306.7 285.3 226.9 205.4 128.2 204.7zM128.2 166.6c57.9 0.3 112.3 22.9 153.2 63.9 41 41 63.7 95.5 63.9 153.5h54.5c-0.3-149.9-121.7-271.4-271.6-271.9V166.6L128.2 166.6z"/></svg><!--[if lt IE 9]><em>RSS</em><![endif]--></a></li>
  

  

  

  

  

    
</ul>





<p><span style="color:blue">内容每小时更新一次.</span> Powered by <a href="https://github.com/AWEEKJ/kiko-now">Kiko Now</a> & <a href="https://github.com/gitalk/gitalk">Gitalk</a> & <a href="https://github.com/duty-machine/news">duty-machine</a>, 站务 <a href="https://be4.herokuapp.com">NodeBE4</a>（<span style="color:red">被墙</span>）</p>





        </footer>
      </div>
    </div>

    



  </body>
</html>
