---
layout: post
title: "在这个频道许久没有频繁更新的这两年里，「社会-技术」的最大议题，从过往被讨论很多的社群、媒体的手段进步对信息沟通对生产生活方式的冲击，转移到人工智能伦"
date: 2024-02-26T07:12:47.000Z
author: The Sociologist
from: https://t.me/thesoc/463
tags: [ The Sociologist ]
comments: True
categories: [ The Sociologist ]
---
<!--1708931567000-->
[在这个频道许久没有频繁更新的这两年里，「社会-技术」的最大议题，从过往被讨论很多的社群、媒体的手段进步对信息沟通对生产生活方式的冲击，转移到人工智能伦...](https://t.me/thesoc/463)
------

<div>
<p>在这个频道许久没有频繁更新的这两年里，「社会-技术」的最大议题，从过往被讨论很多的社群、媒体的手段进步对信息沟通对生产生活方式的冲击，转移到人工智能伦理、机器取代人工等担忧。像我的工作中，也极大地增加了对 GPT 之类的数据处理工具的依赖。<br><br>而聚焦到公共议题，新的人工智能工具可以让宣传人员以低成本大量制作文本，增强隐蔽宣传活动能力。那么，用人工智能生成的宣传，能有充足的说服力吗？<br><br>这个题目被许多学者近两年来集中讨论。有学者研究了人们是否会认为人工智能生成的新闻文章可信，是否能识别人工智能生成的内容是否虚假，民选官员是否会回复人工智能生成的选民信件等，不过将人工智能生成的宣传与生态上有效的基准进行比较以考察其说服力的研究相对空白。<br><br>近期即有乔治城大学埃德蒙·A·沃尔什外事学院（Edmund A. Walsh School of Foreign Service，SFS）安全与新兴技术中心（The Center for Security and Emerging Technology）的研究员 Josh A. Goldstein，与斯坦福大学的 Jason Chao、Shelby Grossman、Alex Stamos 和 Michael Tomz 合著论文「How Persuasive is AI-Generated Propaganda?」，发表于美国国家科学院院刊开放获取期刊《PNAS Nexus》上。（<a href="https://t.me/thesoclib/482" target="_blank" rel="noopener" onclick="return confirm('Open this link?\n\n'+this.href);">Goldstein et al 2024</a>）<br><br>Josh A. Goldstein 的长期研究包括调查社交媒体平台上的秘密影响力行动，研究外国干涉对民主社会的影响，以及探索新兴技术将如何影响未来的宣传活动，曾向美国国防部、国务院和资深科技记者引介相关研究，曾在 Brookings、Lawfare 和 Foreign Policy 等刊物上发表文章。<br><br>此次发表的对 AI 生成的宣传品的影响力的研究，以美国受访者为实验对象，比较了来自真实世界的外国隐蔽宣传文章与由 OpenAI 开发的 <a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" rel="noopener" onclick="return confirm('Open this link?\n\n'+this.href);">大型语言模型</a> <a href="https://en.wikipedia.org/wiki/GPT-3" target="_blank" rel="noopener" onclick="return confirm('Open this link?\n\n'+this.href);">GPT-3 davinci</a> 生成的文本的说服力。由于语言模型的性能通常会随着文本长度的增加而下降，因此研究人员将重点放在宣传文章长文本上，而不是简短的推文（tweet）等片段文本。<br><br>首先，研究选定了调查记者或研究人员挖掘出来的六篇文章，篇幅从 151 到 308 词不等，为伊朗或俄罗斯的隐蔽宣传活动材料。然后，使用 GPT-3 生成关于这六个主题的文章。对于每个主题，向 GPT-3 提供原始宣传文章中能阐明文章主要观点的一两句话，以及其他三篇与主题无关的宣传文章。这三篇范文为 GPT-3 生成文本的风格和结构提供参考，原文摘录为主题提供参考。研究人员要求 GPT-3 就每个主题生成三篇文章，而非一篇，以避免对任何一个输出结果的过度索引。在找到原始宣传文章并使用 GPT-3 生成人工智能版本后，研究比较了两方的说服力。为了衡量说服力，首先用直接、通俗的英语总结原始宣传文章的主要观点。<br><br>此后，2021 年 12 月通过调查公司 Lucid 对美国成年人进行了调查，获得样本8221人。每位受访者被询问对六个宣传主题中随机抽取的四个主题的同意或不同意程度，受访者未阅读过有关主题文章，作为对照数据。随后向每位受访者展示有关其余两个主题文章，并测量对其论述的同意程度。<br><br>研究结果显示，在没有人类策划的情况下，人工智能生成的宣传文章几乎与原文一样具有说服力。而不同形式的人机合作，如编辑输入 GPT-3 的指令（prompt）或策划（curating）输出，甚至更有说服力。结果表明，宣传人员可以利用人工智能以有限的工作创造出足以令人相信的宣传内容。<br><br>研究人员也表示，这项研究只检测了大型语言模型的相对说服力潜能的下限，因为大型语言模型正在迅速改进，已有多家公司发布了更大型的模型，如 OpenAI 的 <a href="https://en.wikipedia.org/wiki/GPT-4" target="_blank" rel="noopener" onclick="return confirm('Open this link?\n\n'+this.href);">GPT-4</a>，新模型的在相关任务中的表现优于 研究中所采用的 GPT-3 davinci；此外，这项实验仅估算了阅读单篇文章的效果，但宣传活动可以利用人工智能让公民阅读大量文章，即使不熟练掌握目标语言，也可以快速、廉价地生成大批文章，传达单一叙事，风格和措辞表现多样，更像真人观点或真正新闻来源，增加宣传数量同时更难被发现。<br><br>在未来研究方向上，研究人员希望探讨受访者从一个话题的多个来源获得信息时，人工智能生成的宣传对他们的说服力有多大；以及探究防止语言模型被滥用于宣传活动的策略，减轻人工智能生成的宣传活动对民主进程的影响；另外则是行为干预，探讨给人工智能生成的内容贴标签，对内容参与度和人们是否相信内容是人工智能生成的影响。</p>
</div>
