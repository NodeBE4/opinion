---
layout: post
title: "与审查共存(四)：无察觉，不反抗"
date: 2020-06-14T13:53:37.000Z
author: 揍笑桶
from: https://matters.news/@cccccc/%25E4%25B8%258E%25E5%25AE%25A1%25E6%259F%25A5%25E5%2585%25B1%25E5%25AD%2598-%25E5%259B%259B-%25E6%2597%25A0%25E5%25AF%259F%25E8%25A7%2589-%25E4%25B8%258D%25E5%258F%258D%25E6%258A%2597-bafyreidkcugnpa6qgiqwvyjwfmrg26c5onqwpgr2nwwtjyzqsjkciw6lly
tags: [ Matters ]
categories: [ Matters ]
---
<!--1592142817000-->
[与审查共存(四)：无察觉，不反抗](https://matters.news/@cccccc/%25E4%25B8%258E%25E5%25AE%25A1%25E6%259F%25A5%25E5%2585%25B1%25E5%25AD%2598-%25E5%259B%259B-%25E6%2597%25A0%25E5%25AF%259F%25E8%25A7%2589-%25E4%25B8%258D%25E5%258F%258D%25E6%258A%2597-bafyreidkcugnpa6qgiqwvyjwfmrg26c5onqwpgr2nwwtjyzqsjkciw6lly)
------

<div>
<p><em>这篇文章主要是对Molly Roberts新发表的题为”对网络审查不服从的韧性“的文献综述的大致翻译。意译为主，会有在尊重原意基础上的、适合Matters读者群的改写。在黄色错位线后加入必要引用，在灰色模块里穿插个人评论。每次翻译一个小章节，进度不定，原文详见</em><a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-polisci-050718-032837" target="_blank"><em>期刊官网</em></a><em>。（我是新加入的伙伴笑桶，这篇翻译由<a class="mention" href="https://matters.news/@andyischaos" target="_blank" data-display-name="ZandY" data-user-name="andyischaos" data-id="VXNlcjo5NTg">﻿<span>@ZandY</span>﻿</a> 跟我合作完成）</em></p><hr><p>审查会利用信息的特性进行伪装，让人难以察觉到信息操控。基于恐惧的审查是利用恐吓和威慑阻止消息传播，要行之有效就必须要让它暴露在公共空间中；而像阻塞和灌水这样更为复杂的审查形式，如网站封锁、对搜索结果进行重新排序等，可以在用户不知情的情况下发挥作用。因此，信息操纵很难被察觉，用户很难注意到政府对他们信息环境的影响。</p><p>如果用户能察觉到审查，ta们能抵抗它吗？学者们对此有着不同的答案。</p><hr><p><strong>一方面，察觉到「审查」其实会使审查变得更有效。</strong>比如，因为它能带来寒蝉效应（所以用户会自我审查…）——在传统媒体中我们对此并不陌生。</p><blockquote><a href="https://www.law.berkeley.edu/php-programs/faculty/facultyPubsPDF.php?facID=15878&pubID=3" target="_blank">Stern & Hassid（2010）</a>显示，在中国，只有1%的媒体记者和律师遭到过政府的直接镇压。剩下的99%则会因为无法确定哪些行为会被审查经常进行自我审查。但自我审查并不意味着他们减少了对政治的关注。相反，他们会根据过往案例对哪些行为为什么会遭到审查进行解释，并总结出一套安全的行为准则。</blockquote><p>这种恐惧在虚拟世界里同样普遍。政府直接露骨的政治宣传会弱化民众的抗议意愿（Huang <a href="https://www.jstor.org/stable/43664158?seq=1#metadata_info_tab_contents" target="_blank">2015</a>，<a href="https://www.journals.uchicago.edu/doi/abs/10.1086/696863" target="_blank">2018</a>），实名注册后部分人会避免在平台上讨论政治话题（<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2265271" target="_blank">Fu et al. 2013</a>）。在沙特阿拉伯，Twitter用户遭到政府拘禁后，几乎不会再在网上公开批评政府（<a href="https://alexandra-siegel.com/wp-content/uploads/2019/05/Saudi_Twitter_APSR_RR.pdf" target="_blank">Pan & Siegel 2020</a>）。而2016年土耳其政变失败后，大量土耳其Twitter用户选择了自我审查：不仅是减少了发言，而且还删除了自己过去的帖子，把账号转为受限（protected）模式，或者干脆删除了自己的帐号 (<a href="https://www.usenix.org/conference/foci17/workshop-program/presentation/tanash" target="_blank">Tanash et al. 2017</a>）。用户承担的政治风险越高时，寒蝉效应在他们身上体现得就越明显。</p><pre class="ql-syntax">我觉得网络世界的自我审查更令人难过。这不只是因为豆瓣、微博等平台上公共空间的式微使个体不能随心所欲地表达自己的想法。有时候为了安全地呈现想法、讨论问题，发布的文字被乔装、甚至扭曲，继而造成了中文语言环境的污染。讨论中的欲言又止、阴阳怪调、拼音缩写等让人无奈又摸不着头脑，甚至会让人失去表达和交流的欲望。简单来说，我们不能用中文好好说话了。</pre><hr><p><strong>另一方面，对「审查」的察觉可能会引起人们对被屏蔽信息的好奇，和种种不服从</strong>。就像现实空间里的镇压可能会带来副作用一样，审查也可能适得其反。虽然露骨明显的政治宣传会使用户畏于表达，但用户对政权的印象也会恶化，产生更强的移民意愿（<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3055019" target="_blank">Huang 2018</a>）。</p><blockquote><a href="https://www.cambridge.org/core/journals/american-political-science-review/article/how-saudi-crackdowns-fail-to-silence-online-dissent/1BA13DF8FD5D04EC181BCD4D1055254B" target="_blank">Pan & Seigel</a> 通过Twitter的数据发现，虽然政府的拘捕会让异见人士噤声，但也会刺激被捕人士的关注者。一旦发生拘捕，关注者们在Twitter上表达的反政府情绪就会增加。另外，作者还发现这些异见人士被捕后，Google上对他们的搜索会增加。这说明用户们正通过审查逐渐了解到被捕人士以前写的东西。</blockquote><p>这表明审查这个行为本身就可能在向民众传递信息，从而改变ta们的观念。对传统媒体的研究表明，当公民意识到官方媒体的偏颇时，ta们就会主动去寻找更可靠的信息。实际上，只要民众可以辨认出政府的政治宣传，就会去抵制它（<a href="https://www.semanticscholar.org/paper/Sources-of-Popular-Support-for-Authoritarian-Geddes-Zaller/8a1e4b28acc6a6714f373d37db682585962e0df6" target="_blank">Geddes & Zaller 1989</a>）。如果他们发现商业媒体比起官方媒体更能反映公众意见，就会有策略地从商业媒体中获取信息，而只有官方媒体真的有信息价值时才会去读它们。（<a href="https://www.cambridge.org/core/books/media-commercialization-and-authoritarian-rule-in-china/F393EFA6A12B5DC61A5C36AC5E2BBF06" target="_blank">Stockmann 2012</a>）</p><blockquote>Epstein et al. 在<a href="https://cbw.sh/static/pdf/epstein-2017-pacmhci.pdf" target="_blank">2017</a>年对利用搜索引擎进行信息操纵的效果进行了后续研究，对搜索引擎的操纵的察觉，能够显著降低公众舆论受到的影响。这些研究表明，当察觉到信息操纵时，用户们就会开始考虑信息操纵的影响。此前，Epstein & Robertson（<a href="https://www.pnas.org/content/pnas/112/33/E4512.full.pdf" target="_blank">2015</a>） 通过实验发现搜索引擎的排序结果确实能够改变人们的决定。（详见系列第二篇）</blockquote><p>在线审查可以调动用户对政府进行反抗或者激发他们对审查内容的兴趣（<a href="https://alexandra-siegel.com/wp-content/uploads/2019/05/Saudi_Twitter_APSR_RR.pdf" target="_blank">Pan＆Siegel</a>）。这种现象通常被称为史翠珊效应（Streisand effect），起源于芭芭拉·史翠珊（Barbra Streisand）起诉加利福尼亚海岸唱片公司。她要求该公司从其网站上删除她的豪宅照片，但诉讼反而引起了们对照片的关注，随后吸引了成千上万的观众访问该网站（<a href="https://ro.uow.edu.au/cgi/viewcontent.cgi?article=2890&context=lhapapers" target="_blank">Jansen＆Martin 2015</a>）。</p><p>同样地，人们的好奇心会引导他们去了解审查的内容。这就是为什么某些网站就算被封锁了，它的用户访问量还是很高；一旦某些内容被审查，对它们的搜索和访问就会暴增（<a href="https://firstmonday.org/article/view/5525/4155" target="_blank">Nabi 2014</a>）。更为明显的审查甚至会引起民众激烈的抗议。乌干达实行媒体税后，使用WhatsApp这类社交应用的用户每天都要缴纳税款。虽然这政策整体上减少了对社交媒体的使用，但它也引起了反弹。开始征税后，不仅社交媒体上出现了更多关于采取集体行动的文章；而且乌干达的抗议示威活动增加了48％，其中也包括对社交媒体税的抗议（<a href="https://arxiv.org/pdf/1909.04107.pdf" target="_blank">Boxell＆Steinert-Threlkeld 2019</a>）。</p><hr><p>审查过度反而可能会危及专制体制。这一点其实和另一些实证研究的结论一致：信息渠道的畅通，和对政府的正面看法，两者是正相关的。</p><blockquote>曾经的东德境内有部分地区可以收到西德电视信号，<a href="https://www.jstor.org/stable/25791984" target="_blank">Kern＆Hainmueller</a>（2009）利用这个特殊差异去研究外国媒体对民意的影响，结论却与人们所以为的外媒能削弱专制统治的观点相反——那些能避开政府审查访问西德电视台的东德人反而对本国政权的看法更为积极。而且这个结果与东德各地区的签证申请等数据一致（这其中的原因很可能是这些人因为能够看到东德的娱乐节目，生活就没那么不堪忍受）。</blockquote><figure class="image">      <picture>        <source type="image/webp" media="(min-width: 768px)" srcset="https://assets.matters.news/processed/1080w/embed/ea0c77ec-ab5e-4ba9-8daa-1c61d333f85c.webp" onerror="this.srcset='https://assets.matters.news/embed/ea0c77ec-ab5e-4ba9-8daa-1c61d333f85c.png'">        <source media="(min-width: 768px)" srcset="https://assets.matters.news/processed/1080w/embed/ea0c77ec-ab5e-4ba9-8daa-1c61d333f85c.png" onerror="this.srcset='https://assets.matters.news/embed/ea0c77ec-ab5e-4ba9-8daa-1c61d333f85c.png'">        <source type="image/webp" srcset="https://assets.matters.news/processed/540w/embed/ea0c77ec-ab5e-4ba9-8daa-1c61d333f85c.webp">        <img src="https://assets.matters.news/embed/ea0c77ec-ab5e-4ba9-8daa-1c61d333f85c.png" srcset="https://assets.matters.news/processed/540w/embed/ea0c77ec-ab5e-4ba9-8daa-1c61d333f85c.png" loading="lazy" referrerpolicy="no-referrer">      </picture>    <figcaption><span>西德电视台的广播信号强度分布（出自Kern＆Hainmueller 2009）</span></figcaption></figure><blockquote><a href="https://www.tandfonline.com/doi/abs/10.1080/10584609.2012.737439" target="_blank">Hassanpour</a>（2014）通过埃及和叙利亚的互联网封锁论证了，网络连接的中断会使人们进行面对面互动，进而形成“<a href="https://zh.wikipedia.org/wiki/%E5%B0%8F%E4%B8%96%E7%95%8C%E7%B6%B2%E8%B7%AF" target="_blank">小世界网络</a>”。塔希尔广场抗议活动期间，埃及政府对互联网和媒体的封锁是增加了，而非减少了民众的协调合作，这也许是因为人们开始通过面对面交流以及更密集的本地网络来获取信息。 互联网封锁使不关心政治的公民对动乱有更多的了解并产生兴趣，通过小的地方性网络协调的抗议活动比通过互联网进行中心协调的抗议活动更难被政府控制。</blockquote><p>这些研究不仅反映了公众会对审查产生反弹，而且表明信息操纵可能会降低政府反驳假信息的能力，因为公民们已不怎么信任政府。就算反政府的谣言被澄清，公民对政府的信任也会显著下降。而且，政府对这些谣言的反驳不如政府批评者的反驳有效，用户可能不再相信政府的反驳（<a href="https://www.cambridge.org/core/journals/british-journal-of-political-science/article/war-of-misinformation-the-political-effects-of-rumors-and-rumor-rebuttals-in-an-authoritarian-country/9BA716D7394435F5A0C2291EC5E7B5B7" target="_blank">Huang 2017</a>）。</p><p>这些产生反弹的案例有一个共同点：审查容易被发现，而且同时影响了许多用户。审查影响了YouTube这个在土耳其和巴基斯坦极受欢迎的网站，无法访问这个网站会提醒许多用户注意以前未察觉到的审查；同样，乌干达的社交媒体税是一种非常明显的审查形式，它影响了所有的互联网用户，最后成为了人们合作起来反抗的共识基础；Huang（<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3055019" target="_blank">2018</a>）也表明由于可见度高，露骨明显的政治宣传反而会让人们意识到被审查的内容。当然，在什么条件下对审查的察觉会产生反效果，这还需要进一步研究。</p><p>下一部分，Molly将讨论政府如何对审查技术进行调整，来（a）减少审查制度的可见度，（b）消除其诱发群体行动的可能性，最后驯服互联网。</p><p> </p>
</div>
