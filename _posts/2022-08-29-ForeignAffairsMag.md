---
author: ForeignAffairsMag
categories:
- Reddit
date: 2022-09-01
from: https://old.reddit.com/r/geopolitics/comments/x2heav/spirals_of_delusion_how_ai_distorts/
layout: post
tags:
- Reddit
title: ForeignAffairsMag在2022-08-29~2022-09-04的言论
---

* This will become a table of contents (this text will be scrapped).
{:toc}

### 297: [Spirals of Delusion: How AI Distorts Decision-Making and Makes Dictators More Dangerous](https://old.reddit.com/r/geopolitics/comments/x2heav/spirals_of_delusion_how_ai_distorts/), submitted on 2022-09-01 00:05:45+08:00.

----- __297.1__ -----2022-09-01 00:17:11+08:00:

\[SS from the essay by Henry Farrell, Abraham Newman, and Jeremy Wallace\]

\[M\]achine learning is disrupting traditional forms of democratic feedback (voices and votes) as new technologies facilitate disinformation and worsen existing biases—taking prejudice hidden in data and confidently transforming it into incorrect assertions. To autocrats fumbling in the dark, meanwhile, machine learning looks like an answer to their prayers. Such technology can tell rulers whether their subjects like what they are doing without the hassle of surveys or the political risks of open debates and elections. For this reason, many observers have fretted that advances in AI will only strengthen the hand of dictators and further enable them to control their societies.  
The truth is more complicated. Bias is visibly a problem for democracies. But because it is more visible, citizens can mitigate it through other forms of feedback. When, for example, a racial group sees that hiring algorithms are biased against them, they can protest and seek redress with some chance of success. Authoritarian countries are probably at least as prone to bias as democracies are, perhaps more so. Much of this bias is likely to be invisible, especially to the decision-makers at the top. That makes it far more difficult to correct, even if leaders can see that something needs correcting.

