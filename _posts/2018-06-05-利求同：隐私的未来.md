---
layout: post
title: "利求同：隐私的未来"
date: 2018-06-05
author: 利求同
from: http://www.ideobook.com/2745/future-privacy/
tags: [ 智识 ]
categories: [ 智识 ]
---

<article class="post-entry clearfix post-2745 post type-post status-publish format-standard has-post-thumbnail hentry category-social-sciences category-essays tag-1153 tag-38 tag-1320 tag-1022 tag-1322 tag-1321 tag-736">
 <div class="post-entry-thumbnail">
  <img alt="利求同：隐私的未来" src="http://www.ideobook.com/img/annuit-coeptis-1200x292.jpg"/>
 </div>
 <!-- /blog-entry-thumbnail -->
 <div class="post-entry-text clearfix">
  <header>
   <h1>
    利求同：隐私的未来
   </h1>
   <ul class="post-entry-meta">
    <li>
     By:
     <a href="http://www.ideobook.com/liqiutong/" title="查看 利求同 的作者主页">
      利求同
     </a>
     . 2018-6-5.
     <a href="http://www.ideobook.com/372/post-views-count/" title="统计说明">
      7,019
     </a>
    </li>
   </ul>
  </header>
  <div class="post-entry-content">
   <p>
    “秘密是撒谎，分享是关怀，隐私是偷窃。”
   </p>
   <p>
    <a href="https://amzn.to/2kX6rEP">
     <img alt="" src="/img/circle_movie_poster.jpg" style="float: right; margin: 5px 0 35px 40px;"/>
    </a>
    这是美国科幻作家埃格斯（Dave Eggers）对未来的大胆想象。他的小说《圆圈》（
    <a href="https://amzn.to/2xJK27r">
     <em>
      The Circle
     </em>
    </a>
    ）拍了
    <a href="https://amzn.to/2kX6rEP">
     电影
    </a>
    ，这句话是影片里面同名超级公司的训言，同公司建筑的极简主义风格一起，接受“吸科技”的瘾君子朝拜。那里，我们习以为常的道德规范被颠倒了，做成新的信条：藏着隐私是严重的人格缺陷，上缴个人信息等于实现人生自由，光大“分享主义”美德；而保护隐私就视同盗窃，要受新人类的唾弃，并交给新法律制裁。
   </p>
   <p>
    隐私，能如此激发作家的想象，应该说是物联网智能时代的一个标记。不过，作为隐私的法定业主，我们得感激埃格斯先生的慷慨。因为在他的超级智能化的未来，隐私仍是有价值的，且依法享有平等的保护。人们只需修正价值观，将隐私从“私”和“隐”的疆域中剥离，转化为信息/数据财产，就能继续熟悉的生活了。当然，这新财产总是落在了别人，例如圆圈公司的手里，留给我们个人的，只是生产和再生产即奉献隐私的许可，人格权的一具空壳。但权利的空壳也是权利，也能给人带来安慰，因而是促进社会和谐美丽所不可少的一项制度。
   </p>
   <p>
    事实上，这隐私的未来已经到来。做一个透明人，自愿或被迫交出隐私，供人牟利，业已是生活常态了。只是，价值观的修正跟社会道德转型尚待完成。转型时期，还会有人呼吁，试图保护隐私；隐私的归属和使用上的冲突，却日益频发而尖锐起来。这是因为，在资本当道的条件下，隐私同分享有着不可调和的矛盾。最近脸书在美国乃至全球受到质疑，就是生动的例证。国会一边吵架，一边调查，俄国是否介入或干扰了美国大选，脸书却被爆料曾泄露8,700万用户的个人信息，给一家英国公司。脸书声称，这些用户信息是第三方以“不正当方式”获取的。小扎亲自出面，向公众道歉，保证今后严加管理。殊不知，早在二〇一一年，脸书就用户信息泄露事件做出过几乎同样的承诺。而那承诺之所以未能兑现，是因为无法兑现；实际上，国家法律也不允许兑现。现在的商业模式和残酷的产业竞争，有哪一家网络企业，包括电商大鳄，不是靠挖掘买卖用户信息赚钱的？手里的用户隐私越多，市场就越大，利润就越高。假如隐私当真严加保护，不就等于支柱产业集体自杀了？
    <br/>
    <span id="more-2745">
    </span>
   </p>
   <p>
    但是，真正的问题还不是几家大企业的利润多寡。关键在于，这事关乎我们的道德价值和理性选择：人工智能（AI），这一人类引以为傲的创造，信息技术的高峰，很可能与保护隐私是格格不入的。AI以高效、优化为目标，追求的是优于人脑的超级硅基智能。在那个智能体系中，信息是基本元素，是一切事物和生命的记录、编辑与展开。人，整体而言，跟任何碳基物、无机物一样，只是一个信息集。而隐私，进入大数据时代，作为一种游离于人类整体信息集边缘的个体特征，就“过于人性”了——承载了太多的价值立场和法律风险。保护隐私，人类信息集就变得坑坑洼洼，不好用了，所以亟需优化、标准化、去风险化。换言之，隐私成了硅基智能的障碍，是必须清除的杂音；非如此，人类不能同AI结合而融入未来。
   </p>
   <p>
    于是，我们不得不直面那一种可能，即隐私的终结。我们必须思考：如果隐私终结，人类将如何生存。
   </p>
   <p>
   </p>
   <p style="text-align: center;">
    <strong>
     一、隐私的可隐性
    </strong>
   </p>
   <p>
    研究一事物的终结，需要从其兴衰的条件和过程中寻找原因。那么，隐私是因何而来的呢？它又怎样塑造了我们的日常生活，它的消解意味着什么？这些问题的答案至关重要。
   </p>
   <p>
    历史地看，隐私是人类对自身生存状态的一种描述，既是社会的客观存在，也是道德伦理的主观认知，因而承载着情感和价值判断。关于隐私，学说繁多，实践更是千姿百态。但万变不离其宗，都包含两个基本要素：一、人的个体有别于群体/社会之公，称之为“私”；二、私的领域，时而需要隔绝于公，视之为“隐”。可以说，隐私的观念，其被社会认可而纳入“私”的范畴，乃是因“公”而生，而获得价值的。隐私既是私与公有别或对立的产物，也是公私赖以共存的条件。
   </p>
   <p>
    有学者认为，隐私源于人的动物性。人是独立的个体，同时又是群居动物。人在群体中生活，繁衍生息需要一定的私密空间和时间，才能建立亲疏有别的家庭跟社会关系，私与隐便在其中了。文明开化以后，隐私的观念和习惯，更是人类高级智力活动如宗教、艺术、政治、经济等的产物。渐渐地，隐私就演变为一种个体与群体的生活伦理，超越动物本能，而复杂精致起来，终于成了社会秩序的一根支柱（卫斯汀，1967）。
   </p>
   <p>
    这公私对应关系, 早在古希腊，亚里士多德就注意到了。他提出区分家室私事（the oikos）和城邦公务（the polis）这一对范畴的哲学命题，并讨论了自愿行为的概念。由此开启了一个漫长的学术传统，探究隐私同自由意志、自我意识以及自由人格的关系。自由意志是人自主选择而行动的一种能力。所以通常，只有自由意志下的行为，才当得起相应的法律责任和道德评价，无论赏罚、毁誉、愧疚。同理，有了自由意志，教导、说服、审议、禁止、判决等社会机制才能运作。而自由意志的产生和行使，是离不开隐私的环境的。首先，有了隐私，人才能培育道德自我意识，即充分意识到自己与行为后果的联系，即“我”是“我的行为”的“动力因”（efficient cause），从而能够自觉承担后果责任。于是，才产生了对行动的自主选择的心理需求，自由意志才得以培育。所以，没有隐私，就没有自由意志。
   </p>
   <p>
    更重要的是，第二，隐私所要求的社会认可同保护，其实是以自由意志，即人对他人和社会负责的能力，为对价的。换言之，消灭隐私，就是消灭人类个体负责的能力。因为，隐私的存在，不仅是自由意志生成和行使的条件，也是个体接受社会评价、承担社会义务的前提。反之，若无隐私，自我意识跟自由意志就失去了植根的土壤，社会评价和个体责任就无所依托。
   </p>
   <p>
    如此，私与公共存而辩证统一，我们所知的人类社会及其道德伦理制度，都包含了对隐私和自由意志的认可，虽然程度不一。社会承认并尊重个人（自由人）享有一定的隐私权益，并且或多或少，限制他人（包括政府、企业、团体）对个人信息的索取和使用。相应地，社会要求个人为享有隐私，或他人的不知情、不得干预而付出对价，即为自己的选择和言行负责。也就是说，隐私，作为具有道德价值的利益，是人格尊严的先决条件，也是社会组织、道德伦理、法律问责机制的一块基石。一八九〇年，美国法学家沃伦（Samuel Warren）和布兰代斯（Louis Brandeis）发表了题为“
    <a href="http://www.cs.cornell.edu/~shmat/courses/cs5436/warren-brandeis.pdf">
     隐私权
    </a>
    ”的著名论文，第一次系统阐述了所谓“独处的权利”，尝试厘清隐私保护的法律学说和适用规范。隐私权的设立与发展，极大地加强了人们的隐私意识。隐私成了公民的基本权益，享有隐私是现代社会理所当然的一项个人自由；保护隐私，即保护人的尊严，保护我们唯一的生活世界。
   </p>
   <p>
    然而今天，这唯一世界，正受到全方位的挑战。随着新型信息技术的迅猛发展和智能终端的普及，隐私首当其冲。一不留神，隐私已是千疮百孔，被那无所不能、无处不在的信息工具盯住了。人们的一举一动，每一个闪念都处于监控之下，不啻一个个透明人。要躲避监控而“独处”，过“正常”日子，几乎不可能了。有史以来第一次，隐私制作成了商品，大规模地买卖。而隐私一旦商品化，不同社会阶层和集团便生出相互冲突的利益诉求，关于隐私的社会共识就名存实亡了。
   </p>
   <p>
    表面上，个人似乎仍是隐私的所有者或法律上的主体，对隐私的动物性需求也未变。基于隐私和自由意志的社会道德依旧，保护隐私的法规都好好的；毋宁说，新制定的保护措施越来越严格，更上一层楼了。可是仔细观察，这些未变的方面都不再重要，重要的却彻底变样了：信息技术的“天网”已经布下，隐私无处可藏了！所以，尽管法律规定，隐私应当保护，那藏不住的私，是不成其为隐私的。这样看来，“可隐而不可知”是捍卫隐私的关键。易言之，隐私的成立和维护，可隐性是一项必要条件。因为，破坏了隐，也就同时取消了私，即公私的界限。
   </p>
   <p>
    这必要条件遭到破坏，隐私变得可知而失控，正是当下隐私困局的症结所在。一切隐私问题的探讨和对策研究，都不能绕开这一现实。
   </p>
   <p>
   </p>
   <p style="text-align: center;">
    <strong>
     二、信息化和隐私困局
    </strong>
   </p>
   <p>
    信息时代的大势，是隐私的隐秘性趋近消失。结果，直接危及隐私的两要素，公私有别和私的自处。其始作俑者，叫作隐私的信息化或数码化：隐私被信息技术重新包装，放入虚拟电子黑箱，隔绝于人的感官，被“稀释”处理之后，以“中性化”的数据再现。然而，隐私和信息数据是极不协调的两极。数据是技术产品，往往视为客观中性，外延开放包容；隐私却充满了道德价值，属于人类自我意识的范畴，是主观而收敛排他的。当“隐私数据”被捆绑成一个复合概念，这种不协调就被强行抹去，为隐私数据化，继而商品化铺设通道，隐私的天地就彻底改变了。很快，人们开始接受一种全新的生活方式：零隐私世界。
   </p>
   <p>
    我们的观察，可以从隐私的必要条件“可隐性”入手。传统上，关于可隐性的讨论不多。这不是疏忽。从前，日常生活中的隐私，可隐性一向不是问题。仿佛“造物”一开始就恩赐了隐私，让人行使自由意志。人类的感官，获取外界信息的能力有限，眼耳鼻口舌，加上皮肤，远不如许多动物的敏锐好使。一层纸，一段距离，几天的间隔，就足以阻断外界信息的感应接收。而我们引以为傲的大脑，相对于别的动物可称发达，但信息存储的可靠性及处理速度，都很不理想；稍微过量，复杂一点，便束手无策。这就使得个人信息不难保持隐秘。例如，说话的声音跟表情，是瞬间即逝的，通常只有近距离耳闻目睹，才能得知。又如，DNA和脑电波，藏在生物密码中，人的感官无法直接辨认、破译或记录。
   </p>
   <p>
    所以，私的自处而有别于公，生活中不许外人窥探隐私，是自然而然形成习惯和道德规范的。正是这种合乎“人的尺度”的可隐性，成全了隐私，让人当上自己隐私的守卫，从而整个社会有了维护隐私的意愿，在道德也在法律层面。这么看，人之享有隐私，藉其培育自由意志，不仅是出于传统的道德选择，还有赖于客观上隐私信息往往具有较高的隐秘性。换一角度，隐私之能够获得保护，在一定程度上也是人们对其可隐性特征的一种认知和回应。
   </p>
   <p>
    假如人类满足于“造物”的馈赠，不去触动维护隐私的各样屏障，隐私就可以保持可隐而安全。可是，人类好奇，总想探求新知，创制工具，发现世界的奥秘。终于，到了物联网智能时代，隐私的传统屏障坍塌了。生活完全变了，人必须时刻披露个人信息。从农贸市场买菜用微信支付，到旅游点门票的脸像识别；从政府联网办公，到银行电子转账；从百度搜索，到芝麻信用评分和信息诈骗；还有街头巷尾的摄像头，低头族的手机，直至谷歌眼镜、扫地机器人、汽车传感器、植入手臂的上班打卡芯片……个人信息的收集监控不放过生活的任何一个环节。伴随技术进步，隐私的疆域大大拓展了，连基因信号和下意识的意念，也被挖掘了纳入个人信息。信息化的隐私，是信息爆炸，需要超级计算机来处理，接受各类算法的深度分析，以便追踪、模拟、预测人们的思想和行动。隐私不再可隐。私的自处，公私有别，变得越来越不现实了。
   </p>
   <p>
    一般认为，人们尊重隐私，本身便是道德选择。然而在网络世界，隐私的物理载体形态同其他信息并无两样。无论我们的银行存款、股票交易，还是DNA遗传指令、生理特征，都已经化作“0”和“1”的数码序列，由算法处理、电脑存储。那里，隐私的内涵是隐没了的，不会影响技术系统的运作。而隐私的数码序列外形，却丝毫不能出错，否则系统就会罢工。久而久之，信息化的隐私化身为数据而“中性化”，卸下了道德伦理的约束，自由了。
   </p>
   <p>
    隐私信息化，带来两个严重后果：一是隐私脱离主体，超越时空，永久地驻扎在信息工具里。人失去了对自己隐私的控制，而受制于信息工具及其主人。第二，电子数码的信息密度低，噪音强，体量庞大，就像一片茂盛的原始丛林，遵循机器的组织原则，虚拟黑箱运作。人自身的信息处理能力对于如此巨大的数据集，是束手无策的，只能依赖机器。而机器依赖性越高，隐私数据的收集者/掌控者的话语权就越大，个人的谈判力就越低。于是，信息社会里，隐私开始自愿或被迫地从“私”（如消费者）向“公”（如商家）流动，在“公”领域快速而大规模聚集，并按照信息工具主人制定的规则，嵌入人们的日常生活。比如，自从社交网站普及，我们的思想表达、兴趣好恶，连同亲友信息就被平台电商收集起来清洗，成了后者的数据财产。接下去的数据交易，则进一步模糊了信息的属性；隐私本身，也因为在公私之间频繁穿梭而不再“纯粹”，虽然仍指向个人或群体，例如网购者/买家的行为与需求信息，同卖方的交易规则交叉互动而产生的信息集；又如，免费使用搜索器生成的数据。这时，个人维护隐私的意愿就显得不那么理直气壮，而难以坚持，直至隐私与道德价值脱钩。如此，私与公这对经典范畴开始游移不定，公私间界限模糊起来，隐私就无处落脚了。
   </p>
   <p>
    这就是隐私信息化带来的最严峻的挑战。面对挑战，作为拥有自由意志的人类整体，我们仍有机会做出选择，重建隐私的屏障。然而，新经济选择了隐私的商品化，添上了压垮隐私的最后一根稻草。
   </p>
   <p>
   </p>
   <p style="text-align: center;">
    <strong>
     三、隐私商品化和法律保护的迷思
    </strong>
   </p>
   <p>
    隐私商品化，标志着资本主义世界对隐私态度的质的变化，也是信息社会转型期矛盾的一个焦点。隐私有用有市，不是新发现。但隐私既是自由人格的条件，也是人的软肋，需要精心呵护。所以，传统道德讲求节制，是包括尊重隐私在内的；拿自己或他人的隐私做交易，就更是可耻了。道德加上信息能力有限，可谓双重的约束，隐私才能一路平安地走来。
   </p>
   <p>
    现在，智能终端的天网建成，迅速消解了这两道护卫，把蕴藏在隐私中的经济价值和社会控制力裸露了。这大大刺激了隐私的商业挖掘。人们找出各种正当化的理由，隐私淘金热就像放出笼子的野兽，失控了。个人信息充斥了商品市场，在经济生活中占有越来越大的比重。所谓智能经济，几乎所有最赚钱的企业都在挖掘使用和买卖隐私，不论谷歌、脸书、百度跟阿里巴巴。打开脸书，看看你自己上缴的信息吧：照片视频，留言打招呼的就不说了，每天的生活细节、消费习惯、工作安排，亲友往来等等，事无巨细，连你自己都没注意或忘记了的，统统记录在案。谷歌占有的信息集就更庞大了。这些网络巨头深知，隐私就是财富。于是，隐私被冠以新的身份：以市场需求来定价交易的商品。
   </p>
   <p>
    既是商品，就免不了推向市场，“公平”竞争。站在市场经济的立场，挖掘隐私，消费隐私，完全符合发展经济的政策目标。这样一来，尊重隐私、维护隐私的道德和技术屏障，因为有碍市场经济，反而处境尴尬了。资本的策略，是把收集个人信息跟服务的便利、高效、创新挂钩；将分享隐私和焕然一新的消费者感受等同。在饱和的宣传攻势下，商家和政府采集使用个人信息，几乎没有任何阻力，还美其名曰：消费者同商家双赢，老百姓和国家双赢。可是，双赢是市场赢家的说辞；凡是双赢的交易，桌面下面总有一方或第三方要付出代价。智能经济的代价，便是终端用户/消费者交出隐私。表面上，提交隐私信息换取服务和便利，对人只有好处，但其损害后果是潜在或滞后的，包括未来就业发生困难，突然被拒绝医疗保险，或者遭受价格歧视、信用误导（参见拙文《
    <a href="/2415/privacy-money-bag/">
     交出了隐私，再掏空钱袋
    </a>
    》），直至削弱人们负责任的能力或自由意志。
   </p>
   <p>
    最近美国一个例子，为此做了绝妙的脚注。二〇一七年三月，国会投票，封杀了联邦通讯委员会（FCC）年前通过的《互联网隐私规则》（IPR）。《规则》是为保护网络用户的隐私而订立的，限制了网商使用和“分享”即出售用户的网上行为信息。诡异的是，封杀理由与保护隐私毫不搭界，而是平衡网商的利益，保障市场的公平竞争。也就是说，围绕《规则》的利益较量，用户的隐私权益根本没在考虑之列。更有甚者，国会还表决禁止FCC今后颁布任何类似的保护用户隐私的法规。据说，这么做是有经济学依据的。大名鼎鼎的波斯纳法官曾著文阐述：保护个人隐私经常是低效的，而特殊保护又没有必要。以经济学观之，商家的“隐私”或商业秘密比用户隐私更有理由受保护（
    <a href="https://amzn.to/2Jujpba">
     波斯纳，1981
    </a>
    ）。据此逻辑，与其加强隐私保护，不如促进商家的公平竞争，总效益更高。这便是隐私沦为市场交易的商品，必须面对的利益与辩白。尤其令人担忧的是，在道德伦理和技术手段都败下阵来的今天，法律已是捍卫隐私的最后一道脆弱的防线。
   </p>
   <p>
    隐私法如此不堪一击，并不奇怪。立法向来是社会各方利益集团谈判妥协的产物，一般总是向强势方倾斜。如果遵循“经济规律”即市场信条来制定规则，法律就不能妨碍“正常”的商品交换，尤其是实用价值高、市场需求大的商品。而隐私早成了信息市场的宠儿。君不见，个人行为信息支撑着精准投放广告、区别定价；指纹和刷脸，方便了身份识别跟信用追踪；DNA信息则可帮助保险公司甄别投保人风险。难怪隐私保护变得缩手缩脚了，因为所有的强势利益集团都要求法律承认，商家收集个人信息，做成商品，就是科学、正当、高效，故而应当支持。于是，基于技术操作规程，法律将获取和使用隐私分成两类：合法、非法。例如，黑客为非法，因为没有向官方注册；但社交和购物网站合法，只需设置用户选择及相关提示。
   </p>
   <p>
    如此立法执法，造成一个假象：仿佛合法取用隐私对人无害，可以放心“分享”。唯有非法入侵才是隐私遭破坏的原因和隐患，才会影响我们的正常生活。所以只消立法禁止、惩罚隐私数据的盗窃泄漏和非法买卖，我们的隐私就安然无恙了。
   </p>
   <p>
    这当然是自欺欺人。首先，常识告诉我们，媒体经常报道的个人和团伙盗卖个人信息，由于明显违法，偷偷摸摸见不得人，是撼动不了隐私的道德地位的。真正的威胁来自合法的隐私收集和商品化交易，因为那是系统的规模化的受保护市场行为。那些网络平台和产业巨头，大大小小的网站、店家、服务商，日复一日、年复一年地依法获取加工隐私“原材料”，才是对隐私的最大伤害。其次，法律上那一堆看似细致入微的隐私保护条款，不仅对黑箱操作的“漏洞”防不胜防，还是商家的免责保护机制。大数据AI等信息技术日新月异，黑箱操作是设计使然，关乎效率和商业技术秘密。故有评论认为，提高操作透明度，让信息系统内隐私数据的来龙去脉受监督，有助于保护隐私。欧盟最近颁布的《一般数据保护条例》（GDPR) ，添加了条款，要求算法自动决策的使用者为决策给出解释。这是目前为止，对黑箱现象做出的最严格限制。也许会有一定的效果，但《条例》依然回避了隐私商品化问题，而把注意力导向透明度。这是意味深长的。再看脸书，当它的保护隐私设置被合法或不当“攻破”，造成海量用户信息“泄漏”，面对公众舆论跟政府监管部门的压力，确实，老板公开道歉了，保证采取补救措施，提高透明度，甚至答应让用户看到脸书为广告商提供的自己的画像（profile)。但是，它没忘记重申一句：精准投放广告的商业模式不变。
   </p>
   <p>
    商品化成为定局，隐私脱离主体，被合法挖掘追踪分析，广泛用于解读并预测、规制人的欲望、想法和行动，人与隐私的关系就变了。隐私主体失去了话语权，不再是自己隐私的主人和守护者（马丁，1971）。鉴于个人信息的巨大经济价值和政治红利，法律别无选择，只能承认或默许隐私商品化。而公共议题就转变为：谁可以“合法”占有商品化的果实，即商业利益的竞争和垄断。所以，合法或是非法，法律都不可能还人类以隐私之安宁。
   </p>
   <p>
    法律保护的效用如此之低，为什么各国，尤其是发达经济体，还在不断强化隐私权的立法和宣传？原因很简单，那是政府部门同立法者目前唯一能做，而不影响“大局”的事情。当然，那也是业界巨头所希望的。比如小扎，今年三月接受CNN采访，就明确邀请国会立法，规制社交网站，说：问题不是该不该规制，而是什么是正确的规则。
   </p>
   <p>
    资本非常清醒：隐私关乎人的责任能力，占有隐私并获得保护，就要承担相对应的社会责任。当人们交出隐私（无论自愿或不知情），让商家牟利或政府监管，个人的自由意志选择范围便相应地缩小了。人的自主选择越少，承担责任的能力也越小。反之，商家和政府获取的隐私越多，对用户跟社会的控制力也越强。隐私易手，对应的社会责任并不会消失，是需要重新分配的。而且不仅是责任，还是社会风险管理机制的全盘安排。但市场经济是自利者的王国，资本拿隐私赚大钱，却无意承担附着于隐私的社会责任。这就是为什么，他们一边推动隐私商品化，一边在媒体和立法层面，大声疾呼保障隐私。他们企图让人相信，尽管隐私化作他人财产已是生活常态，原始隐私权仍在自己手中，并受到前所未有的法律保护。只需发扬分享的美德，就会得到最佳补偿，即生活便利。巨头们直言不讳，希望失去隐私的人们一如既往地承担行为主体的责任，而掌控隐私的唱唱法律保护的高调，即可免责而享受用户“分享”的馈赠。
   </p>
   <p>
    这，应该就是埃格斯先生设想的零隐私未来的起点同终线。无独有偶，脸书老板早在二〇一〇年就说过，我们的隐私观过时了，
    <a href="https://www.theguardian.com/technology/2010/jan/11/facebook-privacy">
     隐私“不再是社会规范”
    </a>
    。大家不仅乐于分享各种信息，而且喜欢向越来越多的陌生人开放自己，“促成了新的社会规范”（约翰逊, 2010）。是的，只要巨头们奉行《圆圈》里的那句台词：知道（隐私）好。知道一切（隐私）更好！法律就救不了隐私。
   </p>
   <p>
   </p>
   <p style="text-align: center;">
    <strong>
     四、隐私终结，意味着什么？
    </strong>
   </p>
   <p>
    说到这里，隐私经过信息社会商业化的洗礼，命运只有一个去向——走向终结！
   </p>
   <p>
    也许，一些占有者以为，自己可以是隐私终结的例外，甚而能够在支配他人隐私的同时，继续保有自己的隐私？然而，人类的总命运是谁也逃不脱的。从目前AI的发展势头看，我们不得不警惕，一种智力优于人类，且具有“自由意志”的独立物种出现。届时，机器人未必“甘当”人类肢体和心智的延伸，而人类却要依靠它才能生存。因此，隐私危机必须放在人机关系中去思考、规划。个人信息的网络储存越多，分析工具越精致高效，硅基智能成长为独立物种而摆脱人类管控的步伐，就会越快。当AI提升至通用智能，能够在多个领域自我学习，不再需要人的知识连同隐私当它的学习素材，一如自学围棋、碾压人类顶级大脑的“阿尔法零”，那一天，将奏响隐私的挽歌。
   </p>
   <p>
    不过，隐私的终结，并不意味着人类终结。归根结蒂，人是可以零隐私地活着的。迄今为止，隐私对于人类重要，是因为人受制于较低的信息能力，亦即人类为自己安排了那样的生活秩序。所以一方面，隐私是人类高级智力活动的产物，体现了人对自身价值的期待和尊重；另一方面，一旦人类实现“自我超越”，造出通用人工智能（AGI），让机器取代自己思考、劳动、创造，后隐私时代便降临了。
   </p>
   <p>
    进入后隐私时代，人类社会现存的经济基础和上层建筑必然失效了。人类将怎样生活？没有历史经验，没有参照物，很难想象。但有三点可以预期：
   </p>
   <p>
    一、那将是一种没有自觉自愿，不知何为荣辱问责，但高效而标准化的低智低能的生活秩序。那里，隐私失去了意义。它不再能培育自由人格，因为系统中没有自由意志的位置。它不再是社会责任的对价，因为人无须自由选择自主行动而承担责任。它也不再是智力活动的衍生品，因为人类主动放弃了发展智力的努力，满足于在无限优化了的天网下执行指令。
   </p>
   <p>
    二、社会的中心不再是人与人的关系，而是人机关系和机机关系。人类不复为地球的主人，反倒有可能变成硅基智能系统的累赘。不是有AI专家预测，二十五年后，无人驾驶技术成熟，人类将被禁止驾车上路。无人驾驶的交通系统，其交通规则、道路设计、社区安排等，都是不许出错的。人类驾驶只会破坏科学设计的完美，引发交通事故，降低行车效率。实际上，排斥人类参与、删除人类个性，那样的硅胶智能世界，才可能是高效简洁、完满无缺的一个大“圆圈”。
   </p>
   <p>
    三、人类世界本身，共产主义或许是唯一的选项。因为机器人治下，人不但没有了隐私，分工也已消失。所有的个体都集合于一个总体，个人自由即全体的自由，我为人人即人人为我（
    <a href="/2640/ethics-of-artificial-intelligence/">
     冯象，2017
    </a>
    ）。
   </p>
   <p>
    <img alt="Marvin Minsky" src="/img/Marvin_Minsky.jpg" style="float: right; margin: 5px 0px 35px 45px;"/>
    人工智能的先驱，已故的麻省理工学院教授明斯基（Marvin Minsky）说过：有朝一日，当我们掌握了建造智力远胜人类的机器的知识，就不得不面对一个奇特的问题，那就是：该不该建造？我很幸运，因为我可以把这一困难的选择留给后人。但我相信，他们不会建造，除非找到很好的理由（
    <a href="https://www.aaai.org/ojs/index.php/aimagazine/article/view/376/312">
     明斯基，1982
    </a>
    ）。明斯基还曾经对深度学习神经网络技术做出悲观的描述（《认知器演算法》，1969, 1987），他的观点被认为阻碍了AI发展达半个世纪之久，因而颇受诟病。但我想，换个角度，这也许是教授对人类最大的贡献：为我们做好准备迎接机器人时代，赢得了宝贵的时间。
   </p>
   <p>
    明斯基的智慧提醒我们，对隐私应取审慎节制的态度。也许，停下隐私的深度挖掘和过度商业化，我们会少些便捷、舒适和效率，办事会不那么顺畅。但我们就可以继续辛勤劳动，思考学习；继续拥有自由意志，而担起自己的社会责任。我们将保有隐私同人格尊严。这，才是一种更美好的生活。
   </p>
   <p style="text-align: right;">
    二〇一七年十月初稿，一八年四月定稿
    <br/>
    原载《文化纵横》6/2018
   </p>
   <hr/>
   <p>
    参考阅读
   </p>
   <ul>
    <li>
     波斯纳（Richard Posner）：《正义经济学》（
     <a href="https://amzn.to/2Jujpba">
      <em>
       The Economics of Justice
      </em>
     </a>
     ），哈佛大学出版社，1981。
    </li>
    <li>
     <a href="http://fengxiang.ideobook.com/">
      冯象
     </a>
     ：《
     <a href="/2640/ethics-of-artificial-intelligence/">
      我是阿尔法——论人机伦理
     </a>
     》，载《文化纵横》12/2017。
    </li>
    <li>
     马丁（George Martin）：《简议长生》（Brief proposal on immortality: an interim solution），载《生物学医学展望》（
     <em>
      Perspectives in Biology and Medicine
     </em>
     ）14/2:339, 1971。
    </li>
    <li>
     明斯基（Marvin Minsky）：
     <a href="https://www.aaai.org/ojs/index.php/aimagazine/article/view/376/312">
      《为什么人以为电脑做不了》（Why People Think Computer Can’t）
     </a>
     ，载《人工智能杂志》（
     <em>
      AI Magazine
     </em>
     ）3:4, 1982（秋季号）。
    </li>
    <li>
     卫斯汀（Alan Westin）：《隐私与自由》（
     <a href="https://amzn.to/2JjhzGP">
      <em>
       Privacy and Freedom
      </em>
     </a>
     ），Athenaeum, 1967。
    </li>
    <li>
     约翰逊（Bobbie Johnson）：《隐私不再是社会规范，脸书创始人说》（
     <a>
      Privacy no longer a social norm, says Facebook founder
     </a>
     ），载《卫报》（
     <em>
      The Guardian
     </em>
     ）2010.1.10。
    </li>
   </ul>
  </div>
  <!-- /post-entry-content -->
  <footer class="post-entry-footer">
   <p>
    Categorized:
    <a href="http://www.ideobook.com/category/social-sciences/" rel="category tag">
     社会科学 · SOCIAL SCIENCES
    </a>
    -
    <a href="http://www.ideobook.com/category/essays/" rel="category tag">
     评论随笔 · ESSAYS
    </a>
   </p>
   <p>
    Tagged:
    <a href="http://www.ideobook.com/tag/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd/" rel="tag">
     人工智能
    </a>
    -
    <a href="http://www.ideobook.com/tag/%e5%88%a9%e6%b1%82%e5%90%8c/" rel="tag">
     利求同
    </a>
    -
    <a href="http://www.ideobook.com/tag/%e5%95%86%e4%b8%9a%e5%8c%96/" rel="tag">
     商业化
    </a>
    -
    <a href="http://www.ideobook.com/tag/%e5%95%86%e5%93%81%e5%8c%96/" rel="tag">
     商品化
    </a>
    -
    <a href="http://www.ideobook.com/tag/%e8%84%b8%e4%b9%a6/" rel="tag">
     脸书
    </a>
    -
    <a href="http://www.ideobook.com/tag/%e8%b5%84%e6%9c%ac/" rel="tag">
     资本
    </a>
    -
    <a href="http://www.ideobook.com/tag/%e9%9a%90%e7%a7%81/" rel="tag">
     隐私
    </a>
   </p>
  </footer>
  <!-- /post-entry-footer -->
  <footer class="post-entry-footer">
   <p>
    如果您喜欢本站文章，
    <a href="http://www.ideobook.com/subscription/">
     请订阅我们的电子邮件
    </a>
    ，以便及时获取更新通知。
   </p>
   <p>
    好书推荐:
    <a href="https://amzn.to/2BLHdBY">
     脱销多年新近重印的四卷本奥威尔文集 The Collected Essays, Journalism, and Letters of George Orwell: Volume 1
    </a>
    ,
    <a href="https://amzn.to/32VpT9o">
     2
    </a>
    ,
    <a href="https://amzn.to/2pk1FHp">
     3
    </a>
    ,
    <a href="https://amzn.to/32WV0RW">
     4
    </a>
    .
   </p>
  </footer>
  <div class="boxframe" id="commentsbox">
   <div class="comments-area clearfix" id="comments">
    <div class="comment-respond" id="respond">
     <h3 class="comment-reply-title" id="reply-title">
      Leave a Reply
      <small>
       <a href="/2745/future-privacy/#respond" id="cancel-comment-reply-link" rel="nofollow" style="display:none;">
        <span class="wpex-icon-remove-sign">
        </span>
       </a>
      </small>
     </h3>
    </div>
    <!-- #respond -->
   </div>
   <!-- /comments -->
  </div>
  <!-- /commentsbox -->
 </div>
 <!-- /post-entry-text -->
</article>

