---
layout: post
title: "算法是个黑箱，让它“透明化”是不够的"
date: 2018-12-18
author: 方可成
from: http://cnpolitics.org/2018/12/algorithms-and-transparent/
tags: [ 政見 ]
categories: [ 政見 ]
---

<div class="post-block">
 <h1 class="post-head">
  算法是个黑箱，让它“透明化”是不够的
 </h1>
 <p class="post-subhead">
 </p>
 <p class="post-tag">
 </p>
 <p class="post-author">
  <!--a href="http://cnpolitics.org/author/admin/">方可成</a-->
  <a href="http://cnpolitics.org/author/admin/">
   方可成
  </a>
  <span style="font-size:14px;color:#b9b9b9;">
   ｜2018-12-18
  </span>
 </p>
 <!--p class="post-lead">透明化真的能带来对事物的完整掌控吗？</p-->
 <div class="post-body">
  <p>
   <a href="http://cnpolitics.org/wp-content/uploads/2018/12/640-3.jpeg">
    <img alt="" class="alignnone size-full wp-image-13060" height="319" src="http://cnpolitics.org/wp-content/uploads/2018/12/640-3-e1545139453626.jpeg" width="566"/>
   </a>
  </p>
  <p>
   我们的生活越来越被一种叫做“算法”的东西决定。
  </p>
  <p>
   你在搜索引擎键入关键词，出来什么结果、按照什么顺序排列，是由算法决定的；你在微博和今日头条上刷出什么文章和广告，也是算法决定的；你打网约车、听歌、购物，往往都有算法的参与……在一些国家还出现了用算法来判案，用算法来决定是否拘捕一个人。《人类简史》的作者赫拉利甚至还预测：未来你的伴侣可能也是由算法计算，然后推荐给你的。
  </p>
  <p>
   简单理解，算法就是由计算机自动执行的一套规则。它在人类社会中扮演的角色越来越重要，但人们对算法还知之甚少。而这自然是很危险的：如果我们不了解算法，它就可能被用于侵害我们的权益、伤害社会正义，而我们可能对此毫无察觉。
  </p>
  <p>
   因此，近年来，有越来越多人呼吁：科技公司应该打开算法这个“黑箱”，让算法透明化，接受公众监督。比如，Facebook让哪些内容出现在人们的时间线上，他们是怎样决定的？为什么有时候会推荐假新闻？要不，公开代码给大家看看？
  </p>
  <p>
   不过，美国南加州大学的两位研究者在传播学期刊《New Media &amp; Society》上发表的一篇论文认为：仅仅讲“算法透明化”是不够的，甚至可能会让人误入歧途。
  </p>
  <p>
   他们说，呼吁透明化，是因为人们理所当然地认为：当人们看见了一个东西，自然就有机会和义务去监督它。简言之，透明化带来一种掌控感。
  </p>
  <p>
   然而，这样的想法是存在漏洞的。两位研究者总结了“算法透明化”的10大局限性。
  </p>
  <p>
   <strong>
    第一，透明度和权力可能是脱离的。
   </strong>
   看见了，并不一定意味着能够采取行动。比如，在某些独裁国家，民众能够看见腐败，但也无济于事，因为民众什么都做不了，这样反而会助长犬儒心态。如果人们不能及时处理、消化、运用那些被公开的信息，那透明了也是白搭。
  </p>
  <p>
   <strong>
    第二，透明化可能有副作用。
   </strong>
   有时，极端的透明化会让那些边缘化的反抗群体被暴露。商业公司则经常指出：算法透明化可能会使得一些人利用系统的特性来作弊。
  </p>
  <p>
   <strong>
    第三，透明化有时反而会遮蔽真相。
   </strong>
   当信息过多、无用信息淹没了有用信息的时候，透明化可能适得其反，让人找不到头绪。
  </p>
  <p>
   <strong>
    第四，透明化会制造一种二元对立的思维。
   </strong>
   信息的封闭和透明并不是非黑即白的选择，不是只有“完全黑箱”和“完全透明”两种选择。比如，斯诺登在曝光NSA的监控项目时，就没有直接向公众发布，而是选择与自己信任的、有能力解读这些信息的记者合作。
  </p>
  <p>
   <strong>
    第五，透明化会过多强调个体责任。
   </strong>
   透明化假定的前提是，人人都能理解被公开的算法，并进行有意义的讨论。但这是过于理想化的设想，是不可能实现的。两位研究者将其称为“新自由主义模式的个体能动性”，即把重任都施加在个人身上。
  </p>
  <p>
   <strong>
    第六，透明并不一定带来信任。
   </strong>
   信任是双向的。达芬奇拒绝发布早期潜水艇设计的详细手稿，因为他害怕被坏人用来制造水下暗杀。一些开发者不希望公布算法，不是因为商业秘密，而是不想被某些人利用。
  </p>
  <p>
   <strong>
    第七，透明化可能让一些专业人士圈定自己的领域，拒绝公众参与和监督。
   </strong>
   即便是公开的信息，也可以被专业群体利用起来，塑造自身权威，甚至被利益集团腐蚀，通过对公开信息的曲解操作，为他们代言。
  </p>
  <p>
   <strong>
    第八，透明化可能会让“看见”比“理解”更受重视。
   </strong>
   看见了黑箱里面，不代表理解了它的原理。要理解算法，仅仅看见一行行的代码是不够的，还要学会与它们互动。
  </p>
  <p>
   <strong>
    第九，透明化是有技术方面的局限性的。
   </strong>
   算法越来越庞大、复杂，以至于在科技公司开发算法的过程中，出现了很多连程序员自己都无法理解的结果。如果他们自己都理解不了，那么公开给大家，也没什么用。
  </p>
  <p>
   <strong>
    第十，算法有时间上的局限性。
   </strong>
   算法在不断变动中，看见了当下的算法，不代表能够预见未来的算法怎样运转。
  </p>
  <p>
   两位研究者列举出这些局限性，并不是想说：透明化的方向是错误的。其实，他们的意思是：仅仅依赖“透明化”，不足以真正监督算法。他们想做的，是在透明化的基础上更进一步，想办法避免以上这些问题。
  </p>
  <p>
   他们认为，我们要做的不是“朝系统里面看”，而是“将不同的系统结合起来看”，其中包括在这个系统中的人，也包括代码、机器等非人类元素。
  </p>
  <p>
   比如说，如果透明化之后，人们还是没有足够的权力去监督，那么我们就应该重视：如何去改变不对等的权力关系，而不是仅仅停留在透明这一步。再比如，如果透明化导致有效信息被淹没，那么关注的重点就应该放在：系统是如何在信息过载当中，有意转移我们注意力的。如果连程序员自己都搞不懂算法的结果，那我们应该考虑的就是：是不是要推迟算法的应用时间，留出更多的时间给开发者，甚至，是否根本就不应该来开发这样一套系统？
  </p>
  <p>
   总之，这篇论文指出的是透明化的局限性，而不是它的错误性。研究者认为，我们应该对算法有更多了解，而不能只停留在要求算法透明化这一步。
  </p>
  <p>
   虽然文章说的是算法，但其实我们也可以联系到其他领域。无论在哪个领域，“透明化”都不是一个完全能实现监督的方式。
  </p>
  <p>
   <strong>
    本文系网易新闻·网易号“各有态度”特色内容。
   </strong>
  </p>
  <div class="post-endnote">
   <h4>
    参考文献
   </h4>
   <ul>
    <li>
     Ananny, M., &amp; Crawford, K. (2018). Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability. New Media &amp; Society, 20(3), 973-989.
    </li>
   </ul>
  </div>
 </div>
 <!-- icon list -->
 <!--/div-->
 <!-- social box -->
 <div class="post-end-button back-to-top">
  <p style="padding-top:20px;">
   回到开头
  </p>
 </div>
 <div id="display_bar">
  <img src="http://cnpolitics.org/wp-content/themes/CNPolitics/images/shadow-post-end.png"/>
 </div>
</div>

