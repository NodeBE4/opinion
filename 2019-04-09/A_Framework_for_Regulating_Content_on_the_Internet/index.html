<!DOCTYPE html>
<html>
  <head>
  <title>A Framework for Regulating Content on the Internet – 觀點 – 從草根到大師 git.io/JJCxS</title>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="
  
     A Framework for Regulating Content on the Internet 
    
  Posted on             Tuesday, April 9, 2019 
            Friday, July 24, 2020 
     Author  by  Ben Thompson   
    
    
  
  
  
    This week, when the U.K.’s Secretary of State for Digital, Culture, Media and Sport and the Secretary of State for the Home Department released  a white paper  calling for significantly increased regulation for tech companies, the scope of the debate was predictable. The  MIT Technology Review  laid it out succinctly:
    
      Technology giants will be forced to have a “duty of care” for their users, if a proposal announced by the government on Monday becomes law. The proposal — a “white paper,” in UK legal parlance, which is one of the first stages of a formal government policy — is, on the surface at least, sweeping in scope and is a serious shot across the bows for big tech companies. But it has also raised some serious concerns about how it will be implemented and the possible consequences it might have on citizens’ free speech…
      The proposals have raised interest among academics and observers, and alarm among privacy campaigners. The former note that while the document is scant on details despite being tens of thousands of words long, it sets out a clear direction in a way few countries have been willing to do. But the latter fear that the way it is implemented could easily lead to censorship for users of social networks rather than curbing the excesses of the networks themselves.
    
    This proposal comes on the tail of an exposé in Bloomberg entitled  YouTube Executives Ignored Warnings, Letting Toxic Videos Run Rampant  ; the debate around that piece, which I wrote about last week in two Daily Updates (  here  and  here  ), not only touched on the question of free speech, but also the sheer scale of the problem — and, relatedly, the sheer scale of Facebook of Google.
     Problematic Regulation 
    In short, there are clear questions that arise around all of these exposés and proposals:
    
      First, what content should be regulated, if any, and by whom?
      Second, what is a viable way to monitor the content generated on these platforms?
      Third, how can privacy, competition, and free expression be preserved?
    
    You can see how these questions quickly arrive at competing answers when looking at recent attempts at regulation:
    
      GDPR has certainly increased the number of website click-throughs; it has also strengthened Facebook and  especially Google’s competitive position  exactly  as predicted  .
      The  European Copyright Directive  , specifically Article 13, makes platforms liable for copyright violations, and while the European Parliament took care to state that this wasn’t a requirement for a content filter, there is no other viable solution. Content filters are not only extremely difficult and expensive to develop (Google  has spent $100 million plus on ContentID  ), entrenching the largest players that have the resources to fund development and the leverage to pay for it, they will also necessarily be overly strict, limiting user expression.
      Even more egregious than the Copyright Directive, amazingly enough, is  Australia’s new law  about “abhorrent violent material” like the live-streaming of the horrific Christchurch mass shooting. Companies are liable if such content is discovered on their service 
     period
     — being told it exists is sufficient evidence of recklessness — and worse, every company in the stack is liable, from ISPs to cloud providers to social networks. That leaves no choice but to spy on all user traffic or, for small-and-medium-sized platforms outside of Australia, avoid the country altogether.
    
    At the same times, the Christchurch video and its spread are clearly problematic — there is something off about the current state of affairs.
     The Christchurch Video 
    It hardly bears noting that in a pre-Internet world there would be no widespread video of the Christchurch hate crime. Capturing video required specialized equipment, and more importantly, broadcasting video was limited to a small number of television stations, all of which, even if they had the video, would have exercised their editorial judgment to keep it off the air.
    What is critical to note, though, is that it is not a direct leap from “pre-Internet” to the Internet as we experience it today. The terrorist in Christchurch didn’t set up a server to livestream video from his phone; rather, he used Facebook’s built-in functionality. And, when it came to the video’s spread, the culprit was not email or message boards, but social media generally. To put it another way, to have spread that video on the Internet would be possible but difficult; to spread it on social media was trivial.
    The core issue is business models: to set up a live video streaming server is somewhat challenging, particularly if you are not technically inclined, and it costs money. More expensive still are the bandwidth costs of actually reaching a significant number of people. Large social media sites like Facebook or YouTube, though, are happy to bear those costs in service of a larger goal: building their advertising businesses.
    The key differentiator of  Super-Aggregators  is that they have three-sided markets: users, content providers (which may include users!), and advertisers. Both content providers and advertisers want the user’s attention, and the latter are willing to pay for it. This leads to a beautiful business model from the perspective of a Super-Aggregator:
    
      Content providers provide content for free, facilitated by the Super-Aggregator
      Users view that content, and provide their own content, facilitated by the Super-Aggregator
      Advertisers can reach the exact users they want by paying the Super-Aggregator
    
    Everything is aligned from the Super-Aggregator perspective: users give attention that content providers work to earn, and advertisers compete to buy their way in.
      
    Moreover, this arrangement allows Super-Aggregators to be relatively unconcerned with 
    what
    exactly flows across their network: advertisers simply want eyeballs, and the revenue from serving them pays for the infrastructure to not only accommodate users but also give content suppliers the tools to provide whatever sort of content those users may want.
    That, there, is the rub: given that these platforms are basically  reflections of humanity  , what users want varies from the beautiful to the profane — and things far more ugly than that. And worse, there is no editorial judgment to keep users from what they want, or suppliers from providing it. Indeed, that such sordid content can exist on YouTube and Facebook is testament to just how popular they are; that such content is effectively incentivized speaks to the fact that YouTube and Facebook’s moneymaking mechanism is completely divorced from this content match-making.
     Market Failure 
    This is, in its own way, a market failure, albeit not, to be clear, in an economic sense: the allocation of goods and services by a Super-Aggregator is not only efficient, but also generates significant consumer surpluses. The failure, rather, comes from videos like that of the Christchurch massacre, or problematic YouTube content. It is not good for society that terrorists be able to freely broadcast their videos, or that  child-exploitation videos spread on YouTube  .
    The problem is that there is no way to check this behavior: the vast majority of Facebook and YouTube users self-select away from this content, and while advertisers raise a fuss if they find out their ads are alongside this content, they have no incentive to leave the platforms entirely. That leaves Facebook and YouTube themselves, but while they would surely like to avoid PR black eyes, what they like even more is the limitless supply of attention and content that comes from making it easier for anyone anywhere to upload and view content of any type.
    Note how much different this is than a traditional customer-supplier relationship, even one mediated by a market-maker: users disgusted by Uber, for example, could switch to Lyft, directly impacting Uber’s bottom-line. Or go back a few years, when GoDaddy expressed support for SOPA copyright legislation: the company was  forced to change its position  in the face of widespread boycotts (including by yours truly). When users pay they have power; when users and those who pay are distinct, as is the case with these advertising-supported Super-Aggregators, the power of persuasion — that is, the power of the market — is absent.
     The Three Frees 
    There are, in Internet parlance, three types of “free”:
    
      “Free as in speech” means the freedom or right to do something
      “Free as in beer” means that you get something for free without any additional responsibility
      “Free as in puppy” means that you get something for free, but the longterm costs are substantial
    
    Most in the West agree, at least in theory, with the idea that the Internet should preserve “free as in speech”; China in particular represents a cautionary tale as to how technology can be leveraged in the opposite direction. The question that should be asked, though, is if preserving “free as in speech” should also mean preserving “free as in beer.”
    Specifically, Facebook and YouTube offer “free as in speech” in conjunction with “free as in beer”: content can be created and proliferated without any responsibility, including cost. Might it be better if content that society deemed problematic were still “free as in speech”, but also “free as in puppy” — that is, with costs to the supplier that aligned with the costs to society?
     A Regulatory Framework for the Internet 
    This distinction might square some of the circles I presented at the beginning: how might society regulate content without infringing on rights or destroying competitive threats to the largest incumbents?
    Start with this precept: the Internet ought to be available to anyone without any restriction. This means banning content blocking or throttling at the ISP level with regulation designed for the Internet. It also means that platform providers generally speaking should continue to not be liable for content posted on their services (platform providers include everything from AWS to Azure to shared hosts, and everything in-between); these platform providers can, though, choose to 
    not
    host content suppliers they do not want to, whether because of their own corporate values or because they fear boycott from other customers.
    I think, though, that platform providers that primarily monetize through advertising should be in their own category: as I noted above, because these platform providers separate monetization from content supply and consumption, there is no price or payment mechanism to incentivize them to be concerned with problematic content; in fact, the incentives of an advertising business drive them to focus on engagement, i.e. giving users what they want, no matter how noxious.
    This distinct categorization is critical to developing regulation that actually addresses problems without adverse side effects. Australia, for example, has no need to be concerned about shared hosting sites, but rather Facebook and YouTube; similarly, Europe wants to rein in tech giants without — and I will give the E.U. the benefit of the doubt here — burdening small online businesses with massive amounts of red tape. And, from a theoretical perspective, the appropriate place for regulation is where there is market failure; constraining the application to that failure is what is so difficult.
    The result is a regulatory framework that looks like this:
      
    “Free as in speech” is guaranteed at the infrastructure level, the market polices platform providers generally (i.e. “free as in puppy”), while regulation is narrowly limited to businesses that are primarily monetized through advertising (i.e. “free as in beer”) and thus impervious to traditional content marketplace pressures.
    
    This framework, to be clear, leaves many unanswered questions: what regulations, for example, are appropriate for companies like YouTube and Facebook? Are they even constitutional in the United States? Should we be concerned about the lack of competition in these regulated categories, or encouraged that there will now be a significant incentive to build competitive services that do not rely on advertising? What about VC-funded companies that have not yet specified their business models?
    Still, I think this framework provides a very important foundation for addressing many of the flaws in today’s regulatory proposals, particularly the unintended effects on small-and-medium sized businesses and the platforms that support them which, I believe, are critical for the economy of the future. Regulators and lawmakers should, as always, be wary that in the well-meaning attempt to shape the world as it is they foreclose the world that might be.
    
      
         Share 
        
          
              Facebook  
              Twitter  
              LinkedIn  
              Email  
            
          
        
      
    
    
       
     Related
     
    
  
  

" />
    <meta property="og:description" content="
  
     A Framework for Regulating Content on the Internet 
    
  Posted on             Tuesday, April 9, 2019 
            Friday, July 24, 2020 
     Author  by  Ben Thompson   
    
    
  
  
  
    This week, when the U.K.’s Secretary of State for Digital, Culture, Media and Sport and the Secretary of State for the Home Department released  a white paper  calling for significantly increased regulation for tech companies, the scope of the debate was predictable. The  MIT Technology Review  laid it out succinctly:
    
      Technology giants will be forced to have a “duty of care” for their users, if a proposal announced by the government on Monday becomes law. The proposal — a “white paper,” in UK legal parlance, which is one of the first stages of a formal government policy — is, on the surface at least, sweeping in scope and is a serious shot across the bows for big tech companies. But it has also raised some serious concerns about how it will be implemented and the possible consequences it might have on citizens’ free speech…
      The proposals have raised interest among academics and observers, and alarm among privacy campaigners. The former note that while the document is scant on details despite being tens of thousands of words long, it sets out a clear direction in a way few countries have been willing to do. But the latter fear that the way it is implemented could easily lead to censorship for users of social networks rather than curbing the excesses of the networks themselves.
    
    This proposal comes on the tail of an exposé in Bloomberg entitled  YouTube Executives Ignored Warnings, Letting Toxic Videos Run Rampant  ; the debate around that piece, which I wrote about last week in two Daily Updates (  here  and  here  ), not only touched on the question of free speech, but also the sheer scale of the problem — and, relatedly, the sheer scale of Facebook of Google.
     Problematic Regulation 
    In short, there are clear questions that arise around all of these exposés and proposals:
    
      First, what content should be regulated, if any, and by whom?
      Second, what is a viable way to monitor the content generated on these platforms?
      Third, how can privacy, competition, and free expression be preserved?
    
    You can see how these questions quickly arrive at competing answers when looking at recent attempts at regulation:
    
      GDPR has certainly increased the number of website click-throughs; it has also strengthened Facebook and  especially Google’s competitive position  exactly  as predicted  .
      The  European Copyright Directive  , specifically Article 13, makes platforms liable for copyright violations, and while the European Parliament took care to state that this wasn’t a requirement for a content filter, there is no other viable solution. Content filters are not only extremely difficult and expensive to develop (Google  has spent $100 million plus on ContentID  ), entrenching the largest players that have the resources to fund development and the leverage to pay for it, they will also necessarily be overly strict, limiting user expression.
      Even more egregious than the Copyright Directive, amazingly enough, is  Australia’s new law  about “abhorrent violent material” like the live-streaming of the horrific Christchurch mass shooting. Companies are liable if such content is discovered on their service 
     period
     — being told it exists is sufficient evidence of recklessness — and worse, every company in the stack is liable, from ISPs to cloud providers to social networks. That leaves no choice but to spy on all user traffic or, for small-and-medium-sized platforms outside of Australia, avoid the country altogether.
    
    At the same times, the Christchurch video and its spread are clearly problematic — there is something off about the current state of affairs.
     The Christchurch Video 
    It hardly bears noting that in a pre-Internet world there would be no widespread video of the Christchurch hate crime. Capturing video required specialized equipment, and more importantly, broadcasting video was limited to a small number of television stations, all of which, even if they had the video, would have exercised their editorial judgment to keep it off the air.
    What is critical to note, though, is that it is not a direct leap from “pre-Internet” to the Internet as we experience it today. The terrorist in Christchurch didn’t set up a server to livestream video from his phone; rather, he used Facebook’s built-in functionality. And, when it came to the video’s spread, the culprit was not email or message boards, but social media generally. To put it another way, to have spread that video on the Internet would be possible but difficult; to spread it on social media was trivial.
    The core issue is business models: to set up a live video streaming server is somewhat challenging, particularly if you are not technically inclined, and it costs money. More expensive still are the bandwidth costs of actually reaching a significant number of people. Large social media sites like Facebook or YouTube, though, are happy to bear those costs in service of a larger goal: building their advertising businesses.
    The key differentiator of  Super-Aggregators  is that they have three-sided markets: users, content providers (which may include users!), and advertisers. Both content providers and advertisers want the user’s attention, and the latter are willing to pay for it. This leads to a beautiful business model from the perspective of a Super-Aggregator:
    
      Content providers provide content for free, facilitated by the Super-Aggregator
      Users view that content, and provide their own content, facilitated by the Super-Aggregator
      Advertisers can reach the exact users they want by paying the Super-Aggregator
    
    Everything is aligned from the Super-Aggregator perspective: users give attention that content providers work to earn, and advertisers compete to buy their way in.
      
    Moreover, this arrangement allows Super-Aggregators to be relatively unconcerned with 
    what
    exactly flows across their network: advertisers simply want eyeballs, and the revenue from serving them pays for the infrastructure to not only accommodate users but also give content suppliers the tools to provide whatever sort of content those users may want.
    That, there, is the rub: given that these platforms are basically  reflections of humanity  , what users want varies from the beautiful to the profane — and things far more ugly than that. And worse, there is no editorial judgment to keep users from what they want, or suppliers from providing it. Indeed, that such sordid content can exist on YouTube and Facebook is testament to just how popular they are; that such content is effectively incentivized speaks to the fact that YouTube and Facebook’s moneymaking mechanism is completely divorced from this content match-making.
     Market Failure 
    This is, in its own way, a market failure, albeit not, to be clear, in an economic sense: the allocation of goods and services by a Super-Aggregator is not only efficient, but also generates significant consumer surpluses. The failure, rather, comes from videos like that of the Christchurch massacre, or problematic YouTube content. It is not good for society that terrorists be able to freely broadcast their videos, or that  child-exploitation videos spread on YouTube  .
    The problem is that there is no way to check this behavior: the vast majority of Facebook and YouTube users self-select away from this content, and while advertisers raise a fuss if they find out their ads are alongside this content, they have no incentive to leave the platforms entirely. That leaves Facebook and YouTube themselves, but while they would surely like to avoid PR black eyes, what they like even more is the limitless supply of attention and content that comes from making it easier for anyone anywhere to upload and view content of any type.
    Note how much different this is than a traditional customer-supplier relationship, even one mediated by a market-maker: users disgusted by Uber, for example, could switch to Lyft, directly impacting Uber’s bottom-line. Or go back a few years, when GoDaddy expressed support for SOPA copyright legislation: the company was  forced to change its position  in the face of widespread boycotts (including by yours truly). When users pay they have power; when users and those who pay are distinct, as is the case with these advertising-supported Super-Aggregators, the power of persuasion — that is, the power of the market — is absent.
     The Three Frees 
    There are, in Internet parlance, three types of “free”:
    
      “Free as in speech” means the freedom or right to do something
      “Free as in beer” means that you get something for free without any additional responsibility
      “Free as in puppy” means that you get something for free, but the longterm costs are substantial
    
    Most in the West agree, at least in theory, with the idea that the Internet should preserve “free as in speech”; China in particular represents a cautionary tale as to how technology can be leveraged in the opposite direction. The question that should be asked, though, is if preserving “free as in speech” should also mean preserving “free as in beer.”
    Specifically, Facebook and YouTube offer “free as in speech” in conjunction with “free as in beer”: content can be created and proliferated without any responsibility, including cost. Might it be better if content that society deemed problematic were still “free as in speech”, but also “free as in puppy” — that is, with costs to the supplier that aligned with the costs to society?
     A Regulatory Framework for the Internet 
    This distinction might square some of the circles I presented at the beginning: how might society regulate content without infringing on rights or destroying competitive threats to the largest incumbents?
    Start with this precept: the Internet ought to be available to anyone without any restriction. This means banning content blocking or throttling at the ISP level with regulation designed for the Internet. It also means that platform providers generally speaking should continue to not be liable for content posted on their services (platform providers include everything from AWS to Azure to shared hosts, and everything in-between); these platform providers can, though, choose to 
    not
    host content suppliers they do not want to, whether because of their own corporate values or because they fear boycott from other customers.
    I think, though, that platform providers that primarily monetize through advertising should be in their own category: as I noted above, because these platform providers separate monetization from content supply and consumption, there is no price or payment mechanism to incentivize them to be concerned with problematic content; in fact, the incentives of an advertising business drive them to focus on engagement, i.e. giving users what they want, no matter how noxious.
    This distinct categorization is critical to developing regulation that actually addresses problems without adverse side effects. Australia, for example, has no need to be concerned about shared hosting sites, but rather Facebook and YouTube; similarly, Europe wants to rein in tech giants without — and I will give the E.U. the benefit of the doubt here — burdening small online businesses with massive amounts of red tape. And, from a theoretical perspective, the appropriate place for regulation is where there is market failure; constraining the application to that failure is what is so difficult.
    The result is a regulatory framework that looks like this:
      
    “Free as in speech” is guaranteed at the infrastructure level, the market polices platform providers generally (i.e. “free as in puppy”), while regulation is narrowly limited to businesses that are primarily monetized through advertising (i.e. “free as in beer”) and thus impervious to traditional content marketplace pressures.
    
    This framework, to be clear, leaves many unanswered questions: what regulations, for example, are appropriate for companies like YouTube and Facebook? Are they even constitutional in the United States? Should we be concerned about the lack of competition in these regulated categories, or encouraged that there will now be a significant incentive to build competitive services that do not rely on advertising? What about VC-funded companies that have not yet specified their business models?
    Still, I think this framework provides a very important foundation for addressing many of the flaws in today’s regulatory proposals, particularly the unintended effects on small-and-medium sized businesses and the platforms that support them which, I believe, are critical for the economy of the future. Regulators and lawmakers should, as always, be wary that in the well-meaning attempt to shape the world as it is they foreclose the world that might be.
    
      
         Share 
        
          
              Facebook  
              Twitter  
              LinkedIn  
              Email  
            
          
        
      
    
    
       
     Related
     
    
  
  

" />
    
    <meta name="author" content="觀點" />

    
    <meta property="og:title" content="A Framework for Regulating Content on the Internet" />
    <meta property="twitter:title" content="A Framework for Regulating Content on the Internet" />
    

  <link rel="stylesheet" type="text/css" href="/opinion/style.css" />
  <link rel="alternate" type="application/rss+xml" title="觀點 - 從草根到大師 git.io/JJCxS" href="/opinion/feed.xml" />

  <!-- Social Share Kit CSS -->
  <link rel="stylesheet" href="/opinion/assets/css/social-share-kit.css" type="text/css">
  <link rel="stylesheet" href="/opinion/assets/css/font-awesome.min.css" type="text/css">
  <link rel="stylesheet" href="/opinion/assets/css/bootstrap.min.css" type="text/css">
  <script type="text/javascript" src="/opinion/assets/js/jquery-3.5.1.js"></script>
  <script type="text/javascript" src="/opinion/assets/js/page.js"></script>

</head>

  <body>
    <div class="wrapper-masthead">
  <div class="container">
    <header class="masthead clearfix">
      

      <div class="site-info">
        <h1 class="site-name" style="display: inline-block;"><a href="/opinion/">觀點</a></h1>
        <i class="site-description" style="font-size: 12px;">從草根到大師 git.io/JJCxS</i>
      </div>

      <nav>
        <span id="search-container" >
          <a href="/opinion/tools"><i class="fa fa-bookmark twitter" title="百宝箱"></i></a>
        <a><i class="fa fa-search" title="限前100結果"></i></a><input type="text" id="search-input" placeholder="標題 作者 來源 日期 (17499)"
          style="margin: 10px 0px 0px 0px; height: 30px;width: auto" title="本站最正確的打開方式">
        </span>
        
        
        <a href="/opinion/categories" style="color: Tomato;"><i class="fa fa-tags" title="分类"></i></a>
        
        
        
        <a href="https://be4.herokuapp.com/" style="color: #003366;"><i class="fa fa-comments" title="论坛"></i></a>
        
        
        
        <a href="/opinion/about"><i class="fa fa-info-circle" title="关于"></i></a>
        
        
        <a title="电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇，del同来源旧一篇" onclick="toggle_visibility('help')"><i class="fa fa-question-circle"></i></a>
        <a id="fa-home" href="https://nodebe4.github.io" title="BE4服务列表" onclick="//toggle_visibility('site-list')"><i class="fa fa-home" aria-hidden="true"></i></a>
      </nav>

    </header>
    <div id="site-list" class="tags" style="display: block;text-align: right;border-bottom: 1px solid lightGray;"><noscript><span style="background-color: #e8e8e8;color: #d10000;font-size: 14px;">开启浏览器JavaScript以获取搜索功能和更好的浏览体验</span></noscript></div>
    <p id="help" style="font-size: 14px;display: none;text-align: right;"><span style="color:green;">电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇, del同来源旧一篇</span>; <span style="color:orange">对应触屏FAB：上下右左</span>; 轉Markdown<a href="https://euangoddard.github.io/clipboard2markdown/"><i class="fa fa-file-text-o"></i></a></p>
  </div>
</div>

<script type="text/javascript" >
  function toggle_visibility(id){
    var help = document.getElementById(id)
    if (help.style.display=='none'){
      help.style.display='block';
    }else{
      help.style.display='none';
    }
  }

  const url = "https://nodebe4.github.io/sitelist.json"

  document.addEventListener("DOMContentLoaded", function(event){
    // var homebtn = document.getElementById("fa-home")
    // homebtn.removeAttribute("href")
    var content = document.getElementById("site-list");
    content.innerHTML = ''
    var ul = document.createElement("ul")
    ul.classList.add("label")
    content.appendChild(ul)
    var cnt = 0

    $.getJSON(url, function(allsites) {

      allsites.map(item =>{
        var li = document.createElement('li')
        li.classList.add("tag")
        li.id = 'site-' + cnt
        ul.appendChild(li)
        var a0 = document.createElement('a')
        li.appendChild(a0)
        a0.href = item.url[0]
        var span = document.createElement('span')
        a0.appendChild(span)
        span.innerText = item['name']
        // span.style.backgroundColor = item['background-color']
        // span.style.color='#E4CBC3'
        span.style.color = item['background-color']
        span.style['font-size'] = '14px'
        cnt += 1
        // test_alive(li.id, a0.href)
      })
    })
  })

function test_alive(id, url){
  var divstatus = document.getElementById(id)
  const base = 'https://textance.herokuapp.com/title/'
  var fullurl = base + url
  $.ajax({
      url: fullurl,
      complete: function(data) {
        if (data.responseText.includes('502')){
          // divstatus.style.color='#FBB7B7'
          // divstatus.style.color='gray'
          // divstatus.title = "服务器无响应"
          divstatus.parentNode.removeChild(divstatus)
        }else{
          // divstatus.style.color='#B6FAC8'
          divstatus.title = data.responseText
        }
      }
  });
  return divstatus
}
</script>



    <!-- Left & centered positioning -->

<div class="ssk-sticky ssk-right ssk-center ssk-sticky-hide-xs ssk-group ssk-round">
  
    <a href="https://be4news.pythonanywhere.com/archivenow/ia/https%3A%2F%2Fstratechery.com%2F2019%2Fa-regulatory-framework-for-the-internet%2F" class="ssk ssk-link" title="存到互联网档案馆" target="_blank"></a>
    <a href="https://www.facebook.com/sharer.php?u=https://stratechery.com/2019/a-regulatory-framework-for-the-internet/" class="ssk ssk-facebook"></a>
    <a href="https://twitter.com/intent/tweet?url=https://stratechery.com/2019/a-regulatory-framework-for-the-internet/&text=A Framework for Regulating Content on the Internet&hashtags=觀點" class="ssk ssk-twitter"></a>
    <a href="https://reddit.com/submit?url=https://stratechery.com/2019/a-regulatory-framework-for-the-internet/&title=A Framework for Regulating Content on the Internet" class="ssk ssk-reddit"></a>
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://stratechery.com/2019/a-regulatory-framework-for-the-internet/&title=A Framework for Regulating Content on the Internet" class="ssk ssk-linkedin"></a>
    <a href="mailto:{email_address}?subject=A Framework for Regulating Content on the Internet&body=
  
     A Framework for Regulating Content on the Internet 
    
  Posted on             Tuesday, April 9, 2019 
            Friday, July 24, 2020 
     Author  by  Ben Thompson   
    
    
  
  
  
    This week, when the U.K.’s Secretary of State for Digital, Culture, Media and Sport and the Secretary of State for the Home Department released  a white paper  calling for significantly increased regulation for tech companies, the scope of the debate was predictable. The  MIT Technology Review  laid it out succinctly:
    
      Technology giants will be forced to have a “duty of care” for their users, if a proposal announced by the government on Monday becomes law. The proposal — a “white paper,” in UK legal parlance, which is one of the first stages of a formal government policy — is, on the surface at least, sweeping in scope and is a serious shot across the bows for big tech companies. But it has also raised some serious concerns about how it will be implemented and the possible consequences it might have on citizens’ free speech…
      The proposals have raised interest among academics and observers, and alarm among privacy campaigners. The former note that while the document is scant on details despite being tens of thousands of words long, it sets out a clear direction in a way few countries have been willing to do. But the latter fear that the way it is implemented could easily lead to censorship for users of social networks rather than curbing the excesses of the networks themselves.
    
    This proposal comes on the tail of an exposé in Bloomberg entitled  YouTube Executives Ignored Warnings, Letting Toxic Videos Run Rampant  ; the debate around that piece, which I wrote about last week in two Daily Updates (  here  and  here  ), not only touched on the question of free speech, but also the sheer scale of the problem — and, relatedly, the sheer scale of Facebook of Google.
     Problematic Regulation 
    In short, there are clear questions that arise around all of these exposés and proposals:
    
      First, what content should be regulated, if any, and by whom?
      Second, what is a viable way to monitor the content generated on these platforms?
      Third, how can privacy, competition, and free expression be preserved?
    
    You can see how these questions quickly arrive at competing answers when looking at recent attempts at regulation:
    
      GDPR has certainly increased the number of website click-throughs; it has also strengthened Facebook and  especially Google’s competitive position  exactly  as predicted  .
      The  European Copyright Directive  , specifically Article 13, makes platforms liable for copyright violations, and while the European Parliament took care to state that this wasn’t a requirement for a content filter, there is no other viable solution. Content filters are not only extremely difficult and expensive to develop (Google  has spent $100 million plus on ContentID  ), entrenching the largest players that have the resources to fund development and the leverage to pay for it, they will also necessarily be overly strict, limiting user expression.
      Even more egregious than the Copyright Directive, amazingly enough, is  Australia’s new law  about “abhorrent violent material” like the live-streaming of the horrific Christchurch mass shooting. Companies are liable if such content is discovered on their service 
     period
     — being told it exists is sufficient evidence of recklessness — and worse, every company in the stack is liable, from ISPs to cloud providers to social networks. That leaves no choice but to spy on all user traffic or, for small-and-medium-sized platforms outside of Australia, avoid the country altogether.
    
    At the same times, the Christchurch video and its spread are clearly problematic — there is something off about the current state of affairs.
     The Christchurch Video 
    It hardly bears noting that in a pre-Internet world there would be no widespread video of the Christchurch hate crime. Capturing video required specialized equipment, and more importantly, broadcasting video was limited to a small number of television stations, all of which, even if they had the video, would have exercised their editorial judgment to keep it off the air.
    What is critical to note, though, is that it is not a direct leap from “pre-Internet” to the Internet as we experience it today. The terrorist in Christchurch didn’t set up a server to livestream video from his phone; rather, he used Facebook’s built-in functionality. And, when it came to the video’s spread, the culprit was not email or message boards, but social media generally. To put it another way, to have spread that video on the Internet would be possible but difficult; to spread it on social media was trivial.
    The core issue is business models: to set up a live video streaming server is somewhat challenging, particularly if you are not technically inclined, and it costs money. More expensive still are the bandwidth costs of actually reaching a significant number of people. Large social media sites like Facebook or YouTube, though, are happy to bear those costs in service of a larger goal: building their advertising businesses.
    The key differentiator of  Super-Aggregators  is that they have three-sided markets: users, content providers (which may include users!), and advertisers. Both content providers and advertisers want the user’s attention, and the latter are willing to pay for it. This leads to a beautiful business model from the perspective of a Super-Aggregator:
    
      Content providers provide content for free, facilitated by the Super-Aggregator
      Users view that content, and provide their own content, facilitated by the Super-Aggregator
      Advertisers can reach the exact users they want by paying the Super-Aggregator
    
    Everything is aligned from the Super-Aggregator perspective: users give attention that content providers work to earn, and advertisers compete to buy their way in.
      
    Moreover, this arrangement allows Super-Aggregators to be relatively unconcerned with 
    what
    exactly flows across their network: advertisers simply want eyeballs, and the revenue from serving them pays for the infrastructure to not only accommodate users but also give content suppliers the tools to provide whatever sort of content those users may want.
    That, there, is the rub: given that these platforms are basically  reflections of humanity  , what users want varies from the beautiful to the profane — and things far more ugly than that. And worse, there is no editorial judgment to keep users from what they want, or suppliers from providing it. Indeed, that such sordid content can exist on YouTube and Facebook is testament to just how popular they are; that such content is effectively incentivized speaks to the fact that YouTube and Facebook’s moneymaking mechanism is completely divorced from this content match-making.
     Market Failure 
    This is, in its own way, a market failure, albeit not, to be clear, in an economic sense: the allocation of goods and services by a Super-Aggregator is not only efficient, but also generates significant consumer surpluses. The failure, rather, comes from videos like that of the Christchurch massacre, or problematic YouTube content. It is not good for society that terrorists be able to freely broadcast their videos, or that  child-exploitation videos spread on YouTube  .
    The problem is that there is no way to check this behavior: the vast majority of Facebook and YouTube users self-select away from this content, and while advertisers raise a fuss if they find out their ads are alongside this content, they have no incentive to leave the platforms entirely. That leaves Facebook and YouTube themselves, but while they would surely like to avoid PR black eyes, what they like even more is the limitless supply of attention and content that comes from making it easier for anyone anywhere to upload and view content of any type.
    Note how much different this is than a traditional customer-supplier relationship, even one mediated by a market-maker: users disgusted by Uber, for example, could switch to Lyft, directly impacting Uber’s bottom-line. Or go back a few years, when GoDaddy expressed support for SOPA copyright legislation: the company was  forced to change its position  in the face of widespread boycotts (including by yours truly). When users pay they have power; when users and those who pay are distinct, as is the case with these advertising-supported Super-Aggregators, the power of persuasion — that is, the power of the market — is absent.
     The Three Frees 
    There are, in Internet parlance, three types of “free”:
    
      “Free as in speech” means the freedom or right to do something
      “Free as in beer” means that you get something for free without any additional responsibility
      “Free as in puppy” means that you get something for free, but the longterm costs are substantial
    
    Most in the West agree, at least in theory, with the idea that the Internet should preserve “free as in speech”; China in particular represents a cautionary tale as to how technology can be leveraged in the opposite direction. The question that should be asked, though, is if preserving “free as in speech” should also mean preserving “free as in beer.”
    Specifically, Facebook and YouTube offer “free as in speech” in conjunction with “free as in beer”: content can be created and proliferated without any responsibility, including cost. Might it be better if content that society deemed problematic were still “free as in speech”, but also “free as in puppy” — that is, with costs to the supplier that aligned with the costs to society?
     A Regulatory Framework for the Internet 
    This distinction might square some of the circles I presented at the beginning: how might society regulate content without infringing on rights or destroying competitive threats to the largest incumbents?
    Start with this precept: the Internet ought to be available to anyone without any restriction. This means banning content blocking or throttling at the ISP level with regulation designed for the Internet. It also means that platform providers generally speaking should continue to not be liable for content posted on their services (platform providers include everything from AWS to Azure to shared hosts, and everything in-between); these platform providers can, though, choose to 
    not
    host content suppliers they do not want to, whether because of their own corporate values or because they fear boycott from other customers.
    I think, though, that platform providers that primarily monetize through advertising should be in their own category: as I noted above, because these platform providers separate monetization from content supply and consumption, there is no price or payment mechanism to incentivize them to be concerned with problematic content; in fact, the incentives of an advertising business drive them to focus on engagement, i.e. giving users what they want, no matter how noxious.
    This distinct categorization is critical to developing regulation that actually addresses problems without adverse side effects. Australia, for example, has no need to be concerned about shared hosting sites, but rather Facebook and YouTube; similarly, Europe wants to rein in tech giants without — and I will give the E.U. the benefit of the doubt here — burdening small online businesses with massive amounts of red tape. And, from a theoretical perspective, the appropriate place for regulation is where there is market failure; constraining the application to that failure is what is so difficult.
    The result is a regulatory framework that looks like this:
      
    “Free as in speech” is guaranteed at the infrastructure level, the market polices platform providers generally (i.e. “free as in puppy”), while regulation is narrowly limited to businesses that are primarily monetized through advertising (i.e. “free as in beer”) and thus impervious to traditional content marketplace pressures.
    
    This framework, to be clear, leaves many unanswered questions: what regulations, for example, are appropriate for companies like YouTube and Facebook? Are they even constitutional in the United States? Should we be concerned about the lack of competition in these regulated categories, or encouraged that there will now be a significant incentive to build competitive services that do not rely on advertising? What about VC-funded companies that have not yet specified their business models?
    Still, I think this framework provides a very important foundation for addressing many of the flaws in today’s regulatory proposals, particularly the unintended effects on small-and-medium sized businesses and the platforms that support them which, I believe, are critical for the economy of the future. Regulators and lawmakers should, as always, be wary that in the well-meaning attempt to shape the world as it is they foreclose the world that might be.
    
      
         Share 
        
          
              Facebook  
              Twitter  
              LinkedIn  
              Email  
            
          
        
      
    
    
       
     Related
     
    
  
  

" class="ssk ssk-email"></a>
    <a href="http://pinterest.com/pin/create/link/?url=https://stratechery.com/2019/a-regulatory-framework-for-the-internet/" class="ssk ssk-pinterest"></a>
    <a href="https://www.tumblr.com/widgets/share/tool?canonicalUrl=https://stratechery.com/2019/a-regulatory-framework-for-the-internet/&title=A Framework for Regulating Content on the Internet&caption=
  
     A Framework for Regulating Content on the Internet 
    
  Posted on             Tuesday, April 9, 2019 
            Friday, July 24, 2020 
     Author  by  Ben Thompson   
    
    
  
  
  
    This week, when the U.K.’s Secretary of State for Digital, Culture, Media and Sport and the Secretary of State for the Home Department released  a white paper  calling for significantly increased regulation for tech companies, the scope of the debate was predictable. The  MIT Technology Review  laid it out succinctly:
    
      Technology giants will be forced to have a “duty of care” for their users, if a proposal announced by the government on Monday becomes law. The proposal — a “white paper,” in UK legal parlance, which is one of the first stages of a formal government policy — is, on the surface at least, sweeping in scope and is a serious shot across the bows for big tech companies. But it has also raised some serious concerns about how it will be implemented and the possible consequences it might have on citizens’ free speech…
      The proposals have raised interest among academics and observers, and alarm among privacy campaigners. The former note that while the document is scant on details despite being tens of thousands of words long, it sets out a clear direction in a way few countries have been willing to do. But the latter fear that the way it is implemented could easily lead to censorship for users of social networks rather than curbing the excesses of the networks themselves.
    
    This proposal comes on the tail of an exposé in Bloomberg entitled  YouTube Executives Ignored Warnings, Letting Toxic Videos Run Rampant  ; the debate around that piece, which I wrote about last week in two Daily Updates (  here  and  here  ), not only touched on the question of free speech, but also the sheer scale of the problem — and, relatedly, the sheer scale of Facebook of Google.
     Problematic Regulation 
    In short, there are clear questions that arise around all of these exposés and proposals:
    
      First, what content should be regulated, if any, and by whom?
      Second, what is a viable way to monitor the content generated on these platforms?
      Third, how can privacy, competition, and free expression be preserved?
    
    You can see how these questions quickly arrive at competing answers when looking at recent attempts at regulation:
    
      GDPR has certainly increased the number of website click-throughs; it has also strengthened Facebook and  especially Google’s competitive position  exactly  as predicted  .
      The  European Copyright Directive  , specifically Article 13, makes platforms liable for copyright violations, and while the European Parliament took care to state that this wasn’t a requirement for a content filter, there is no other viable solution. Content filters are not only extremely difficult and expensive to develop (Google  has spent $100 million plus on ContentID  ), entrenching the largest players that have the resources to fund development and the leverage to pay for it, they will also necessarily be overly strict, limiting user expression.
      Even more egregious than the Copyright Directive, amazingly enough, is  Australia’s new law  about “abhorrent violent material” like the live-streaming of the horrific Christchurch mass shooting. Companies are liable if such content is discovered on their service 
     period
     — being told it exists is sufficient evidence of recklessness — and worse, every company in the stack is liable, from ISPs to cloud providers to social networks. That leaves no choice but to spy on all user traffic or, for small-and-medium-sized platforms outside of Australia, avoid the country altogether.
    
    At the same times, the Christchurch video and its spread are clearly problematic — there is something off about the current state of affairs.
     The Christchurch Video 
    It hardly bears noting that in a pre-Internet world there would be no widespread video of the Christchurch hate crime. Capturing video required specialized equipment, and more importantly, broadcasting video was limited to a small number of television stations, all of which, even if they had the video, would have exercised their editorial judgment to keep it off the air.
    What is critical to note, though, is that it is not a direct leap from “pre-Internet” to the Internet as we experience it today. The terrorist in Christchurch didn’t set up a server to livestream video from his phone; rather, he used Facebook’s built-in functionality. And, when it came to the video’s spread, the culprit was not email or message boards, but social media generally. To put it another way, to have spread that video on the Internet would be possible but difficult; to spread it on social media was trivial.
    The core issue is business models: to set up a live video streaming server is somewhat challenging, particularly if you are not technically inclined, and it costs money. More expensive still are the bandwidth costs of actually reaching a significant number of people. Large social media sites like Facebook or YouTube, though, are happy to bear those costs in service of a larger goal: building their advertising businesses.
    The key differentiator of  Super-Aggregators  is that they have three-sided markets: users, content providers (which may include users!), and advertisers. Both content providers and advertisers want the user’s attention, and the latter are willing to pay for it. This leads to a beautiful business model from the perspective of a Super-Aggregator:
    
      Content providers provide content for free, facilitated by the Super-Aggregator
      Users view that content, and provide their own content, facilitated by the Super-Aggregator
      Advertisers can reach the exact users they want by paying the Super-Aggregator
    
    Everything is aligned from the Super-Aggregator perspective: users give attention that content providers work to earn, and advertisers compete to buy their way in.
      
    Moreover, this arrangement allows Super-Aggregators to be relatively unconcerned with 
    what
    exactly flows across their network: advertisers simply want eyeballs, and the revenue from serving them pays for the infrastructure to not only accommodate users but also give content suppliers the tools to provide whatever sort of content those users may want.
    That, there, is the rub: given that these platforms are basically  reflections of humanity  , what users want varies from the beautiful to the profane — and things far more ugly than that. And worse, there is no editorial judgment to keep users from what they want, or suppliers from providing it. Indeed, that such sordid content can exist on YouTube and Facebook is testament to just how popular they are; that such content is effectively incentivized speaks to the fact that YouTube and Facebook’s moneymaking mechanism is completely divorced from this content match-making.
     Market Failure 
    This is, in its own way, a market failure, albeit not, to be clear, in an economic sense: the allocation of goods and services by a Super-Aggregator is not only efficient, but also generates significant consumer surpluses. The failure, rather, comes from videos like that of the Christchurch massacre, or problematic YouTube content. It is not good for society that terrorists be able to freely broadcast their videos, or that  child-exploitation videos spread on YouTube  .
    The problem is that there is no way to check this behavior: the vast majority of Facebook and YouTube users self-select away from this content, and while advertisers raise a fuss if they find out their ads are alongside this content, they have no incentive to leave the platforms entirely. That leaves Facebook and YouTube themselves, but while they would surely like to avoid PR black eyes, what they like even more is the limitless supply of attention and content that comes from making it easier for anyone anywhere to upload and view content of any type.
    Note how much different this is than a traditional customer-supplier relationship, even one mediated by a market-maker: users disgusted by Uber, for example, could switch to Lyft, directly impacting Uber’s bottom-line. Or go back a few years, when GoDaddy expressed support for SOPA copyright legislation: the company was  forced to change its position  in the face of widespread boycotts (including by yours truly). When users pay they have power; when users and those who pay are distinct, as is the case with these advertising-supported Super-Aggregators, the power of persuasion — that is, the power of the market — is absent.
     The Three Frees 
    There are, in Internet parlance, three types of “free”:
    
      “Free as in speech” means the freedom or right to do something
      “Free as in beer” means that you get something for free without any additional responsibility
      “Free as in puppy” means that you get something for free, but the longterm costs are substantial
    
    Most in the West agree, at least in theory, with the idea that the Internet should preserve “free as in speech”; China in particular represents a cautionary tale as to how technology can be leveraged in the opposite direction. The question that should be asked, though, is if preserving “free as in speech” should also mean preserving “free as in beer.”
    Specifically, Facebook and YouTube offer “free as in speech” in conjunction with “free as in beer”: content can be created and proliferated without any responsibility, including cost. Might it be better if content that society deemed problematic were still “free as in speech”, but also “free as in puppy” — that is, with costs to the supplier that aligned with the costs to society?
     A Regulatory Framework for the Internet 
    This distinction might square some of the circles I presented at the beginning: how might society regulate content without infringing on rights or destroying competitive threats to the largest incumbents?
    Start with this precept: the Internet ought to be available to anyone without any restriction. This means banning content blocking or throttling at the ISP level with regulation designed for the Internet. It also means that platform providers generally speaking should continue to not be liable for content posted on their services (platform providers include everything from AWS to Azure to shared hosts, and everything in-between); these platform providers can, though, choose to 
    not
    host content suppliers they do not want to, whether because of their own corporate values or because they fear boycott from other customers.
    I think, though, that platform providers that primarily monetize through advertising should be in their own category: as I noted above, because these platform providers separate monetization from content supply and consumption, there is no price or payment mechanism to incentivize them to be concerned with problematic content; in fact, the incentives of an advertising business drive them to focus on engagement, i.e. giving users what they want, no matter how noxious.
    This distinct categorization is critical to developing regulation that actually addresses problems without adverse side effects. Australia, for example, has no need to be concerned about shared hosting sites, but rather Facebook and YouTube; similarly, Europe wants to rein in tech giants without — and I will give the E.U. the benefit of the doubt here — burdening small online businesses with massive amounts of red tape. And, from a theoretical perspective, the appropriate place for regulation is where there is market failure; constraining the application to that failure is what is so difficult.
    The result is a regulatory framework that looks like this:
      
    “Free as in speech” is guaranteed at the infrastructure level, the market polices platform providers generally (i.e. “free as in puppy”), while regulation is narrowly limited to businesses that are primarily monetized through advertising (i.e. “free as in beer”) and thus impervious to traditional content marketplace pressures.
    
    This framework, to be clear, leaves many unanswered questions: what regulations, for example, are appropriate for companies like YouTube and Facebook? Are they even constitutional in the United States? Should we be concerned about the lack of competition in these regulated categories, or encouraged that there will now be a significant incentive to build competitive services that do not rely on advertising? What about VC-funded companies that have not yet specified their business models?
    Still, I think this framework provides a very important foundation for addressing many of the flaws in today’s regulatory proposals, particularly the unintended effects on small-and-medium sized businesses and the platforms that support them which, I believe, are critical for the economy of the future. Regulators and lawmakers should, as always, be wary that in the well-meaning attempt to shape the world as it is they foreclose the world that might be.
    
      
         Share 
        
          
              Facebook  
              Twitter  
              LinkedIn  
              Email  
            
          
        
      
    
    
       
     Related
     
    
  
  

&tags=觀點" class="ssk ssk-tumblr"></a>
    <a href="https://buffer.com/add?text=A Framework for Regulating Content on the Internet&url=https://stratechery.com/2019/a-regulatory-framework-for-the-internet/" class="ssk ssk-buffer"></a>
</div>


    <div id="main" role="main" class="container">
      
  <!-- Html Elements for Search -->
  <ul id="results-container" class="searched" style="color: #2980B9;"></ul>

  <script src="/opinion/assets/js/simple-jekyll-search.min.js"></script>

  <!-- Configuration -->
  <script>
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    json: '/opinion/search.json',
    searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a><time>{date}</time><a class="tag">{category}</a></li>',
    noResultsText: '没找到',
    limit: 100,
    fuzzy: false,
    exclude: ['Welcome']
  })

  </script>

      







  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    


  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    



<article class="post">
  <h1>A Framework for Regulating Content on the Internet</h1>
  <!-- Look the author details up from the site config. -->
  

  <div>
    <span class="date">
      2019-04-09
    </span>

    <!-- Output author details if some exist. -->
    
      
        <span>
            <!-- Personal Info. -->
            <a  style="font-size:14px;">作者: Ben Thompson</a>
        </span>
      
    


    <ul class="tag">
      <li>
        <a href="https://nodebe4.github.io/opinion/categories/#Stratechery">
          Stratechery
        </a>
      </li>
    </ul>

    
        <span>
            <!-- Personal Info. -->
            <a href="https://stratechery.com/2019/a-regulatory-framework-for-the-internet/" style="font-size:14px;">原文</a>
        </span>
    

    <span style="float: right;" title="Stratechery的其它文章">
      <a style="font-size: 14px;" rel="nofollow" href="#sametag" class="tags">#Stratechery 的其它文章</a>
    </span>

  </div>

  <div class="entry">
    
    
    
    <article class="post-4127 post type-post status-publish format-standard has-post-thumbnail hentry category-articles topics-content-moderation topics-copyrights topics-gdpr topics-law topics-regulation topics-social concepts-advertising concepts-aggregation-theory concepts-business-models concepts-distribution-and-transaction-costs concepts-ethics-and-mores concepts-free concepts-owning-customer-relationship concepts-platforms concepts-technology-and-society companies-facebook companies-google companies-youtube" id="post-4127">
  <header class="entry-header">
    <h1 class="entry-title" id="a-framework-for-regulating-content-on-the-internet-"> A Framework for Regulating Content on the Internet </h1>
    <div class="entry-meta">
<span class="posted-on"> <span class="screen-reader-text"> Posted on </span>           <time class="entry-date published" datetime="2019-04-09T06:48:55-07:00"> Tuesday, April 9, 2019 </time>
           <time class="updated" datetime="2020-07-24T18:37:20-07:00"> Friday, July 24, 2020 </time>
 </span> <span class="byline"> <span class="author vcard"> <span class="screen-reader-text"> Author </span> by <a class="url fn n" href="https://stratechery.com/author/stratechery/"> Ben Thompson </a> </span> </span>
    </div>
    <!-- .entry-meta -->
  </header>
  <!-- .entry-header -->
  <div class="entry-content">
    <p>This week, when the U.K.’s Secretary of State for Digital, Culture, Media and Sport and the Secretary of State for the Home Department released <a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/793360/Online_Harms_White_Paper.pdf"> a white paper </a> calling for significantly increased regulation for tech companies, the scope of the debate was predictable. The <a href="https://www.technologyreview.com/s/613285/the-uks-online-laws-could-be-the-future-of-the-internetand-thats-got-people-worried/"> MIT Technology Review </a> laid it out succinctly:</p>
    <blockquote>
      <p>Technology giants will be forced to have a “duty of care” for their users, if a proposal announced by the government on Monday becomes law. The proposal — a “white paper,” in UK legal parlance, which is one of the first stages of a formal government policy — is, on the surface at least, sweeping in scope and is a serious shot across the bows for big tech companies. But it has also raised some serious concerns about how it will be implemented and the possible consequences it might have on citizens’ free speech…</p>
      <p>The proposals have raised interest among academics and observers, and alarm among privacy campaigners. The former note that while the document is scant on details despite being tens of thousands of words long, it sets out a clear direction in a way few countries have been willing to do. But the latter fear that the way it is implemented could easily lead to censorship for users of social networks rather than curbing the excesses of the networks themselves.</p>
    </blockquote>
    <p>This proposal comes on the tail of an exposé in Bloomberg entitled <a href="https://www.bloomberg.com/news/features/2019-04-02/youtube-executives-ignored-warnings-letting-toxic-videos-run-rampant"> YouTube Executives Ignored Warnings, Letting Toxic Videos Run Rampant </a> ; the debate around that piece, which I wrote about last week in two Daily Updates ( <a href="https://stratechery.com/2019/youtube-and-toxic-videos-youtubes-problematic-incentives-sins-of-omission-and-commission/"> here </a> and <a href="https://stratechery.com/2019/the-wall-street-journal-and-apple-news-the-problem-with-regulating-content-australias-terrible-new-law/"> here </a> ), not only touched on the question of free speech, but also the sheer scale of the problem — and, relatedly, the sheer scale of Facebook of Google.</p>
    <h4 id="problematic-regulation-"> Problematic Regulation </h4>
    <p>In short, there are clear questions that arise around all of these exposés and proposals:</p>
    <ul>
      <li>First, what content should be regulated, if any, and by whom?</li>
      <li>Second, what is a viable way to monitor the content generated on these platforms?</li>
      <li>Third, how can privacy, competition, and free expression be preserved?</li>
    </ul>
    <p>You can see how these questions quickly arrive at competing answers when looking at recent attempts at regulation:</p>
    <ul>
      <li>GDPR has certainly increased the number of website click-throughs; it has also strengthened Facebook and <a href="https://stratechery.com/2019/mark-zuckerbergs-proposal-the-copyright-directive-and-sunk-costs-you-say-you-want-some-regulation/"> especially Google’s competitive position </a> exactly <a href="https://stratechery.com/2017/the-gdpr-and-facebook-and-google-intelligent-tracking-prevention-data-portability-and-social-graphs/"> as predicted </a> .</li>
      <li>The <a href="https://stratechery.com/2018/the-european-union-versus-the-internet/"> European Copyright Directive </a> , specifically Article 13, makes platforms liable for copyright violations, and while the European Parliament took care to state that this wasn’t a requirement for a content filter, there is no other viable solution. Content filters are not only extremely difficult and expensive to develop (Google <a href="https://www.blog.google/outreach-initiatives/public-policy/protecting-what-we-love-about-internet-our-efforts-stop-online-piracy/"> has spent $100 million plus on ContentID </a> ), entrenching the largest players that have the resources to fund development and the leverage to pay for it, they will also necessarily be overly strict, limiting user expression.</li>
      <li>Even more egregious than the Copyright Directive, amazingly enough, is <a href="https://stratechery.com/2019/the-wall-street-journal-and-apple-news-the-problem-with-regulating-content-australias-terrible-new-law/"> Australia’s new law </a> about “abhorrent violent material” like the live-streaming of the horrific Christchurch mass shooting. Companies are liable if such content is discovered on their service <em>
     period
    </em> — being told it exists is sufficient evidence of recklessness — and worse, every company in the stack is liable, from ISPs to cloud providers to social networks. That leaves no choice but to spy on all user traffic or, for small-and-medium-sized platforms outside of Australia, avoid the country altogether.</li>
    </ul>
    <p>At the same times, the Christchurch video and its spread are clearly problematic — there is something off about the current state of affairs.</p>
    <h4 id="the-christchurch-video-"> The Christchurch Video </h4>
    <p>It hardly bears noting that in a pre-Internet world there would be no widespread video of the Christchurch hate crime. Capturing video required specialized equipment, and more importantly, broadcasting video was limited to a small number of television stations, all of which, even if they had the video, would have exercised their editorial judgment to keep it off the air.</p>
    <p>What is critical to note, though, is that it is not a direct leap from “pre-Internet” to the Internet as we experience it today. The terrorist in Christchurch didn’t set up a server to livestream video from his phone; rather, he used Facebook’s built-in functionality. And, when it came to the video’s spread, the culprit was not email or message boards, but social media generally. To put it another way, to have spread that video on the Internet would be possible but difficult; to spread it on social media was trivial.</p>
    <p>The core issue is business models: to set up a live video streaming server is somewhat challenging, particularly if you are not technically inclined, and it costs money. More expensive still are the bandwidth costs of actually reaching a significant number of people. Large social media sites like Facebook or YouTube, though, are happy to bear those costs in service of a larger goal: building their advertising businesses.</p>
    <p>The key differentiator of <a href="https://stratechery.com/2017/the-super-aggregators-and-the-russians/"> Super-Aggregators </a> is that they have three-sided markets: users, content providers (which may include users!), and advertisers. Both content providers and advertisers want the user’s attention, and the latter are willing to pay for it. This leads to a beautiful business model from the perspective of a Super-Aggregator:</p>
    <ul>
      <li>Content providers provide content for free, facilitated by the Super-Aggregator</li>
      <li>Users view that content, and provide their own content, facilitated by the Super-Aggregator</li>
      <li>Advertisers can reach the exact users they want by paying the Super-Aggregator</li>
    </ul>
    <p>Everything is aligned from the Super-Aggregator perspective: users give attention that content providers work to earn, and advertisers compete to buy their way in.</p>
    <p><a href="https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.309.png"> <img alt="The three-way market of a Super-Aggregator" class="aligncenter size-large wp-image-4129" height="271" sizes="(max-width: 640px) 100vw, 640px" src="https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.309-1024x434.png" srcset="https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.309-1024x434.png 1024w, https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.309-300x127.png 300w, https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.309-768x325.png 768w, https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.309-1200x509.png 1200w" width="640" /> </a></p>
    <p>Moreover, this arrangement allows Super-Aggregators to be relatively unconcerned with <em>
    what
   </em> exactly flows across their network: advertisers simply want eyeballs, and the revenue from serving them pays for the infrastructure to not only accommodate users but also give content suppliers the tools to provide whatever sort of content those users may want.</p>
    <p>That, there, is the rub: given that these platforms are basically <a href="https://stratechery.com/2019/the-alexandria-ocasio-cortez-phenomenon-ninjas-2018-facebook-and-the-human-condition/"> reflections of humanity </a> , what users want varies from the beautiful to the profane — and things far more ugly than that. And worse, there is no editorial judgment to keep users from what they want, or suppliers from providing it. Indeed, that such sordid content can exist on YouTube and Facebook is testament to just how popular they are; that such content is effectively incentivized speaks to the fact that YouTube and Facebook’s moneymaking mechanism is completely divorced from this content match-making.</p>
    <h4 id="market-failure-"> Market Failure </h4>
    <p>This is, in its own way, a market failure, albeit not, to be clear, in an economic sense: the allocation of goods and services by a Super-Aggregator is not only efficient, but also generates significant consumer surpluses. The failure, rather, comes from videos like that of the Christchurch massacre, or problematic YouTube content. It is not good for society that terrorists be able to freely broadcast their videos, or that <a href="https://www.buzzfeednews.com/article/charliewarzel/youtube-will-add-more-human-moderators-to-stop-its-child#.xtm3KJv1GP"> child-exploitation videos spread on YouTube </a> .</p>
    <p>The problem is that there is no way to check this behavior: the vast majority of Facebook and YouTube users self-select away from this content, and while advertisers raise a fuss if they find out their ads are alongside this content, they have no incentive to leave the platforms entirely. That leaves Facebook and YouTube themselves, but while they would surely like to avoid PR black eyes, what they like even more is the limitless supply of attention and content that comes from making it easier for anyone anywhere to upload and view content of any type.</p>
    <p>Note how much different this is than a traditional customer-supplier relationship, even one mediated by a market-maker: users disgusted by Uber, for example, could switch to Lyft, directly impacting Uber’s bottom-line. Or go back a few years, when GoDaddy expressed support for SOPA copyright legislation: the company was <a href="https://www.theverge.com/2011/12/23/2657930/godaddy-withdraws-sopa-support-in-face-of-massive-protests"> forced to change its position </a> in the face of widespread boycotts (including by yours truly). When users pay they have power; when users and those who pay are distinct, as is the case with these advertising-supported Super-Aggregators, the power of persuasion — that is, the power of the market — is absent.</p>
    <h4 id="the-three-frees-"> The Three Frees </h4>
    <p>There are, in Internet parlance, three types of “free”:</p>
    <ul>
      <li>“Free as in speech” means the freedom or right to do something</li>
      <li>“Free as in beer” means that you get something for free without any additional responsibility</li>
      <li>“Free as in puppy” means that you get something for free, but the longterm costs are substantial</li>
    </ul>
    <p>Most in the West agree, at least in theory, with the idea that the Internet should preserve “free as in speech”; China in particular represents a cautionary tale as to how technology can be leveraged in the opposite direction. The question that should be asked, though, is if preserving “free as in speech” should also mean preserving “free as in beer.”</p>
    <p>Specifically, Facebook and YouTube offer “free as in speech” in conjunction with “free as in beer”: content can be created and proliferated without any responsibility, including cost. Might it be better if content that society deemed problematic were still “free as in speech”, but also “free as in puppy” — that is, with costs to the supplier that aligned with the costs to society?</p>
    <h4 id="a-regulatory-framework-for-the-internet-"> A Regulatory Framework for the Internet </h4>
    <p>This distinction might square some of the circles I presented at the beginning: how might society regulate content without infringing on rights or destroying competitive threats to the largest incumbents?</p>
    <p>Start with this precept: the Internet ought to be available to anyone without any restriction. This means banning content blocking or throttling at the ISP level with regulation designed for the Internet. It also means that platform providers generally speaking should continue to not be liable for content posted on their services (platform providers include everything from AWS to Azure to shared hosts, and everything in-between); these platform providers can, though, choose to <em>
    not
   </em> host content suppliers they do not want to, whether because of their own corporate values or because they fear boycott from other customers.</p>
    <p>I think, though, that platform providers that primarily monetize through advertising should be in their own category: as I noted above, because these platform providers separate monetization from content supply and consumption, there is no price or payment mechanism to incentivize them to be concerned with problematic content; in fact, the incentives of an advertising business drive them to focus on engagement, i.e. giving users what they want, no matter how noxious.</p>
    <p>This distinct categorization is critical to developing regulation that actually addresses problems without adverse side effects. Australia, for example, has no need to be concerned about shared hosting sites, but rather Facebook and YouTube; similarly, Europe wants to rein in tech giants without — and I will give the E.U. the benefit of the doubt here — burdening small online businesses with massive amounts of red tape. And, from a theoretical perspective, the appropriate place for regulation is where there is market failure; constraining the application to that failure is what is so difficult.</p>
    <p>The result is a regulatory framework that looks like this:</p>
    <p><a href="https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.310.png"> <img alt="The regulatory framework for the Internet" class="aligncenter size-large wp-image-4128" height="312" sizes="(max-width: 640px) 100vw, 640px" src="https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.310-1024x499.png" srcset="https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.310-1024x499.png 1024w, https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.310-300x146.png 300w, https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.310-768x374.png 768w, https://stratechery.com/wp-content/uploads/2019/04/Paper.stratechery-Year-One-copy.310-1200x585.png 1200w" width="640" /> </a></p>
    <p>“Free as in speech” is guaranteed at the infrastructure level, the market polices platform providers generally (i.e. “free as in puppy”), while regulation is narrowly limited to businesses that are primarily monetized through advertising (i.e. “free as in beer”) and thus impervious to traditional content marketplace pressures.</p>
    <hr />
    <p>This framework, to be clear, leaves many unanswered questions: what regulations, for example, are appropriate for companies like YouTube and Facebook? Are they even constitutional in the United States? Should we be concerned about the lack of competition in these regulated categories, or encouraged that there will now be a significant incentive to build competitive services that do not rely on advertising? What about VC-funded companies that have not yet specified their business models?</p>
    <p>Still, I think this framework provides a very important foundation for addressing many of the flaws in today’s regulatory proposals, particularly the unintended effects on small-and-medium sized businesses and the platforms that support them which, I believe, are critical for the economy of the future. Regulators and lawmakers should, as always, be wary that in the well-meaning attempt to shape the world as it is they foreclose the world that might be.</p>
    <div class="sharedaddy sd-sharing-enabled">
      <div class="robots-nocontent sd-block sd-social sd-social-icon-text sd-sharing">
        <h3 class="sd-title" id="share-"> Share </h3>
        <div class="sd-content">
          <ul>
            <li class="share-facebook"><a class="share-facebook sd-button share-icon" data-shared="sharing-facebook-4127" href="https://stratechery.com/2019/a-regulatory-framework-for-the-internet/?share=facebook" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Facebook"> <span> Facebook </span> </a></li>
            <li class="share-twitter"><a class="share-twitter sd-button share-icon" data-shared="sharing-twitter-4127" href="https://stratechery.com/2019/a-regulatory-framework-for-the-internet/?share=twitter" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Twitter"> <span> Twitter </span> </a></li>
            <li class="share-linkedin"><a class="share-linkedin sd-button share-icon" data-shared="sharing-linkedin-4127" href="https://stratechery.com/2019/a-regulatory-framework-for-the-internet/?share=linkedin" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on LinkedIn"> <span> LinkedIn </span> </a></li>
            <li class="share-email"><a class="share-email sd-button share-icon" data-shared="" href="https://stratechery.com/2019/a-regulatory-framework-for-the-internet/?share=email" rel="nofollow noopener noreferrer" target="_blank" title="Click to email this to a friend"> <span> Email </span> </a></li>
            <li class="share-end"></li>
          </ul>
        </div>
      </div>
    </div>
    <div class="jp-relatedposts" id="jp-relatedposts">
      <h3 class="jp-relatedposts-headline" id="related"> <em>
     Related
    </em> </h3>
    </div>
  </div>
  <!-- .entry-content -->
</article>


  </div>

  <hr style="border-top:1px solid #28323C;"/>

<font size=2px>
  文章版权归原作者所有。
</font>

<div style="text-align:center"><img width="1px" src="https://i.imgur.com/HSw56Ez.png" alt="二维码分享本站" style="text-align:center"/></div>

  <div id="sametag">
    <h4 style="display: inline-block;">#Stratechery 的其它文章</h4>
    <span>--<a href="https://nodebe4.github.io/opinion/2025-02-27/An-Interview-with-Benedict-Evans-About-AI-Unknowns/">最新</a>-</span>
    <span>-<a href="https://nodebe4.github.io/opinion/2009-12-09/Dropbox_and_the_Entrepreneurs_Blindspot/">最早</a>--</span>
    
      <li>
        <time>2019-04-22</time>
        <a href="https://nodebe4.github.io/opinion/2019-04-22/Uber_Questions/">
          Uber Questions
        </a>
      </li>
    
    
      <li>
        <time>2019-04-15</time>
        <a href="https://nodebe4.github.io/opinion/2019-04-15/Disney_and_the_Future_of_TV/">
          Disney and the Future of TV
        </a>
      </li>
    
    
      <li>
        <time>2019-03-26</time>
        <a href="https://nodebe4.github.io/opinion/2019-03-26/Apples_Services_Event/">
          Apple’s Services Event
        </a>
      </li>
    
    
      <li>
        <time>2019-03-12</time>
        <a href="https://nodebe4.github.io/opinion/2019-03-12/Where_Warrens_Wrong/">
          Where Warren’s Wrong
        </a>
      </li>
    
  </div>


  <hr>
  <div class="pagination">
    
      <span class="prev" >
          <a href="https://nodebe4.github.io/opinion/2019-04-09/%E7%9B%9B%E6%B4%AA-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9A%8F%E6%9C%BA%E9%80%89%E6%8B%A9%E6%AF%94-%E7%90%86%E6%80%A7%E9%80%89%E6%8B%A9-%E6%9B%B4%E6%9C%89%E6%95%88/">
            前一篇：盛洪：为什么随机选择比“理性选择”更有效？
          </a>
      </span>
    
    
      <span class="next" >
          <a href="https://nodebe4.github.io/opinion/2019-04-10/%E7%BE%8E%E5%9B%BD%E9%98%B2%E9%83%A8%E5%85%AC%E5%B8%83%E5%AF%B9%E5%8F%B0%E5%86%9B%E5%94%AE%E5%90%88%E7%BA%A6-%E4%B8%BA%E5%8F%B0%E6%B9%BE%E5%86%9B%E8%88%B0%E7%BF%BB%E4%BF%AE%E5%8D%87%E7%BA%A7%E9%9B%B7%E8%BE%BE/">
            後一篇：美国防部公布对台军售合约 为台湾军舰翻修升级雷达
          </a>
      </span>
    

    <script>
    /* post pagination keyboard shortcuts */
    document.body.onkeyup = function(e){
      if (e.keyCode == '37') { window.location = 'https://nodebe4.github.io/opinion/2019-04-09/%E7%9B%9B%E6%B4%AA-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9A%8F%E6%9C%BA%E9%80%89%E6%8B%A9%E6%AF%94-%E7%90%86%E6%80%A7%E9%80%89%E6%8B%A9-%E6%9B%B4%E6%9C%89%E6%95%88/'; } // left arrow key
      if (e.keyCode == '39') { window.location = 'https://nodebe4.github.io/opinion/2019-04-10/%E7%BE%8E%E5%9B%BD%E9%98%B2%E9%83%A8%E5%85%AC%E5%B8%83%E5%AF%B9%E5%8F%B0%E5%86%9B%E5%94%AE%E5%90%88%E7%BA%A6-%E4%B8%BA%E5%8F%B0%E6%B9%BE%E5%86%9B%E8%88%B0%E7%BF%BB%E4%BF%AE%E5%8D%87%E7%BA%A7%E9%9B%B7%E8%BE%BE/'; } // right arrow key
      if (e.keyCode == '45') { window.location = 'https://nodebe4.github.io/opinion/2019-04-15/Disney_and_the_Future_of_TV/'; } // insert key
      if (e.keyCode == '46') { window.location = 'https://nodebe4.github.io/opinion/2019-03-26/Apples_Services_Event/'; } // delete key
    };
    </script>
    <link rel="stylesheet" type="text/css" href="/opinion/assets/css/fab.css" />

<div class="fab-wrapper">
  <div class="fab-wheel">
    
    
    
    <a class="fab-action fab-action-1" title="上一篇(热键 &#8594;)" href="https://nodebe4.github.io/opinion/2019-04-09/%E7%9B%9B%E6%B4%AA-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9A%8F%E6%9C%BA%E9%80%89%E6%8B%A9%E6%AF%94-%E7%90%86%E6%80%A7%E9%80%89%E6%8B%A9-%E6%9B%B4%E6%9C%89%E6%95%88/">
      <i>后</i>
    </a>
    
    
    <a class="fab-action fab-action-2" title="下一篇(热键 &#8592;)" href="https://nodebe4.github.io/opinion/2019-04-10/%E7%BE%8E%E5%9B%BD%E9%98%B2%E9%83%A8%E5%85%AC%E5%B8%83%E5%AF%B9%E5%8F%B0%E5%86%9B%E5%94%AE%E5%90%88%E7%BA%A6-%E4%B8%BA%E5%8F%B0%E6%B9%BE%E5%86%9B%E8%88%B0%E7%BF%BB%E4%BF%AE%E5%8D%87%E7%BA%A7%E9%9B%B7%E8%BE%BE/">
      <i>前</i>
    </a>
    
    
    <a class="fab-action fab-action-3" title="<Stratechery>上一篇(热键 ins)" href="https://nodebe4.github.io/opinion/2019-04-15/Disney_and_the_Future_of_TV/">
      <i>左</i>
    </a>
    
    
    <a class="fab-action fab-action-4" title="<Stratechery>下一篇(热键 del)" href="https://nodebe4.github.io/opinion/2019-03-26/Apples_Services_Event/">
      <i>右</i>
    </a>
    
  </div>
</div>


  </div>


  

</article>

    </div>

    <div style="z-index:2;">
<script src="/opinion/assets/js/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
  diameter: 56,
  cornerOffset: 20, // px
  id: 'back-to-top',
  backgroundColor: '#ddd',
  textColor: 'red'
})</script>
</div>


    <div class="wrapper-footer" id="footer">
      <div class="container">
        <footer class="footer">
          <img width="200px" src="https://i.imgur.com/HSw56Ez.png" alt="二维码分享本站"/>
<font size=2px>二维码分享本站</font>

<!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

  

  

  
  <li><a href="mailto:beauti4@protonmail.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
  

  

  

  
  <li><a href="https://github.com/NodeBE4/opinion" class="icon-13 github" title="GitHub"><svg viewBox="0 0 512 512"><path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z"/></svg><!--[if lt IE 9]><em>GitHub</em><![endif]--></a></li>
  

  

  

  

  

  
  <li><a href="/opinion/feed.xml" class="icon-21 rss" title="RSS"><svg viewBox="0 0 512 512"><path d="M201.8 347.2c0 20.3-16.5 36.8-36.8 36.8 -20.3 0-36.8-16.5-36.8-36.8s16.5-36.8 36.8-36.8C185.3 310.4 201.8 326.8 201.8 347.2zM128.2 204.7v54.5c68.5 0.7 124 56.3 124.7 124.7h54.5C306.7 285.3 226.9 205.4 128.2 204.7zM128.2 166.6c57.9 0.3 112.3 22.9 153.2 63.9 41 41 63.7 95.5 63.9 153.5h54.5c-0.3-149.9-121.7-271.4-271.6-271.9V166.6L128.2 166.6z"/></svg><!--[if lt IE 9]><em>RSS</em><![endif]--></a></li>
  

  

  

  

  

    
</ul>





<p><span style="color:blue">内容每小时更新一次.</span> Powered by <a href="https://github.com/AWEEKJ/kiko-now">Kiko Now</a> & <a href="https://github.com/gitalk/gitalk">Gitalk</a> & <a href="https://github.com/duty-machine/news">duty-machine</a>, 站务 <a href="https://be4.herokuapp.com">NodeBE4</a>（<span style="color:red">被墙</span>）</p>





        </footer>
      </div>
    </div>

    



  </body>
</html>
