<!DOCTYPE html>
<html>
  <head>
  <title>盛洪：生产能力和道德能力 – 觀點 – 從草根到大師 git.io/JJCxS</title>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="
  
      
    
  
    
    
    本文作者盛洪  
     
    谢谢蒋豪。我肯定没有像光沪讲的那么深，但是受启发还是有一些想法的。我觉得人类发展是两个方面，一方面是生产能力  ,  一方面是道德能力。近代的很多理论学说只看到一个维度，比如马克思的历史唯物主义，就看一个维度，这个维度就是生产能力，生产能力不断前进。当然还有其他学派也有这样的思想，什么是好，就是生产能力更强。其实它们没有看到另外一个能力是道德能力。我觉得道德能力应包括两种形式，一种是适用于大众的，就是由大众互动形成的某种习俗、习惯、惯例、传统。这实际上有一个前提，这个前提就是说，互动的人们在生产能力上比较相似，他们不断的交往  ,  交往以后就形成了哈耶克所说的自发秩序。大家发现我们遵守这个秩序能保持一种均衡，不会产生一种不平衡或社会的冲突、动荡和断裂。另外一种就是精英层的道德能力，就比较高了，宗教人士、士大夫还有一些文化精英，他们的能力不仅是对习俗的遵从，而且是对习俗的思考、总结、提炼形成一些更为凝练的道德价值的描述，最后形成我称之为的“文明经典”。这个文明经典又成为一个传统，不断的扩散和传播下去。围绕文明经典就形成了一个文化精英阶层，这个阶层在社会中起到某种骨干作用。  
     
    在一个技术相对稳定的时代，由它决定的这样一个道德形式，尤其是民间形成那种习俗习惯传统  ,  也相对稳定。大家的道德能力首先是受到了基本不变的那种生产能力或技术水平的稳定性的保证，因为由于生产能力都是差不多的，所以大家谁也没有更多的优势，在这种生产能力之下形成这种习俗习惯是相对稳定的。大家借助于对习俗、习惯和传统的遵从，保证他们的道德能力与他们的生产能力相匹配。如果出现了一种技术创新或革命，而这种技术革命还有一个特点，就是一部分人优先掌握，他们在生产能力上产生某种优势，这个时候严格来讲，过去人和人之间遵从的道德规范或者说习俗、习惯和传统，就崩塌了，因为原来的习俗习惯在人的生产能力都差不多的情况下，你打不过我、我也打不过你，我想抢你也没你劲大，现在不是了，现在我想抢你很容易，我拿把枪就把你抢了，因为你没有枪。传统的自发形成的伦理规则就崩塌掉了，这是任何发生技术变革时代应该特别关注和警惕的，因为大家总是一味的看到了新技术或者更高的生产能力，给掌握这种新技术和生产能力的人带来的好处，没有看到这些人利用这种优势，相对于没有这种优势的人之间，又会出现对原来那种道德均衡的破坏，甚至对没有优势人的一种侵夺，这种情况其实经常发生。  
     
    我觉得在近代社会是非常明显的。近代以来，比如说西方人先有了更高的生产能力，很快就会把这种生产能力运用到怎么能使自己获得更多的利益方面，这必然打破过去那种道德均衡，其实它就崩塌了。所以近代以来那种东西方的冲突就在这儿。这种情形到了现代仍然有演进，比如说这样一种生产能力带来的现代武器，会导致其它一些国家的冲突。我看到非洲经常有动乱，一个人拿着枪的第一个想法，不是要保持人们之间和平的均衡，而要拿这个枪消灭那些过去一直跟我抗衡的人群，所以在近代也能看出，非洲会出现很多血腥的事情，这只不过是近代以来所有事情的重演，西方殖民者对于非西方人的类似情形的重演。  
     
    在现代人工智能的框架下也会出现这种情形。假如这种新技术不是为所有人所掌握，只是为一小部分人所掌握，这小部分人一定会利用这种优势打破原来的均衡，比如我能猜透你，我为什么不用这个优势来从你身上攫取更多的利益呢。这可能也包括两部分，一部分是在不同民族和不同国家之间，假如谁更有优势，谁就占更大便宜。当然这个说法其实是很古老的。大家都知道，技术的竞争很快会用到国家层次，包括欧洲也是一样的。很多人说科学无国界，那都是胡说。科学一上来就跟国家层次是相关的。不要把科学家打扮得那么纯真，不是那样的。很多科学，如计算抛物线，是计算炮弹轨迹的；那些化学公式是干嘛的？是炸弹配方。瓦特改进蒸气机，法国人就想买，幸亏瓦特爱国，没有卖。人工智能其实也是同样的道理，假如人工智能被一些人垄断的话，可能会对没有掌握人工智能的人形成一种威胁，而且这个威胁一定会打破原来的那种道德均衡。原来我们都挺和谐，但是必然要打破，所以不同国家之间可能会有这种情况。  
     
    但是这种情况我觉得不是最严重的，因为好像现代技术不断在扩展，很快就会从一国扩展到其它国家。但是也不能完全否定有这种危险，比如现在为什么各国把人工智能当成国家战略，这个不要回避。有些人想到怎么去杀人，当然也有很多人反对。但是即使不用来直接杀人，也可以间接杀人，如可以用人工智能来分析敌情，可以制定我的战略等等，其实都包括了。假如真有这种人工智能的话，可能有些国家在战争上就更有优势。  
     
    
    吕兆楠：
    无人机就是机器人。  
     
    
    盛洪：
    无人机带来很多道德问题。  
     
    
    吕兆楠：
    它可以炸掉你，也可以送东西，一个好的、一个坏的。  
     
    
    盛洪：
    技术本来是中性的，无人机就是一个道德问题，因为有了无人机可以任意去炸，类似于去暗杀，道理是一样的。  
     
    
    宁越：
    有人用无人机把俄罗斯总理的财产侦查了一个遍。  
     
    
    盛洪：
    所以有好、有坏。  
     
    
    吕兆楠：
    现在无人机可以快递，这是好事。  
     
    
    盛洪：
    人工智能、大数据，仍然存在人群之间的那种鸿沟。普通的消费者和一个巨大的交易平台、服务平台，比如像阿里巴巴，亚马逊，优步、滴滴这样的，会产生由于大数据、由于人工智能所造成的垄断。举个很简单的例子，有人指出，优步或者滴滴公司有大数据的时候，经济学的说法，可以产生非常实时的歧视性定价，你收入是多少、你是哪个阶层的、你住在哪儿、你现在上班还是下班、你现在是不是快迟到了，全知道，你快迟到了肯定要多加钱了，然后我就趁这个机会就给你加钱，大数据完全可以做到这一点，这个问题已经被发现了。  
     
    
    吕兆楠：
    没有隐私了。  
     
    
    盛洪：
    这就有问题。所以人们绝不会遵循过去形成的那种道德原则，甚至变得更恶劣。再一方面就是政府了，刚才谈到了，这就是专制主义者的第一个想法，我拿着人工智能、拿着大数据监控所有的人。这也是一种理想，我能控制所有人。  
     
    
    何光沪：
    刚才我接一个电话就是叫我不许参加这个会的。  
     
    
    盛洪：
    所以这就是专制主义可能利用的，有可能导致更为专制，这也是对人类社会的破坏。专制可能有这种优势，你在哪儿我知道，你到哪儿发言我知道，你脑子里想什么我恨不得知道，我搞这个公式把你判成什么样的人，我还给你评分，参加一次会给你加一分，加十分枪毙。这也是人工智能带来的负面的影响。我们不能光看正面影响，也有负面的。  
     
    所以我说，我倒不是特别赞成光沪那个说国际管制，问题是，谁来管制。但是有一点要求，人工智能一定要某种意义上强制性普及，你不能形成某些掌握人工智能的那种垄断优势，而有些人不知道。我觉得比如将来人工智能应该双向的，比如现在手机，每个人其实都拿着一个计算机，这是手机，其实这是一种普及，这种普及，我觉得随着技术的发展，是在消解那种用人工智能做坏事的可能性，当然这种普及包括了不同民族的、不同阶层的、不同角色的，不是你是交易平台，我只是一个普通的交易者，我们俩不平等，不是的，我们是对等的。  
     
    从这来讲我的想法是，这个技术革命所带来的那种对道德均衡的打破，往往是通过技术革命的普及来解决。最开始贵族有一把刀，是很贵的，一般人是买不起的。这个技术普及了，每个人都有一把刀，这个贵族的优势就没有了。手枪、热兵器发展之前，男女之间力量不平衡，男的力量大。现在女的拿把枪，男的力量优势就没有了，就促进了男女平等。还是这个枪，像美国，大家都有枪，政府有枪、警察有枪，我也有。  
     
    
    吕兆楠：
    持枪合法化。  
     
    
    盛洪：
    技术的普及造成了一种力量均势。所以我们要求的就是，最先进的技术一定要公布给大家，或者制成大家能用的那样一些设备。当然这个做法还是回到经济学家讲的，我们要市场制度、我们要竞争、反垄断，人工智能要反垄断，尤其现在比较严重的垄断，一个是政府的垄断，一个是大的平台的垄断，所以我觉得这两者可能是最值得关注的，你要管制就管制这两个垄断，政府不能用这种技术去控制公民，这就侵犯了公民权利了，严格来讲，这不是管制，是宪法约束。大平台也是一样，将来你那样做就是垄断了。  
     
    
    吕兆楠：
    要强制他。  
     
    
    何光沪：
    我这两天看到电视上天天有扎克•伯格，扎克•伯格国会对他的问询，他不是有意的泄漏一些东西，控制都能控制，搜集情况都能搜集，但是不能用来伤害你，是这样的。他那个法律是不能上让伤害人，因为他有伤害人，所以把他天天叫来审问他。  
     
    
    盛洪：
    美国人非常敏感这个问题，有很高的警惕性。如果拿这种技术伤害民众，很可怕，所以国会让扎克伯格去去作证，这是一个问题。  
     
    
    何光沪：
    是一个失误造成的。  
     
    
    盛洪：
    最后我想讲一讲，人工智能本身是不是构成对作为整体的人类的威胁。我觉得首先，如果人工智能有威胁的话，就必然有它的自我利益，没有的话就不会，有自我利益就接近于人了，它是那个主体，它有主体感。而现在只是一个计算的速度快的问题，现在人工智能是一种没有身体的人工智能，关键是不构成有自我意识和自我利益的主体，我认为没有关系的。人工智能再厉害只是人的一部分、是一个工具，比较可怕的是有人利用它来伤害别的人。  
     
    另外一点，人工智能有没有道德呢？我觉得可以有道德。道德怎么产生的？道德其实是互动中产生的，假如人工智能和人工智能之间互动，它们一定会产生某种自发秩序，就是某种习俗、某种规则，在比如说一群人工智能中间会形成某种平衡，为什么呢？这是一个基本逻辑，你要保证这个人工智能活别的也活，而且它们之间比较均衡的话，这个逻辑跟人是一样的，所以不是要教它们道德。人们现在的想法，是一种建构主义形式，我告诉你有  10  条道德你就遵循，当然这是可以的。还有一种，你从来不告诉它们到底什么是道德，它们会不会知道呢？你要弄一群人工智能，互动多少次以后一定会有，这个也挺有趣。我们的经济学家，包括我们信奉哈耶克自发秩序的人，我们都可以搞这个实验，我买一群人工智能的小机器人让它们去互动。过了一段时间发现他们之间一定有某种规则。我们坚信自发秩序，就坚信有这个结果。所以我说人工智能最后还是有道德的。  
     
    
    吕兆楠：
    请问一下盛老师，你刚刚讲最后一句话的意思是说，机器人到最后他也会自立的，机器人这个小团体会自立的，就是有道理。  
     
    
    盛洪：
    对，就是说它会自立，但是它不会达到人这样的自立程度。我刚刚说它们是不是有自我，你可以说他它有自我，你假设它有计算，但没有身体，但是它可以达到一定程度的自我意识。比如蚂蚁也有自我，蚂蚁也可以形成规则，但是它们跟人的理性也是有很大差距 。  
     
    
    吕兆楠：
    你讲的伊斯塔会自立的，他也有他一套规则的。  
     
    
    盛洪：
    其实道德说到头就是个体和群体的关系，只要有个体和群体一定有道德，它们就要互动，你不要给它们规定多少条道德戒律，你就告诉它们你们自己玩去，就会形成规则。  
     
    
    吕兆楠：
    或者这么说，你给他一个道德的行为，红灯要停的，前面人开过来你要停的，他有这么一个道德思路给他之后，他会发展的，狗爬过来我也听的，什么事情不好做的，他会自立的发展成为一个。  
     
    
    盛洪：
    不用给他一个规则说“红灯要停”，它最后就会停的。  
     
    
    吕兆楠：
    这个思维的初次输入是谁输给他的，人输给他的？  
     
    
    盛洪：
    不是的，你不停就要撞车，完蛋了，我偶然停了就没撞车。  
     
    
    吕兆楠：
    你的意思是，不要输入给它、它也会停，假如不停它也死掉了。  
     
    
    盛洪：
    这是有代价的，人类也一样，人类早期，刚与黑猩猩分手不久，死亡的概率大概  15%  —  25%  ，人类进入文明社会，就是人类有了国家以后大概降低到  3%  —  5%  。现在很低。  
     
    
    吕兆楠：
    以前没有交通规则，现在有了。  
     
    
    何光沪：
    非自然死亡的。  
     
    
    盛洪：
    非自然，就是说暴力死亡，所以很多人才知道红灯是不能走的。有很多人类学研究，大概  3%  —  5%  ，随便有几篇文章、几本书都能找到的这些东西，人类大概是  15%  —  25%  。  
     
    
    何光沪：
    你说文明之前？  
     
    
    盛洪：
    文明之前，所谓文明就是有国家以后。  
     
    
    何光沪：
    野蛮时代、原始时代。  
     
    
    盛洪：
    对。  
     
     
     [  
    盛洪
    著名经济学家，天则经济研究所所长。本文为作者  2018  年  7  月  11  日在「人工智能与道德风险」云豹沙龙的演讲，转载请注明  ] 
     
  

" />
    <meta property="og:description" content="
  
      
    
  
    
    
    本文作者盛洪  
     
    谢谢蒋豪。我肯定没有像光沪讲的那么深，但是受启发还是有一些想法的。我觉得人类发展是两个方面，一方面是生产能力  ,  一方面是道德能力。近代的很多理论学说只看到一个维度，比如马克思的历史唯物主义，就看一个维度，这个维度就是生产能力，生产能力不断前进。当然还有其他学派也有这样的思想，什么是好，就是生产能力更强。其实它们没有看到另外一个能力是道德能力。我觉得道德能力应包括两种形式，一种是适用于大众的，就是由大众互动形成的某种习俗、习惯、惯例、传统。这实际上有一个前提，这个前提就是说，互动的人们在生产能力上比较相似，他们不断的交往  ,  交往以后就形成了哈耶克所说的自发秩序。大家发现我们遵守这个秩序能保持一种均衡，不会产生一种不平衡或社会的冲突、动荡和断裂。另外一种就是精英层的道德能力，就比较高了，宗教人士、士大夫还有一些文化精英，他们的能力不仅是对习俗的遵从，而且是对习俗的思考、总结、提炼形成一些更为凝练的道德价值的描述，最后形成我称之为的“文明经典”。这个文明经典又成为一个传统，不断的扩散和传播下去。围绕文明经典就形成了一个文化精英阶层，这个阶层在社会中起到某种骨干作用。  
     
    在一个技术相对稳定的时代，由它决定的这样一个道德形式，尤其是民间形成那种习俗习惯传统  ,  也相对稳定。大家的道德能力首先是受到了基本不变的那种生产能力或技术水平的稳定性的保证，因为由于生产能力都是差不多的，所以大家谁也没有更多的优势，在这种生产能力之下形成这种习俗习惯是相对稳定的。大家借助于对习俗、习惯和传统的遵从，保证他们的道德能力与他们的生产能力相匹配。如果出现了一种技术创新或革命，而这种技术革命还有一个特点，就是一部分人优先掌握，他们在生产能力上产生某种优势，这个时候严格来讲，过去人和人之间遵从的道德规范或者说习俗、习惯和传统，就崩塌了，因为原来的习俗习惯在人的生产能力都差不多的情况下，你打不过我、我也打不过你，我想抢你也没你劲大，现在不是了，现在我想抢你很容易，我拿把枪就把你抢了，因为你没有枪。传统的自发形成的伦理规则就崩塌掉了，这是任何发生技术变革时代应该特别关注和警惕的，因为大家总是一味的看到了新技术或者更高的生产能力，给掌握这种新技术和生产能力的人带来的好处，没有看到这些人利用这种优势，相对于没有这种优势的人之间，又会出现对原来那种道德均衡的破坏，甚至对没有优势人的一种侵夺，这种情况其实经常发生。  
     
    我觉得在近代社会是非常明显的。近代以来，比如说西方人先有了更高的生产能力，很快就会把这种生产能力运用到怎么能使自己获得更多的利益方面，这必然打破过去那种道德均衡，其实它就崩塌了。所以近代以来那种东西方的冲突就在这儿。这种情形到了现代仍然有演进，比如说这样一种生产能力带来的现代武器，会导致其它一些国家的冲突。我看到非洲经常有动乱，一个人拿着枪的第一个想法，不是要保持人们之间和平的均衡，而要拿这个枪消灭那些过去一直跟我抗衡的人群，所以在近代也能看出，非洲会出现很多血腥的事情，这只不过是近代以来所有事情的重演，西方殖民者对于非西方人的类似情形的重演。  
     
    在现代人工智能的框架下也会出现这种情形。假如这种新技术不是为所有人所掌握，只是为一小部分人所掌握，这小部分人一定会利用这种优势打破原来的均衡，比如我能猜透你，我为什么不用这个优势来从你身上攫取更多的利益呢。这可能也包括两部分，一部分是在不同民族和不同国家之间，假如谁更有优势，谁就占更大便宜。当然这个说法其实是很古老的。大家都知道，技术的竞争很快会用到国家层次，包括欧洲也是一样的。很多人说科学无国界，那都是胡说。科学一上来就跟国家层次是相关的。不要把科学家打扮得那么纯真，不是那样的。很多科学，如计算抛物线，是计算炮弹轨迹的；那些化学公式是干嘛的？是炸弹配方。瓦特改进蒸气机，法国人就想买，幸亏瓦特爱国，没有卖。人工智能其实也是同样的道理，假如人工智能被一些人垄断的话，可能会对没有掌握人工智能的人形成一种威胁，而且这个威胁一定会打破原来的那种道德均衡。原来我们都挺和谐，但是必然要打破，所以不同国家之间可能会有这种情况。  
     
    但是这种情况我觉得不是最严重的，因为好像现代技术不断在扩展，很快就会从一国扩展到其它国家。但是也不能完全否定有这种危险，比如现在为什么各国把人工智能当成国家战略，这个不要回避。有些人想到怎么去杀人，当然也有很多人反对。但是即使不用来直接杀人，也可以间接杀人，如可以用人工智能来分析敌情，可以制定我的战略等等，其实都包括了。假如真有这种人工智能的话，可能有些国家在战争上就更有优势。  
     
    
    吕兆楠：
    无人机就是机器人。  
     
    
    盛洪：
    无人机带来很多道德问题。  
     
    
    吕兆楠：
    它可以炸掉你，也可以送东西，一个好的、一个坏的。  
     
    
    盛洪：
    技术本来是中性的，无人机就是一个道德问题，因为有了无人机可以任意去炸，类似于去暗杀，道理是一样的。  
     
    
    宁越：
    有人用无人机把俄罗斯总理的财产侦查了一个遍。  
     
    
    盛洪：
    所以有好、有坏。  
     
    
    吕兆楠：
    现在无人机可以快递，这是好事。  
     
    
    盛洪：
    人工智能、大数据，仍然存在人群之间的那种鸿沟。普通的消费者和一个巨大的交易平台、服务平台，比如像阿里巴巴，亚马逊，优步、滴滴这样的，会产生由于大数据、由于人工智能所造成的垄断。举个很简单的例子，有人指出，优步或者滴滴公司有大数据的时候，经济学的说法，可以产生非常实时的歧视性定价，你收入是多少、你是哪个阶层的、你住在哪儿、你现在上班还是下班、你现在是不是快迟到了，全知道，你快迟到了肯定要多加钱了，然后我就趁这个机会就给你加钱，大数据完全可以做到这一点，这个问题已经被发现了。  
     
    
    吕兆楠：
    没有隐私了。  
     
    
    盛洪：
    这就有问题。所以人们绝不会遵循过去形成的那种道德原则，甚至变得更恶劣。再一方面就是政府了，刚才谈到了，这就是专制主义者的第一个想法，我拿着人工智能、拿着大数据监控所有的人。这也是一种理想，我能控制所有人。  
     
    
    何光沪：
    刚才我接一个电话就是叫我不许参加这个会的。  
     
    
    盛洪：
    所以这就是专制主义可能利用的，有可能导致更为专制，这也是对人类社会的破坏。专制可能有这种优势，你在哪儿我知道，你到哪儿发言我知道，你脑子里想什么我恨不得知道，我搞这个公式把你判成什么样的人，我还给你评分，参加一次会给你加一分，加十分枪毙。这也是人工智能带来的负面的影响。我们不能光看正面影响，也有负面的。  
     
    所以我说，我倒不是特别赞成光沪那个说国际管制，问题是，谁来管制。但是有一点要求，人工智能一定要某种意义上强制性普及，你不能形成某些掌握人工智能的那种垄断优势，而有些人不知道。我觉得比如将来人工智能应该双向的，比如现在手机，每个人其实都拿着一个计算机，这是手机，其实这是一种普及，这种普及，我觉得随着技术的发展，是在消解那种用人工智能做坏事的可能性，当然这种普及包括了不同民族的、不同阶层的、不同角色的，不是你是交易平台，我只是一个普通的交易者，我们俩不平等，不是的，我们是对等的。  
     
    从这来讲我的想法是，这个技术革命所带来的那种对道德均衡的打破，往往是通过技术革命的普及来解决。最开始贵族有一把刀，是很贵的，一般人是买不起的。这个技术普及了，每个人都有一把刀，这个贵族的优势就没有了。手枪、热兵器发展之前，男女之间力量不平衡，男的力量大。现在女的拿把枪，男的力量优势就没有了，就促进了男女平等。还是这个枪，像美国，大家都有枪，政府有枪、警察有枪，我也有。  
     
    
    吕兆楠：
    持枪合法化。  
     
    
    盛洪：
    技术的普及造成了一种力量均势。所以我们要求的就是，最先进的技术一定要公布给大家，或者制成大家能用的那样一些设备。当然这个做法还是回到经济学家讲的，我们要市场制度、我们要竞争、反垄断，人工智能要反垄断，尤其现在比较严重的垄断，一个是政府的垄断，一个是大的平台的垄断，所以我觉得这两者可能是最值得关注的，你要管制就管制这两个垄断，政府不能用这种技术去控制公民，这就侵犯了公民权利了，严格来讲，这不是管制，是宪法约束。大平台也是一样，将来你那样做就是垄断了。  
     
    
    吕兆楠：
    要强制他。  
     
    
    何光沪：
    我这两天看到电视上天天有扎克•伯格，扎克•伯格国会对他的问询，他不是有意的泄漏一些东西，控制都能控制，搜集情况都能搜集，但是不能用来伤害你，是这样的。他那个法律是不能上让伤害人，因为他有伤害人，所以把他天天叫来审问他。  
     
    
    盛洪：
    美国人非常敏感这个问题，有很高的警惕性。如果拿这种技术伤害民众，很可怕，所以国会让扎克伯格去去作证，这是一个问题。  
     
    
    何光沪：
    是一个失误造成的。  
     
    
    盛洪：
    最后我想讲一讲，人工智能本身是不是构成对作为整体的人类的威胁。我觉得首先，如果人工智能有威胁的话，就必然有它的自我利益，没有的话就不会，有自我利益就接近于人了，它是那个主体，它有主体感。而现在只是一个计算的速度快的问题，现在人工智能是一种没有身体的人工智能，关键是不构成有自我意识和自我利益的主体，我认为没有关系的。人工智能再厉害只是人的一部分、是一个工具，比较可怕的是有人利用它来伤害别的人。  
     
    另外一点，人工智能有没有道德呢？我觉得可以有道德。道德怎么产生的？道德其实是互动中产生的，假如人工智能和人工智能之间互动，它们一定会产生某种自发秩序，就是某种习俗、某种规则，在比如说一群人工智能中间会形成某种平衡，为什么呢？这是一个基本逻辑，你要保证这个人工智能活别的也活，而且它们之间比较均衡的话，这个逻辑跟人是一样的，所以不是要教它们道德。人们现在的想法，是一种建构主义形式，我告诉你有  10  条道德你就遵循，当然这是可以的。还有一种，你从来不告诉它们到底什么是道德，它们会不会知道呢？你要弄一群人工智能，互动多少次以后一定会有，这个也挺有趣。我们的经济学家，包括我们信奉哈耶克自发秩序的人，我们都可以搞这个实验，我买一群人工智能的小机器人让它们去互动。过了一段时间发现他们之间一定有某种规则。我们坚信自发秩序，就坚信有这个结果。所以我说人工智能最后还是有道德的。  
     
    
    吕兆楠：
    请问一下盛老师，你刚刚讲最后一句话的意思是说，机器人到最后他也会自立的，机器人这个小团体会自立的，就是有道理。  
     
    
    盛洪：
    对，就是说它会自立，但是它不会达到人这样的自立程度。我刚刚说它们是不是有自我，你可以说他它有自我，你假设它有计算，但没有身体，但是它可以达到一定程度的自我意识。比如蚂蚁也有自我，蚂蚁也可以形成规则，但是它们跟人的理性也是有很大差距 。  
     
    
    吕兆楠：
    你讲的伊斯塔会自立的，他也有他一套规则的。  
     
    
    盛洪：
    其实道德说到头就是个体和群体的关系，只要有个体和群体一定有道德，它们就要互动，你不要给它们规定多少条道德戒律，你就告诉它们你们自己玩去，就会形成规则。  
     
    
    吕兆楠：
    或者这么说，你给他一个道德的行为，红灯要停的，前面人开过来你要停的，他有这么一个道德思路给他之后，他会发展的，狗爬过来我也听的，什么事情不好做的，他会自立的发展成为一个。  
     
    
    盛洪：
    不用给他一个规则说“红灯要停”，它最后就会停的。  
     
    
    吕兆楠：
    这个思维的初次输入是谁输给他的，人输给他的？  
     
    
    盛洪：
    不是的，你不停就要撞车，完蛋了，我偶然停了就没撞车。  
     
    
    吕兆楠：
    你的意思是，不要输入给它、它也会停，假如不停它也死掉了。  
     
    
    盛洪：
    这是有代价的，人类也一样，人类早期，刚与黑猩猩分手不久，死亡的概率大概  15%  —  25%  ，人类进入文明社会，就是人类有了国家以后大概降低到  3%  —  5%  。现在很低。  
     
    
    吕兆楠：
    以前没有交通规则，现在有了。  
     
    
    何光沪：
    非自然死亡的。  
     
    
    盛洪：
    非自然，就是说暴力死亡，所以很多人才知道红灯是不能走的。有很多人类学研究，大概  3%  —  5%  ，随便有几篇文章、几本书都能找到的这些东西，人类大概是  15%  —  25%  。  
     
    
    何光沪：
    你说文明之前？  
     
    
    盛洪：
    文明之前，所谓文明就是有国家以后。  
     
    
    何光沪：
    野蛮时代、原始时代。  
     
    
    盛洪：
    对。  
     
     
     [  
    盛洪
    著名经济学家，天则经济研究所所长。本文为作者  2018  年  7  月  11  日在「人工智能与道德风险」云豹沙龙的演讲，转载请注明  ] 
     
  

" />
    
    <meta name="author" content="觀點" />

    
    <meta property="og:title" content="盛洪：生产能力和道德能力" />
    <meta property="twitter:title" content="盛洪：生产能力和道德能力" />
    

  <link rel="stylesheet" type="text/css" href="/opinion/style.css" />
  <link rel="alternate" type="application/rss+xml" title="觀點 - 從草根到大師 git.io/JJCxS" href="/opinion/feed.xml" />

  <!-- Social Share Kit CSS -->
  <link rel="stylesheet" href="/opinion/assets/css/social-share-kit.css" type="text/css">
  <link rel="stylesheet" href="/opinion/assets/css/font-awesome.min.css" type="text/css">
  <link rel="stylesheet" href="/opinion/assets/css/bootstrap.min.css" type="text/css">
  <script type="text/javascript" src="/opinion/assets/js/jquery-3.5.1.js"></script>
  <script type="text/javascript" src="/opinion/assets/js/page.js"></script>

</head>

  <body>
    <div class="wrapper-masthead">
  <div class="container">
    <header class="masthead clearfix">
      

      <div class="site-info">
        <h1 class="site-name" style="display: inline-block;"><a href="/opinion/">觀點</a></h1>
        <i class="site-description" style="font-size: 12px;">從草根到大師 git.io/JJCxS</i>
      </div>

      <nav>
        <span id="search-container" >
          <a href="/opinion/tools"><i class="fa fa-bookmark twitter" title="百宝箱"></i></a>
        <a><i class="fa fa-search" title="限前100結果"></i></a><input type="text" id="search-input" placeholder="標題 作者 來源 日期 (17499)"
          style="margin: 10px 0px 0px 0px; height: 30px;width: auto" title="本站最正確的打開方式">
        </span>
        
        
        <a href="/opinion/categories" style="color: Tomato;"><i class="fa fa-tags" title="分类"></i></a>
        
        
        
        <a href="https://be4.herokuapp.com/" style="color: #003366;"><i class="fa fa-comments" title="论坛"></i></a>
        
        
        
        <a href="/opinion/about"><i class="fa fa-info-circle" title="关于"></i></a>
        
        
        <a title="电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇，del同来源旧一篇" onclick="toggle_visibility('help')"><i class="fa fa-question-circle"></i></a>
        <a id="fa-home" href="https://nodebe4.github.io" title="BE4服务列表" onclick="//toggle_visibility('site-list')"><i class="fa fa-home" aria-hidden="true"></i></a>
      </nav>

    </header>
    <div id="site-list" class="tags" style="display: block;text-align: right;border-bottom: 1px solid lightGray;"><noscript><span style="background-color: #e8e8e8;color: #d10000;font-size: 14px;">开启浏览器JavaScript以获取搜索功能和更好的浏览体验</span></noscript></div>
    <p id="help" style="font-size: 14px;display: none;text-align: right;"><span style="color:green;">电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇, del同来源旧一篇</span>; <span style="color:orange">对应触屏FAB：上下右左</span>; 轉Markdown<a href="https://euangoddard.github.io/clipboard2markdown/"><i class="fa fa-file-text-o"></i></a></p>
  </div>
</div>

<script type="text/javascript" >
  function toggle_visibility(id){
    var help = document.getElementById(id)
    if (help.style.display=='none'){
      help.style.display='block';
    }else{
      help.style.display='none';
    }
  }

  const url = "https://nodebe4.github.io/sitelist.json"

  document.addEventListener("DOMContentLoaded", function(event){
    // var homebtn = document.getElementById("fa-home")
    // homebtn.removeAttribute("href")
    var content = document.getElementById("site-list");
    content.innerHTML = ''
    var ul = document.createElement("ul")
    ul.classList.add("label")
    content.appendChild(ul)
    var cnt = 0

    $.getJSON(url, function(allsites) {

      allsites.map(item =>{
        var li = document.createElement('li')
        li.classList.add("tag")
        li.id = 'site-' + cnt
        ul.appendChild(li)
        var a0 = document.createElement('a')
        li.appendChild(a0)
        a0.href = item.url[0]
        var span = document.createElement('span')
        a0.appendChild(span)
        span.innerText = item['name']
        // span.style.backgroundColor = item['background-color']
        // span.style.color='#E4CBC3'
        span.style.color = item['background-color']
        span.style['font-size'] = '14px'
        cnt += 1
        // test_alive(li.id, a0.href)
      })
    })
  })

function test_alive(id, url){
  var divstatus = document.getElementById(id)
  const base = 'https://textance.herokuapp.com/title/'
  var fullurl = base + url
  $.ajax({
      url: fullurl,
      complete: function(data) {
        if (data.responseText.includes('502')){
          // divstatus.style.color='#FBB7B7'
          // divstatus.style.color='gray'
          // divstatus.title = "服务器无响应"
          divstatus.parentNode.removeChild(divstatus)
        }else{
          // divstatus.style.color='#B6FAC8'
          divstatus.title = data.responseText
        }
      }
  });
  return divstatus
}
</script>



    <!-- Left & centered positioning -->

<div class="ssk-sticky ssk-right ssk-center ssk-sticky-hide-xs ssk-group ssk-round">
  
    <a href="https://be4news.pythonanywhere.com/archivenow/ia/http%3A%2F%2Funirule.cloud%2Findex.php%3Fc%3Darticle%26id%3D4665" class="ssk ssk-link" title="存到互联网档案馆" target="_blank"></a>
    <a href="https://www.facebook.com/sharer.php?u=http://unirule.cloud/index.php?c=article&id=4665" class="ssk ssk-facebook"></a>
    <a href="https://twitter.com/intent/tweet?url=http://unirule.cloud/index.php?c=article&id=4665&text=盛洪：生产能力和道德能力&hashtags=觀點" class="ssk ssk-twitter"></a>
    <a href="https://reddit.com/submit?url=http://unirule.cloud/index.php?c=article&id=4665&title=盛洪：生产能力和道德能力" class="ssk ssk-reddit"></a>
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://unirule.cloud/index.php?c=article&id=4665&title=盛洪：生产能力和道德能力" class="ssk ssk-linkedin"></a>
    <a href="mailto:{email_address}?subject=盛洪：生产能力和道德能力&body=
  
      
    
  
    
    
    本文作者盛洪  
     
    谢谢蒋豪。我肯定没有像光沪讲的那么深，但是受启发还是有一些想法的。我觉得人类发展是两个方面，一方面是生产能力  ,  一方面是道德能力。近代的很多理论学说只看到一个维度，比如马克思的历史唯物主义，就看一个维度，这个维度就是生产能力，生产能力不断前进。当然还有其他学派也有这样的思想，什么是好，就是生产能力更强。其实它们没有看到另外一个能力是道德能力。我觉得道德能力应包括两种形式，一种是适用于大众的，就是由大众互动形成的某种习俗、习惯、惯例、传统。这实际上有一个前提，这个前提就是说，互动的人们在生产能力上比较相似，他们不断的交往  ,  交往以后就形成了哈耶克所说的自发秩序。大家发现我们遵守这个秩序能保持一种均衡，不会产生一种不平衡或社会的冲突、动荡和断裂。另外一种就是精英层的道德能力，就比较高了，宗教人士、士大夫还有一些文化精英，他们的能力不仅是对习俗的遵从，而且是对习俗的思考、总结、提炼形成一些更为凝练的道德价值的描述，最后形成我称之为的“文明经典”。这个文明经典又成为一个传统，不断的扩散和传播下去。围绕文明经典就形成了一个文化精英阶层，这个阶层在社会中起到某种骨干作用。  
     
    在一个技术相对稳定的时代，由它决定的这样一个道德形式，尤其是民间形成那种习俗习惯传统  ,  也相对稳定。大家的道德能力首先是受到了基本不变的那种生产能力或技术水平的稳定性的保证，因为由于生产能力都是差不多的，所以大家谁也没有更多的优势，在这种生产能力之下形成这种习俗习惯是相对稳定的。大家借助于对习俗、习惯和传统的遵从，保证他们的道德能力与他们的生产能力相匹配。如果出现了一种技术创新或革命，而这种技术革命还有一个特点，就是一部分人优先掌握，他们在生产能力上产生某种优势，这个时候严格来讲，过去人和人之间遵从的道德规范或者说习俗、习惯和传统，就崩塌了，因为原来的习俗习惯在人的生产能力都差不多的情况下，你打不过我、我也打不过你，我想抢你也没你劲大，现在不是了，现在我想抢你很容易，我拿把枪就把你抢了，因为你没有枪。传统的自发形成的伦理规则就崩塌掉了，这是任何发生技术变革时代应该特别关注和警惕的，因为大家总是一味的看到了新技术或者更高的生产能力，给掌握这种新技术和生产能力的人带来的好处，没有看到这些人利用这种优势，相对于没有这种优势的人之间，又会出现对原来那种道德均衡的破坏，甚至对没有优势人的一种侵夺，这种情况其实经常发生。  
     
    我觉得在近代社会是非常明显的。近代以来，比如说西方人先有了更高的生产能力，很快就会把这种生产能力运用到怎么能使自己获得更多的利益方面，这必然打破过去那种道德均衡，其实它就崩塌了。所以近代以来那种东西方的冲突就在这儿。这种情形到了现代仍然有演进，比如说这样一种生产能力带来的现代武器，会导致其它一些国家的冲突。我看到非洲经常有动乱，一个人拿着枪的第一个想法，不是要保持人们之间和平的均衡，而要拿这个枪消灭那些过去一直跟我抗衡的人群，所以在近代也能看出，非洲会出现很多血腥的事情，这只不过是近代以来所有事情的重演，西方殖民者对于非西方人的类似情形的重演。  
     
    在现代人工智能的框架下也会出现这种情形。假如这种新技术不是为所有人所掌握，只是为一小部分人所掌握，这小部分人一定会利用这种优势打破原来的均衡，比如我能猜透你，我为什么不用这个优势来从你身上攫取更多的利益呢。这可能也包括两部分，一部分是在不同民族和不同国家之间，假如谁更有优势，谁就占更大便宜。当然这个说法其实是很古老的。大家都知道，技术的竞争很快会用到国家层次，包括欧洲也是一样的。很多人说科学无国界，那都是胡说。科学一上来就跟国家层次是相关的。不要把科学家打扮得那么纯真，不是那样的。很多科学，如计算抛物线，是计算炮弹轨迹的；那些化学公式是干嘛的？是炸弹配方。瓦特改进蒸气机，法国人就想买，幸亏瓦特爱国，没有卖。人工智能其实也是同样的道理，假如人工智能被一些人垄断的话，可能会对没有掌握人工智能的人形成一种威胁，而且这个威胁一定会打破原来的那种道德均衡。原来我们都挺和谐，但是必然要打破，所以不同国家之间可能会有这种情况。  
     
    但是这种情况我觉得不是最严重的，因为好像现代技术不断在扩展，很快就会从一国扩展到其它国家。但是也不能完全否定有这种危险，比如现在为什么各国把人工智能当成国家战略，这个不要回避。有些人想到怎么去杀人，当然也有很多人反对。但是即使不用来直接杀人，也可以间接杀人，如可以用人工智能来分析敌情，可以制定我的战略等等，其实都包括了。假如真有这种人工智能的话，可能有些国家在战争上就更有优势。  
     
    
    吕兆楠：
    无人机就是机器人。  
     
    
    盛洪：
    无人机带来很多道德问题。  
     
    
    吕兆楠：
    它可以炸掉你，也可以送东西，一个好的、一个坏的。  
     
    
    盛洪：
    技术本来是中性的，无人机就是一个道德问题，因为有了无人机可以任意去炸，类似于去暗杀，道理是一样的。  
     
    
    宁越：
    有人用无人机把俄罗斯总理的财产侦查了一个遍。  
     
    
    盛洪：
    所以有好、有坏。  
     
    
    吕兆楠：
    现在无人机可以快递，这是好事。  
     
    
    盛洪：
    人工智能、大数据，仍然存在人群之间的那种鸿沟。普通的消费者和一个巨大的交易平台、服务平台，比如像阿里巴巴，亚马逊，优步、滴滴这样的，会产生由于大数据、由于人工智能所造成的垄断。举个很简单的例子，有人指出，优步或者滴滴公司有大数据的时候，经济学的说法，可以产生非常实时的歧视性定价，你收入是多少、你是哪个阶层的、你住在哪儿、你现在上班还是下班、你现在是不是快迟到了，全知道，你快迟到了肯定要多加钱了，然后我就趁这个机会就给你加钱，大数据完全可以做到这一点，这个问题已经被发现了。  
     
    
    吕兆楠：
    没有隐私了。  
     
    
    盛洪：
    这就有问题。所以人们绝不会遵循过去形成的那种道德原则，甚至变得更恶劣。再一方面就是政府了，刚才谈到了，这就是专制主义者的第一个想法，我拿着人工智能、拿着大数据监控所有的人。这也是一种理想，我能控制所有人。  
     
    
    何光沪：
    刚才我接一个电话就是叫我不许参加这个会的。  
     
    
    盛洪：
    所以这就是专制主义可能利用的，有可能导致更为专制，这也是对人类社会的破坏。专制可能有这种优势，你在哪儿我知道，你到哪儿发言我知道，你脑子里想什么我恨不得知道，我搞这个公式把你判成什么样的人，我还给你评分，参加一次会给你加一分，加十分枪毙。这也是人工智能带来的负面的影响。我们不能光看正面影响，也有负面的。  
     
    所以我说，我倒不是特别赞成光沪那个说国际管制，问题是，谁来管制。但是有一点要求，人工智能一定要某种意义上强制性普及，你不能形成某些掌握人工智能的那种垄断优势，而有些人不知道。我觉得比如将来人工智能应该双向的，比如现在手机，每个人其实都拿着一个计算机，这是手机，其实这是一种普及，这种普及，我觉得随着技术的发展，是在消解那种用人工智能做坏事的可能性，当然这种普及包括了不同民族的、不同阶层的、不同角色的，不是你是交易平台，我只是一个普通的交易者，我们俩不平等，不是的，我们是对等的。  
     
    从这来讲我的想法是，这个技术革命所带来的那种对道德均衡的打破，往往是通过技术革命的普及来解决。最开始贵族有一把刀，是很贵的，一般人是买不起的。这个技术普及了，每个人都有一把刀，这个贵族的优势就没有了。手枪、热兵器发展之前，男女之间力量不平衡，男的力量大。现在女的拿把枪，男的力量优势就没有了，就促进了男女平等。还是这个枪，像美国，大家都有枪，政府有枪、警察有枪，我也有。  
     
    
    吕兆楠：
    持枪合法化。  
     
    
    盛洪：
    技术的普及造成了一种力量均势。所以我们要求的就是，最先进的技术一定要公布给大家，或者制成大家能用的那样一些设备。当然这个做法还是回到经济学家讲的，我们要市场制度、我们要竞争、反垄断，人工智能要反垄断，尤其现在比较严重的垄断，一个是政府的垄断，一个是大的平台的垄断，所以我觉得这两者可能是最值得关注的，你要管制就管制这两个垄断，政府不能用这种技术去控制公民，这就侵犯了公民权利了，严格来讲，这不是管制，是宪法约束。大平台也是一样，将来你那样做就是垄断了。  
     
    
    吕兆楠：
    要强制他。  
     
    
    何光沪：
    我这两天看到电视上天天有扎克•伯格，扎克•伯格国会对他的问询，他不是有意的泄漏一些东西，控制都能控制，搜集情况都能搜集，但是不能用来伤害你，是这样的。他那个法律是不能上让伤害人，因为他有伤害人，所以把他天天叫来审问他。  
     
    
    盛洪：
    美国人非常敏感这个问题，有很高的警惕性。如果拿这种技术伤害民众，很可怕，所以国会让扎克伯格去去作证，这是一个问题。  
     
    
    何光沪：
    是一个失误造成的。  
     
    
    盛洪：
    最后我想讲一讲，人工智能本身是不是构成对作为整体的人类的威胁。我觉得首先，如果人工智能有威胁的话，就必然有它的自我利益，没有的话就不会，有自我利益就接近于人了，它是那个主体，它有主体感。而现在只是一个计算的速度快的问题，现在人工智能是一种没有身体的人工智能，关键是不构成有自我意识和自我利益的主体，我认为没有关系的。人工智能再厉害只是人的一部分、是一个工具，比较可怕的是有人利用它来伤害别的人。  
     
    另外一点，人工智能有没有道德呢？我觉得可以有道德。道德怎么产生的？道德其实是互动中产生的，假如人工智能和人工智能之间互动，它们一定会产生某种自发秩序，就是某种习俗、某种规则，在比如说一群人工智能中间会形成某种平衡，为什么呢？这是一个基本逻辑，你要保证这个人工智能活别的也活，而且它们之间比较均衡的话，这个逻辑跟人是一样的，所以不是要教它们道德。人们现在的想法，是一种建构主义形式，我告诉你有  10  条道德你就遵循，当然这是可以的。还有一种，你从来不告诉它们到底什么是道德，它们会不会知道呢？你要弄一群人工智能，互动多少次以后一定会有，这个也挺有趣。我们的经济学家，包括我们信奉哈耶克自发秩序的人，我们都可以搞这个实验，我买一群人工智能的小机器人让它们去互动。过了一段时间发现他们之间一定有某种规则。我们坚信自发秩序，就坚信有这个结果。所以我说人工智能最后还是有道德的。  
     
    
    吕兆楠：
    请问一下盛老师，你刚刚讲最后一句话的意思是说，机器人到最后他也会自立的，机器人这个小团体会自立的，就是有道理。  
     
    
    盛洪：
    对，就是说它会自立，但是它不会达到人这样的自立程度。我刚刚说它们是不是有自我，你可以说他它有自我，你假设它有计算，但没有身体，但是它可以达到一定程度的自我意识。比如蚂蚁也有自我，蚂蚁也可以形成规则，但是它们跟人的理性也是有很大差距 。  
     
    
    吕兆楠：
    你讲的伊斯塔会自立的，他也有他一套规则的。  
     
    
    盛洪：
    其实道德说到头就是个体和群体的关系，只要有个体和群体一定有道德，它们就要互动，你不要给它们规定多少条道德戒律，你就告诉它们你们自己玩去，就会形成规则。  
     
    
    吕兆楠：
    或者这么说，你给他一个道德的行为，红灯要停的，前面人开过来你要停的，他有这么一个道德思路给他之后，他会发展的，狗爬过来我也听的，什么事情不好做的，他会自立的发展成为一个。  
     
    
    盛洪：
    不用给他一个规则说“红灯要停”，它最后就会停的。  
     
    
    吕兆楠：
    这个思维的初次输入是谁输给他的，人输给他的？  
     
    
    盛洪：
    不是的，你不停就要撞车，完蛋了，我偶然停了就没撞车。  
     
    
    吕兆楠：
    你的意思是，不要输入给它、它也会停，假如不停它也死掉了。  
     
    
    盛洪：
    这是有代价的，人类也一样，人类早期，刚与黑猩猩分手不久，死亡的概率大概  15%  —  25%  ，人类进入文明社会，就是人类有了国家以后大概降低到  3%  —  5%  。现在很低。  
     
    
    吕兆楠：
    以前没有交通规则，现在有了。  
     
    
    何光沪：
    非自然死亡的。  
     
    
    盛洪：
    非自然，就是说暴力死亡，所以很多人才知道红灯是不能走的。有很多人类学研究，大概  3%  —  5%  ，随便有几篇文章、几本书都能找到的这些东西，人类大概是  15%  —  25%  。  
     
    
    何光沪：
    你说文明之前？  
     
    
    盛洪：
    文明之前，所谓文明就是有国家以后。  
     
    
    何光沪：
    野蛮时代、原始时代。  
     
    
    盛洪：
    对。  
     
     
     [  
    盛洪
    著名经济学家，天则经济研究所所长。本文为作者  2018  年  7  月  11  日在「人工智能与道德风险」云豹沙龙的演讲，转载请注明  ] 
     
  

" class="ssk ssk-email"></a>
    <a href="http://pinterest.com/pin/create/link/?url=http://unirule.cloud/index.php?c=article&id=4665" class="ssk ssk-pinterest"></a>
    <a href="https://www.tumblr.com/widgets/share/tool?canonicalUrl=http://unirule.cloud/index.php?c=article&id=4665&title=盛洪：生产能力和道德能力&caption=
  
      
    
  
    
    
    本文作者盛洪  
     
    谢谢蒋豪。我肯定没有像光沪讲的那么深，但是受启发还是有一些想法的。我觉得人类发展是两个方面，一方面是生产能力  ,  一方面是道德能力。近代的很多理论学说只看到一个维度，比如马克思的历史唯物主义，就看一个维度，这个维度就是生产能力，生产能力不断前进。当然还有其他学派也有这样的思想，什么是好，就是生产能力更强。其实它们没有看到另外一个能力是道德能力。我觉得道德能力应包括两种形式，一种是适用于大众的，就是由大众互动形成的某种习俗、习惯、惯例、传统。这实际上有一个前提，这个前提就是说，互动的人们在生产能力上比较相似，他们不断的交往  ,  交往以后就形成了哈耶克所说的自发秩序。大家发现我们遵守这个秩序能保持一种均衡，不会产生一种不平衡或社会的冲突、动荡和断裂。另外一种就是精英层的道德能力，就比较高了，宗教人士、士大夫还有一些文化精英，他们的能力不仅是对习俗的遵从，而且是对习俗的思考、总结、提炼形成一些更为凝练的道德价值的描述，最后形成我称之为的“文明经典”。这个文明经典又成为一个传统，不断的扩散和传播下去。围绕文明经典就形成了一个文化精英阶层，这个阶层在社会中起到某种骨干作用。  
     
    在一个技术相对稳定的时代，由它决定的这样一个道德形式，尤其是民间形成那种习俗习惯传统  ,  也相对稳定。大家的道德能力首先是受到了基本不变的那种生产能力或技术水平的稳定性的保证，因为由于生产能力都是差不多的，所以大家谁也没有更多的优势，在这种生产能力之下形成这种习俗习惯是相对稳定的。大家借助于对习俗、习惯和传统的遵从，保证他们的道德能力与他们的生产能力相匹配。如果出现了一种技术创新或革命，而这种技术革命还有一个特点，就是一部分人优先掌握，他们在生产能力上产生某种优势，这个时候严格来讲，过去人和人之间遵从的道德规范或者说习俗、习惯和传统，就崩塌了，因为原来的习俗习惯在人的生产能力都差不多的情况下，你打不过我、我也打不过你，我想抢你也没你劲大，现在不是了，现在我想抢你很容易，我拿把枪就把你抢了，因为你没有枪。传统的自发形成的伦理规则就崩塌掉了，这是任何发生技术变革时代应该特别关注和警惕的，因为大家总是一味的看到了新技术或者更高的生产能力，给掌握这种新技术和生产能力的人带来的好处，没有看到这些人利用这种优势，相对于没有这种优势的人之间，又会出现对原来那种道德均衡的破坏，甚至对没有优势人的一种侵夺，这种情况其实经常发生。  
     
    我觉得在近代社会是非常明显的。近代以来，比如说西方人先有了更高的生产能力，很快就会把这种生产能力运用到怎么能使自己获得更多的利益方面，这必然打破过去那种道德均衡，其实它就崩塌了。所以近代以来那种东西方的冲突就在这儿。这种情形到了现代仍然有演进，比如说这样一种生产能力带来的现代武器，会导致其它一些国家的冲突。我看到非洲经常有动乱，一个人拿着枪的第一个想法，不是要保持人们之间和平的均衡，而要拿这个枪消灭那些过去一直跟我抗衡的人群，所以在近代也能看出，非洲会出现很多血腥的事情，这只不过是近代以来所有事情的重演，西方殖民者对于非西方人的类似情形的重演。  
     
    在现代人工智能的框架下也会出现这种情形。假如这种新技术不是为所有人所掌握，只是为一小部分人所掌握，这小部分人一定会利用这种优势打破原来的均衡，比如我能猜透你，我为什么不用这个优势来从你身上攫取更多的利益呢。这可能也包括两部分，一部分是在不同民族和不同国家之间，假如谁更有优势，谁就占更大便宜。当然这个说法其实是很古老的。大家都知道，技术的竞争很快会用到国家层次，包括欧洲也是一样的。很多人说科学无国界，那都是胡说。科学一上来就跟国家层次是相关的。不要把科学家打扮得那么纯真，不是那样的。很多科学，如计算抛物线，是计算炮弹轨迹的；那些化学公式是干嘛的？是炸弹配方。瓦特改进蒸气机，法国人就想买，幸亏瓦特爱国，没有卖。人工智能其实也是同样的道理，假如人工智能被一些人垄断的话，可能会对没有掌握人工智能的人形成一种威胁，而且这个威胁一定会打破原来的那种道德均衡。原来我们都挺和谐，但是必然要打破，所以不同国家之间可能会有这种情况。  
     
    但是这种情况我觉得不是最严重的，因为好像现代技术不断在扩展，很快就会从一国扩展到其它国家。但是也不能完全否定有这种危险，比如现在为什么各国把人工智能当成国家战略，这个不要回避。有些人想到怎么去杀人，当然也有很多人反对。但是即使不用来直接杀人，也可以间接杀人，如可以用人工智能来分析敌情，可以制定我的战略等等，其实都包括了。假如真有这种人工智能的话，可能有些国家在战争上就更有优势。  
     
    
    吕兆楠：
    无人机就是机器人。  
     
    
    盛洪：
    无人机带来很多道德问题。  
     
    
    吕兆楠：
    它可以炸掉你，也可以送东西，一个好的、一个坏的。  
     
    
    盛洪：
    技术本来是中性的，无人机就是一个道德问题，因为有了无人机可以任意去炸，类似于去暗杀，道理是一样的。  
     
    
    宁越：
    有人用无人机把俄罗斯总理的财产侦查了一个遍。  
     
    
    盛洪：
    所以有好、有坏。  
     
    
    吕兆楠：
    现在无人机可以快递，这是好事。  
     
    
    盛洪：
    人工智能、大数据，仍然存在人群之间的那种鸿沟。普通的消费者和一个巨大的交易平台、服务平台，比如像阿里巴巴，亚马逊，优步、滴滴这样的，会产生由于大数据、由于人工智能所造成的垄断。举个很简单的例子，有人指出，优步或者滴滴公司有大数据的时候，经济学的说法，可以产生非常实时的歧视性定价，你收入是多少、你是哪个阶层的、你住在哪儿、你现在上班还是下班、你现在是不是快迟到了，全知道，你快迟到了肯定要多加钱了，然后我就趁这个机会就给你加钱，大数据完全可以做到这一点，这个问题已经被发现了。  
     
    
    吕兆楠：
    没有隐私了。  
     
    
    盛洪：
    这就有问题。所以人们绝不会遵循过去形成的那种道德原则，甚至变得更恶劣。再一方面就是政府了，刚才谈到了，这就是专制主义者的第一个想法，我拿着人工智能、拿着大数据监控所有的人。这也是一种理想，我能控制所有人。  
     
    
    何光沪：
    刚才我接一个电话就是叫我不许参加这个会的。  
     
    
    盛洪：
    所以这就是专制主义可能利用的，有可能导致更为专制，这也是对人类社会的破坏。专制可能有这种优势，你在哪儿我知道，你到哪儿发言我知道，你脑子里想什么我恨不得知道，我搞这个公式把你判成什么样的人，我还给你评分，参加一次会给你加一分，加十分枪毙。这也是人工智能带来的负面的影响。我们不能光看正面影响，也有负面的。  
     
    所以我说，我倒不是特别赞成光沪那个说国际管制，问题是，谁来管制。但是有一点要求，人工智能一定要某种意义上强制性普及，你不能形成某些掌握人工智能的那种垄断优势，而有些人不知道。我觉得比如将来人工智能应该双向的，比如现在手机，每个人其实都拿着一个计算机，这是手机，其实这是一种普及，这种普及，我觉得随着技术的发展，是在消解那种用人工智能做坏事的可能性，当然这种普及包括了不同民族的、不同阶层的、不同角色的，不是你是交易平台，我只是一个普通的交易者，我们俩不平等，不是的，我们是对等的。  
     
    从这来讲我的想法是，这个技术革命所带来的那种对道德均衡的打破，往往是通过技术革命的普及来解决。最开始贵族有一把刀，是很贵的，一般人是买不起的。这个技术普及了，每个人都有一把刀，这个贵族的优势就没有了。手枪、热兵器发展之前，男女之间力量不平衡，男的力量大。现在女的拿把枪，男的力量优势就没有了，就促进了男女平等。还是这个枪，像美国，大家都有枪，政府有枪、警察有枪，我也有。  
     
    
    吕兆楠：
    持枪合法化。  
     
    
    盛洪：
    技术的普及造成了一种力量均势。所以我们要求的就是，最先进的技术一定要公布给大家，或者制成大家能用的那样一些设备。当然这个做法还是回到经济学家讲的，我们要市场制度、我们要竞争、反垄断，人工智能要反垄断，尤其现在比较严重的垄断，一个是政府的垄断，一个是大的平台的垄断，所以我觉得这两者可能是最值得关注的，你要管制就管制这两个垄断，政府不能用这种技术去控制公民，这就侵犯了公民权利了，严格来讲，这不是管制，是宪法约束。大平台也是一样，将来你那样做就是垄断了。  
     
    
    吕兆楠：
    要强制他。  
     
    
    何光沪：
    我这两天看到电视上天天有扎克•伯格，扎克•伯格国会对他的问询，他不是有意的泄漏一些东西，控制都能控制，搜集情况都能搜集，但是不能用来伤害你，是这样的。他那个法律是不能上让伤害人，因为他有伤害人，所以把他天天叫来审问他。  
     
    
    盛洪：
    美国人非常敏感这个问题，有很高的警惕性。如果拿这种技术伤害民众，很可怕，所以国会让扎克伯格去去作证，这是一个问题。  
     
    
    何光沪：
    是一个失误造成的。  
     
    
    盛洪：
    最后我想讲一讲，人工智能本身是不是构成对作为整体的人类的威胁。我觉得首先，如果人工智能有威胁的话，就必然有它的自我利益，没有的话就不会，有自我利益就接近于人了，它是那个主体，它有主体感。而现在只是一个计算的速度快的问题，现在人工智能是一种没有身体的人工智能，关键是不构成有自我意识和自我利益的主体，我认为没有关系的。人工智能再厉害只是人的一部分、是一个工具，比较可怕的是有人利用它来伤害别的人。  
     
    另外一点，人工智能有没有道德呢？我觉得可以有道德。道德怎么产生的？道德其实是互动中产生的，假如人工智能和人工智能之间互动，它们一定会产生某种自发秩序，就是某种习俗、某种规则，在比如说一群人工智能中间会形成某种平衡，为什么呢？这是一个基本逻辑，你要保证这个人工智能活别的也活，而且它们之间比较均衡的话，这个逻辑跟人是一样的，所以不是要教它们道德。人们现在的想法，是一种建构主义形式，我告诉你有  10  条道德你就遵循，当然这是可以的。还有一种，你从来不告诉它们到底什么是道德，它们会不会知道呢？你要弄一群人工智能，互动多少次以后一定会有，这个也挺有趣。我们的经济学家，包括我们信奉哈耶克自发秩序的人，我们都可以搞这个实验，我买一群人工智能的小机器人让它们去互动。过了一段时间发现他们之间一定有某种规则。我们坚信自发秩序，就坚信有这个结果。所以我说人工智能最后还是有道德的。  
     
    
    吕兆楠：
    请问一下盛老师，你刚刚讲最后一句话的意思是说，机器人到最后他也会自立的，机器人这个小团体会自立的，就是有道理。  
     
    
    盛洪：
    对，就是说它会自立，但是它不会达到人这样的自立程度。我刚刚说它们是不是有自我，你可以说他它有自我，你假设它有计算，但没有身体，但是它可以达到一定程度的自我意识。比如蚂蚁也有自我，蚂蚁也可以形成规则，但是它们跟人的理性也是有很大差距 。  
     
    
    吕兆楠：
    你讲的伊斯塔会自立的，他也有他一套规则的。  
     
    
    盛洪：
    其实道德说到头就是个体和群体的关系，只要有个体和群体一定有道德，它们就要互动，你不要给它们规定多少条道德戒律，你就告诉它们你们自己玩去，就会形成规则。  
     
    
    吕兆楠：
    或者这么说，你给他一个道德的行为，红灯要停的，前面人开过来你要停的，他有这么一个道德思路给他之后，他会发展的，狗爬过来我也听的，什么事情不好做的，他会自立的发展成为一个。  
     
    
    盛洪：
    不用给他一个规则说“红灯要停”，它最后就会停的。  
     
    
    吕兆楠：
    这个思维的初次输入是谁输给他的，人输给他的？  
     
    
    盛洪：
    不是的，你不停就要撞车，完蛋了，我偶然停了就没撞车。  
     
    
    吕兆楠：
    你的意思是，不要输入给它、它也会停，假如不停它也死掉了。  
     
    
    盛洪：
    这是有代价的，人类也一样，人类早期，刚与黑猩猩分手不久，死亡的概率大概  15%  —  25%  ，人类进入文明社会，就是人类有了国家以后大概降低到  3%  —  5%  。现在很低。  
     
    
    吕兆楠：
    以前没有交通规则，现在有了。  
     
    
    何光沪：
    非自然死亡的。  
     
    
    盛洪：
    非自然，就是说暴力死亡，所以很多人才知道红灯是不能走的。有很多人类学研究，大概  3%  —  5%  ，随便有几篇文章、几本书都能找到的这些东西，人类大概是  15%  —  25%  。  
     
    
    何光沪：
    你说文明之前？  
     
    
    盛洪：
    文明之前，所谓文明就是有国家以后。  
     
    
    何光沪：
    野蛮时代、原始时代。  
     
    
    盛洪：
    对。  
     
     
     [  
    盛洪
    著名经济学家，天则经济研究所所长。本文为作者  2018  年  7  月  11  日在「人工智能与道德风险」云豹沙龙的演讲，转载请注明  ] 
     
  

&tags=觀點" class="ssk ssk-tumblr"></a>
    <a href="https://buffer.com/add?text=盛洪：生产能力和道德能力&url=http://unirule.cloud/index.php?c=article&id=4665" class="ssk ssk-buffer"></a>
</div>


    <div id="main" role="main" class="container">
      
  <!-- Html Elements for Search -->
  <ul id="results-container" class="searched" style="color: #2980B9;"></ul>

  <script src="/opinion/assets/js/simple-jekyll-search.min.js"></script>

  <!-- Configuration -->
  <script>
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    json: '/opinion/search.json',
    searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a><time>{date}</time><a class="tag">{category}</a></li>',
    noResultsText: '没找到',
    limit: 100,
    fuzzy: false,
    exclude: ['Welcome']
  })

  </script>

      







  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    


  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    



<article class="post">
  <h1>盛洪：生产能力和道德能力</h1>
  <!-- Look the author details up from the site config. -->
  

  <div>
    <span class="date">
      2018-08-10
    </span>

    <!-- Output author details if some exist. -->
    
      
        <span>
            <!-- Personal Info. -->
            <a  style="font-size:14px;">作者: 盛洪</a>
        </span>
      
    


    <ul class="tag">
      <li>
        <a href="https://nodebe4.github.io/opinion/categories/#天则观点">
          天则观点
        </a>
      </li>
    </ul>

    
        <span>
            <!-- Personal Info. -->
            <a href="http://unirule.cloud/index.php?c=article&id=4665" style="font-size:14px;">原文</a>
        </span>
    

    <span style="float: right;" title="天则观点的其它文章">
      <a style="font-size: 14px;" rel="nofollow" href="#sametag" class="tags">#天则观点 的其它文章</a>
    </span>

  </div>

  <div class="entry">
    
    
    
    <div class="article">
  <div class="body-text">
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> <br /> </span></p>
    <div style="text-align:center;">
<img alt="" height="418" src="/uploads/2018/08/111057181928.jpg" style="text-indent:21pt;" width="500" /> <span style="text-indent:21pt;"> </span>
    </div>
    <p><br /></p>
    <p class="MsoNormal" style="text-align:center;text-indent:0cm;">本文作者盛洪 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;">谢谢蒋豪。我肯定没有像光沪讲的那么深，但是受启发还是有一些想法的。我觉得人类发展是两个方面，一方面是生产能力 <span> , </span> 一方面是道德能力。近代的很多理论学说只看到一个维度，比如马克思的历史唯物主义，就看一个维度，这个维度就是生产能力，生产能力不断前进。当然还有其他学派也有这样的思想，什么是好，就是生产能力更强。其实它们没有看到另外一个能力是道德能力。我觉得道德能力应包括两种形式，一种是适用于大众的，就是由大众互动形成的某种习俗、习惯、惯例、传统。这实际上有一个前提，这个前提就是说，互动的人们在生产能力上比较相似，他们不断的交往 <span> , </span> 交往以后就形成了哈耶克所说的自发秩序。大家发现我们遵守这个秩序能保持一种均衡，不会产生一种不平衡或社会的冲突、动荡和断裂。另外一种就是精英层的道德能力，就比较高了，宗教人士、士大夫还有一些文化精英，他们的能力不仅是对习俗的遵从，而且是对习俗的思考、总结、提炼形成一些更为凝练的道德价值的描述，最后形成我称之为的“文明经典”。这个文明经典又成为一个传统，不断的扩散和传播下去。围绕文明经典就形成了一个文化精英阶层，这个阶层在社会中起到某种骨干作用。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;">在一个技术相对稳定的时代，由它决定的这样一个道德形式，尤其是民间形成那种习俗习惯传统 <span> , </span> 也相对稳定。大家的道德能力首先是受到了基本不变的那种生产能力或技术水平的稳定性的保证，因为由于生产能力都是差不多的，所以大家谁也没有更多的优势，在这种生产能力之下形成这种习俗习惯是相对稳定的。大家借助于对习俗、习惯和传统的遵从，保证他们的道德能力与他们的生产能力相匹配。如果出现了一种技术创新或革命，而这种技术革命还有一个特点，就是一部分人优先掌握，他们在生产能力上产生某种优势，这个时候严格来讲，过去人和人之间遵从的道德规范或者说习俗、习惯和传统，就崩塌了，因为原来的习俗习惯在人的生产能力都差不多的情况下，你打不过我、我也打不过你，我想抢你也没你劲大，现在不是了，现在我想抢你很容易，我拿把枪就把你抢了，因为你没有枪。传统的自发形成的伦理规则就崩塌掉了，这是任何发生技术变革时代应该特别关注和警惕的，因为大家总是一味的看到了新技术或者更高的生产能力，给掌握这种新技术和生产能力的人带来的好处，没有看到这些人利用这种优势，相对于没有这种优势的人之间，又会出现对原来那种道德均衡的破坏，甚至对没有优势人的一种侵夺，这种情况其实经常发生。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;">我觉得在近代社会是非常明显的。近代以来，比如说西方人先有了更高的生产能力，很快就会把这种生产能力运用到怎么能使自己获得更多的利益方面，这必然打破过去那种道德均衡，其实它就崩塌了。所以近代以来那种东西方的冲突就在这儿。这种情形到了现代仍然有演进，比如说这样一种生产能力带来的现代武器，会导致其它一些国家的冲突。我看到非洲经常有动乱，一个人拿着枪的第一个想法，不是要保持人们之间和平的均衡，而要拿这个枪消灭那些过去一直跟我抗衡的人群，所以在近代也能看出，非洲会出现很多血腥的事情，这只不过是近代以来所有事情的重演，西方殖民者对于非西方人的类似情形的重演。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;">在现代人工智能的框架下也会出现这种情形。假如这种新技术不是为所有人所掌握，只是为一小部分人所掌握，这小部分人一定会利用这种优势打破原来的均衡，比如我能猜透你，我为什么不用这个优势来从你身上攫取更多的利益呢。这可能也包括两部分，一部分是在不同民族和不同国家之间，假如谁更有优势，谁就占更大便宜。当然这个说法其实是很古老的。大家都知道，技术的竞争很快会用到国家层次，包括欧洲也是一样的。很多人说科学无国界，那都是胡说。科学一上来就跟国家层次是相关的。不要把科学家打扮得那么纯真，不是那样的。很多科学，如计算抛物线，是计算炮弹轨迹的；那些化学公式是干嘛的？是炸弹配方。瓦特改进蒸气机，法国人就想买，幸亏瓦特爱国，没有卖。人工智能其实也是同样的道理，假如人工智能被一些人垄断的话，可能会对没有掌握人工智能的人形成一种威胁，而且这个威胁一定会打破原来的那种道德均衡。原来我们都挺和谐，但是必然要打破，所以不同国家之间可能会有这种情况。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;">但是这种情况我觉得不是最严重的，因为好像现代技术不断在扩展，很快就会从一国扩展到其它国家。但是也不能完全否定有这种危险，比如现在为什么各国把人工智能当成国家战略，这个不要回避。有些人想到怎么去杀人，当然也有很多人反对。但是即使不用来直接杀人，也可以间接杀人，如可以用人工智能来分析敌情，可以制定我的战略等等，其实都包括了。假如真有这种人工智能的话，可能有些国家在战争上就更有优势。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 无人机就是机器人。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 无人机带来很多道德问题。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 它可以炸掉你，也可以送东西，一个好的、一个坏的。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 技术本来是中性的，无人机就是一个道德问题，因为有了无人机可以任意去炸，类似于去暗杀，道理是一样的。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    宁越：
   </b> 有人用无人机把俄罗斯总理的财产侦查了一个遍。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 所以有好、有坏。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 现在无人机可以快递，这是好事。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 人工智能、大数据，仍然存在人群之间的那种鸿沟。普通的消费者和一个巨大的交易平台、服务平台，比如像阿里巴巴，亚马逊，优步、滴滴这样的，会产生由于大数据、由于人工智能所造成的垄断。举个很简单的例子，有人指出，优步或者滴滴公司有大数据的时候，经济学的说法，可以产生非常实时的歧视性定价，你收入是多少、你是哪个阶层的、你住在哪儿、你现在上班还是下班、你现在是不是快迟到了，全知道，你快迟到了肯定要多加钱了，然后我就趁这个机会就给你加钱，大数据完全可以做到这一点，这个问题已经被发现了。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 没有隐私了。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 这就有问题。所以人们绝不会遵循过去形成的那种道德原则，甚至变得更恶劣。再一方面就是政府了，刚才谈到了，这就是专制主义者的第一个想法，我拿着人工智能、拿着大数据监控所有的人。这也是一种理想，我能控制所有人。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    何光沪：
   </b> 刚才我接一个电话就是叫我不许参加这个会的。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 所以这就是专制主义可能利用的，有可能导致更为专制，这也是对人类社会的破坏。专制可能有这种优势，你在哪儿我知道，你到哪儿发言我知道，你脑子里想什么我恨不得知道，我搞这个公式把你判成什么样的人，我还给你评分，参加一次会给你加一分，加十分枪毙。这也是人工智能带来的负面的影响。我们不能光看正面影响，也有负面的。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;">所以我说，我倒不是特别赞成光沪那个说国际管制，问题是，谁来管制。但是有一点要求，人工智能一定要某种意义上强制性普及，你不能形成某些掌握人工智能的那种垄断优势，而有些人不知道。我觉得比如将来人工智能应该双向的，比如现在手机，每个人其实都拿着一个计算机，这是手机，其实这是一种普及，这种普及，我觉得随着技术的发展，是在消解那种用人工智能做坏事的可能性，当然这种普及包括了不同民族的、不同阶层的、不同角色的，不是你是交易平台，我只是一个普通的交易者，我们俩不平等，不是的，我们是对等的。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;">从这来讲我的想法是，这个技术革命所带来的那种对道德均衡的打破，往往是通过技术革命的普及来解决。最开始贵族有一把刀，是很贵的，一般人是买不起的。这个技术普及了，每个人都有一把刀，这个贵族的优势就没有了。手枪、热兵器发展之前，男女之间力量不平衡，男的力量大。现在女的拿把枪，男的力量优势就没有了，就促进了男女平等。还是这个枪，像美国，大家都有枪，政府有枪、警察有枪，我也有。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 持枪合法化。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 技术的普及造成了一种力量均势。所以我们要求的就是，最先进的技术一定要公布给大家，或者制成大家能用的那样一些设备。当然这个做法还是回到经济学家讲的，我们要市场制度、我们要竞争、反垄断，人工智能要反垄断，尤其现在比较严重的垄断，一个是政府的垄断，一个是大的平台的垄断，所以我觉得这两者可能是最值得关注的，你要管制就管制这两个垄断，政府不能用这种技术去控制公民，这就侵犯了公民权利了，严格来讲，这不是管制，是宪法约束。大平台也是一样，将来你那样做就是垄断了。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 要强制他。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    何光沪：
   </b> 我这两天看到电视上天天有扎克•伯格，扎克•伯格国会对他的问询，他不是有意的泄漏一些东西，控制都能控制，搜集情况都能搜集，但是不能用来伤害你，是这样的。他那个法律是不能上让伤害人，因为他有伤害人，所以把他天天叫来审问他。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 美国人非常敏感这个问题，有很高的警惕性。如果拿这种技术伤害民众，很可怕，所以国会让扎克伯格去去作证，这是一个问题。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    何光沪：
   </b> 是一个失误造成的。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 最后我想讲一讲，人工智能本身是不是构成对作为整体的人类的威胁。我觉得首先，如果人工智能有威胁的话，就必然有它的自我利益，没有的话就不会，有自我利益就接近于人了，它是那个主体，它有主体感。而现在只是一个计算的速度快的问题，现在人工智能是一种没有身体的人工智能，关键是不构成有自我意识和自我利益的主体，我认为没有关系的。人工智能再厉害只是人的一部分、是一个工具，比较可怕的是有人利用它来伤害别的人。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;">另外一点，人工智能有没有道德呢？我觉得可以有道德。道德怎么产生的？道德其实是互动中产生的，假如人工智能和人工智能之间互动，它们一定会产生某种自发秩序，就是某种习俗、某种规则，在比如说一群人工智能中间会形成某种平衡，为什么呢？这是一个基本逻辑，你要保证这个人工智能活别的也活，而且它们之间比较均衡的话，这个逻辑跟人是一样的，所以不是要教它们道德。人们现在的想法，是一种建构主义形式，我告诉你有 <span> 10 </span> 条道德你就遵循，当然这是可以的。还有一种，你从来不告诉它们到底什么是道德，它们会不会知道呢？你要弄一群人工智能，互动多少次以后一定会有，这个也挺有趣。我们的经济学家，包括我们信奉哈耶克自发秩序的人，我们都可以搞这个实验，我买一群人工智能的小机器人让它们去互动。过了一段时间发现他们之间一定有某种规则。我们坚信自发秩序，就坚信有这个结果。所以我说人工智能最后还是有道德的。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 请问一下盛老师，你刚刚讲最后一句话的意思是说，机器人到最后他也会自立的，机器人这个小团体会自立的，就是有道理。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 对，就是说它会自立，但是它不会达到人这样的自立程度。我刚刚说它们是不是有自我，你可以说他它有自我，你假设它有计算，但没有身体，但是它可以达到一定程度的自我意识。比如蚂蚁也有自我，蚂蚁也可以形成规则，但是它们跟人的理性也是有很大差距 。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 你讲的伊斯塔会自立的，他也有他一套规则的。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 其实道德说到头就是个体和群体的关系，只要有个体和群体一定有道德，它们就要互动，你不要给它们规定多少条道德戒律，你就告诉它们你们自己玩去，就会形成规则。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 或者这么说，你给他一个道德的行为，红灯要停的，前面人开过来你要停的，他有这么一个道德思路给他之后，他会发展的，狗爬过来我也听的，什么事情不好做的，他会自立的发展成为一个。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 不用给他一个规则说“红灯要停”，它最后就会停的。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 这个思维的初次输入是谁输给他的，人输给他的？ <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 不是的，你不停就要撞车，完蛋了，我偶然停了就没撞车。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 你的意思是，不要输入给它、它也会停，假如不停它也死掉了。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 这是有代价的，人类也一样，人类早期，刚与黑猩猩分手不久，死亡的概率大概 <span> 15% </span> — <span> 25% </span> ，人类进入文明社会，就是人类有了国家以后大概降低到 <span> 3% </span> — <span> 5% </span> 。现在很低。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    吕兆楠：
   </b> 以前没有交通规则，现在有了。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    何光沪：
   </b> 非自然死亡的。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 非自然，就是说暴力死亡，所以很多人才知道红灯是不能走的。有很多人类学研究，大概 <span> 3% </span> — <span> 5% </span> ，随便有几篇文章、几本书都能找到的这些东西，人类大概是 <span> 15% </span> — <span> 25% </span> 。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    何光沪：
   </b> 你说文明之前？ <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 文明之前，所谓文明就是有国家以后。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    何光沪：
   </b> 野蛮时代、原始时代。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.1pt;"><b>
    盛洪：
   </b> 对。 <span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> [ </span> <b>
    盛洪
   </b> 著名经济学家，天则经济研究所所长。本文为作者 <span> 2018 </span> 年 <span> 7 </span> 月 <span> 11 </span> 日在「人工智能与道德风险」云豹沙龙的演讲，转载请注明 <span> ] </span></p>
    <p class="MsoNormal" style="text-indent:21.0pt;"><span> </span></p>
  </div>
</div>


  </div>

  <hr style="border-top:1px solid #28323C;"/>

<font size=2px>
  文章版权归原作者所有。
</font>

<div style="text-align:center"><img width="1px" src="https://i.imgur.com/HSw56Ez.png" alt="二维码分享本站" style="text-align:center"/></div>

  <div id="sametag">
    <h4 style="display: inline-block;">#天则观点 的其它文章</h4>
    <span>--<a href="https://nodebe4.github.io/opinion/2019-05-29/%E7%9B%9B%E6%B4%AA-%E7%94%A8%E7%BB%93%E6%9E%84%E6%80%A7%E5%AF%B9%E7%AD%89%E5%8E%9F%E5%88%99%E6%9B%BF%E4%BB%A3%E6%80%BB%E4%BD%93%E5%85%B3%E7%A8%8E%E5%AF%B9%E6%8A%97/">最新</a>-</span>
    <span>-<a href="https://nodebe4.github.io/opinion/2009-04-24/%E6%B2%BB%E5%9B%BD-18%E4%BA%BF%E4%BA%A9%E7%BA%A2%E7%BA%BF%E7%9A%84%E5%88%B6%E5%BA%A6%E5%90%AB%E4%B9%89/">最早</a>--</span>
    
      <li>
        <time>2018-08-10</time>
        <a href="https://nodebe4.github.io/opinion/2018-08-10/%E8%AE%A8%E8%AE%BA%E4%B8%8E%E6%8F%90%E9%97%AE-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E9%81%93%E5%BE%B7%E9%A3%8E%E9%99%A9-%E4%BA%91%E8%B1%B9%E6%B2%99%E9%BE%99/">
          讨论与提问「人工智能与道德风险」云豹沙龙
        </a>
      </li>
    
    
      <li>
        <time>2018-08-10</time>
        <a href="https://nodebe4.github.io/opinion/2018-08-10/%E8%92%8B%E8%B1%AA-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%88%B1%E4%B8%8E%E5%BF%A7/">
          蒋豪：人工智能爱与忧
        </a>
      </li>
    
    
      <li>
        <time>2018-08-10</time>
        <a href="https://nodebe4.github.io/opinion/2018-08-10/%E5%AE%81%E8%B6%8A-AI%E6%97%B6%E4%BB%A3%E8%AE%A1%E5%88%92%E7%BB%8F%E6%B5%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BB%8D%E7%84%B6%E4%B8%8D%E5%8F%AF%E8%AE%A1%E7%AE%97/">
          宁越：AI时代计划经济大数据仍然不可计算
        </a>
      </li>
    
    
      <li>
        <time>2018-08-09</time>
        <a href="https://nodebe4.github.io/opinion/2018-08-09/%E7%9B%9B%E6%B4%AA-%E4%BB%8E%E4%B8%AD%E5%9B%BD%E5%88%B6%E9%80%A0%E5%88%B0%E4%B8%AD%E5%9B%BD%E5%B8%82%E5%9C%BA/">
          盛洪：从中国制造到中国市场
        </a>
      </li>
    
  </div>


  <hr>
  <div class="pagination">
    
      <span class="prev" >
          <a href="https://nodebe4.github.io/opinion/2018-08-10/%E7%8E%8B%E5%B0%8F%E9%B2%81-%E6%94%B9%E9%9D%A940%E5%B9%B4%E4%B8%8E%E4%B8%AD%E5%9B%BD%E7%BB%8F%E6%B5%8E%E7%9A%84%E6%9C%AA%E6%9D%A5/">
            前一篇：王小鲁：改革40年与中国经济的未来
          </a>
      </span>
    
    
      <span class="next" >
          <a href="https://nodebe4.github.io/opinion/2018-08-10/%E8%92%8B%E8%B1%AA-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%88%B1%E4%B8%8E%E5%BF%A7/">
            後一篇：蒋豪：人工智能爱与忧
          </a>
      </span>
    

    <script>
    /* post pagination keyboard shortcuts */
    document.body.onkeyup = function(e){
      if (e.keyCode == '37') { window.location = 'https://nodebe4.github.io/opinion/2018-08-10/%E7%8E%8B%E5%B0%8F%E9%B2%81-%E6%94%B9%E9%9D%A940%E5%B9%B4%E4%B8%8E%E4%B8%AD%E5%9B%BD%E7%BB%8F%E6%B5%8E%E7%9A%84%E6%9C%AA%E6%9D%A5/'; } // left arrow key
      if (e.keyCode == '39') { window.location = 'https://nodebe4.github.io/opinion/2018-08-10/%E8%92%8B%E8%B1%AA-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%88%B1%E4%B8%8E%E5%BF%A7/'; } // right arrow key
      if (e.keyCode == '45') { window.location = 'https://nodebe4.github.io/opinion/2018-08-10/%E8%92%8B%E8%B1%AA-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%88%B1%E4%B8%8E%E5%BF%A7/'; } // insert key
      if (e.keyCode == '46') { window.location = 'https://nodebe4.github.io/opinion/2018-08-10/%E5%AE%81%E8%B6%8A-AI%E6%97%B6%E4%BB%A3%E8%AE%A1%E5%88%92%E7%BB%8F%E6%B5%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BB%8D%E7%84%B6%E4%B8%8D%E5%8F%AF%E8%AE%A1%E7%AE%97/'; } // delete key
    };
    </script>
    <link rel="stylesheet" type="text/css" href="/opinion/assets/css/fab.css" />

<div class="fab-wrapper">
  <div class="fab-wheel">
    
    
    
    <a class="fab-action fab-action-1" title="上一篇(热键 &#8594;)" href="https://nodebe4.github.io/opinion/2018-08-10/%E7%8E%8B%E5%B0%8F%E9%B2%81-%E6%94%B9%E9%9D%A940%E5%B9%B4%E4%B8%8E%E4%B8%AD%E5%9B%BD%E7%BB%8F%E6%B5%8E%E7%9A%84%E6%9C%AA%E6%9D%A5/">
      <i>后</i>
    </a>
    
    
    <a class="fab-action fab-action-2" title="下一篇(热键 &#8592;)" href="https://nodebe4.github.io/opinion/2018-08-10/%E8%92%8B%E8%B1%AA-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%88%B1%E4%B8%8E%E5%BF%A7/">
      <i>前</i>
    </a>
    
    
    <a class="fab-action fab-action-3" title="<天则观点>上一篇(热键 ins)" href="https://nodebe4.github.io/opinion/2018-08-10/%E8%92%8B%E8%B1%AA-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%88%B1%E4%B8%8E%E5%BF%A7/">
      <i>左</i>
    </a>
    
    
    <a class="fab-action fab-action-4" title="<天则观点>下一篇(热键 del)" href="https://nodebe4.github.io/opinion/2018-08-10/%E5%AE%81%E8%B6%8A-AI%E6%97%B6%E4%BB%A3%E8%AE%A1%E5%88%92%E7%BB%8F%E6%B5%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BB%8D%E7%84%B6%E4%B8%8D%E5%8F%AF%E8%AE%A1%E7%AE%97/">
      <i>右</i>
    </a>
    
  </div>
</div>


  </div>


  

</article>

    </div>

    <div style="z-index:2;">
<script src="/opinion/assets/js/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
  diameter: 56,
  cornerOffset: 20, // px
  id: 'back-to-top',
  backgroundColor: '#ddd',
  textColor: 'red'
})</script>
</div>


    <div class="wrapper-footer" id="footer">
      <div class="container">
        <footer class="footer">
          <img width="200px" src="https://i.imgur.com/HSw56Ez.png" alt="二维码分享本站"/>
<font size=2px>二维码分享本站</font>

<!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

  

  

  
  <li><a href="mailto:beauti4@protonmail.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
  

  

  

  
  <li><a href="https://github.com/NodeBE4/opinion" class="icon-13 github" title="GitHub"><svg viewBox="0 0 512 512"><path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z"/></svg><!--[if lt IE 9]><em>GitHub</em><![endif]--></a></li>
  

  

  

  

  

  
  <li><a href="/opinion/feed.xml" class="icon-21 rss" title="RSS"><svg viewBox="0 0 512 512"><path d="M201.8 347.2c0 20.3-16.5 36.8-36.8 36.8 -20.3 0-36.8-16.5-36.8-36.8s16.5-36.8 36.8-36.8C185.3 310.4 201.8 326.8 201.8 347.2zM128.2 204.7v54.5c68.5 0.7 124 56.3 124.7 124.7h54.5C306.7 285.3 226.9 205.4 128.2 204.7zM128.2 166.6c57.9 0.3 112.3 22.9 153.2 63.9 41 41 63.7 95.5 63.9 153.5h54.5c-0.3-149.9-121.7-271.4-271.6-271.9V166.6L128.2 166.6z"/></svg><!--[if lt IE 9]><em>RSS</em><![endif]--></a></li>
  

  

  

  

  

    
</ul>





<p><span style="color:blue">内容每小时更新一次.</span> Powered by <a href="https://github.com/AWEEKJ/kiko-now">Kiko Now</a> & <a href="https://github.com/gitalk/gitalk">Gitalk</a> & <a href="https://github.com/duty-machine/news">duty-machine</a>, 站务 <a href="https://be4.herokuapp.com">NodeBE4</a>（<span style="color:red">被墙</span>）</p>





        </footer>
      </div>
    </div>

    



  </body>
</html>
